[{"authors":["admin"],"categories":null,"content":"\nHelping you create and mentor security aware, cross functional, self-managing teams, able to create solutions that resist, and actively defend against today\u0026rsquo;s security attacks, while increasing profit and reducing costs.\n\nWhether you\u0026rsquo;re running a small or large project, we can work with you to move the information security focus from late in the development life-cycle to within the development team. Thus saving significant costs, while improving quality, productivity, and predictability of software releases.\n\nBe sure to review some of the clients we\u0026rsquo;ve worked with to establish successful outcomes, along with their testimonials\n","date":1613535431,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1613535431,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://binarymist.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Helping you create and mentor security aware, cross functional, self-managing teams, able to create solutions that resist, and actively defend against today\u0026rsquo;s security attacks, while increasing profit and reducing costs.\n\nWhether you\u0026rsquo;re running a small or large project, we can work with you to move the information security focus from late in the development life-cycle to within the development team. Thus saving significant costs, while improving quality, productivity, and predictability of software releases.","tags":null,"title":"Kim Carter","type":"authors"},{"authors":["Kim Carter"],"categories":[],"content":" purpleteam alpha (both local and cloud environments) have been released, after several years of hard work, mostly on top of a day job.\n\nThis is the very short story of the process of taking purpleteam (a web security regression testing SaaS and CLI) from Proof of Concept (PoC) to Alpha release.\nPoC Q: What were my intentions with creating the original Proof of Concept (PoC), what was I trying to achieve?\nA: Elicit Developer feedback, Find out what Developers and their Teams really needed for just in time security regression testing of their web applications and APIs. How to get this process (dynamic security testing) as close as possible to the coding of their applications and APIs\nQ: What did I do with the PoC?\nA: Took it around the world speaking and running workshops with Developers and their Teams. That\u0026rsquo;s right, getting this process as close as possible to Developers and their Teams\nTo name a few such events:\n CHCH.js Meetup 2016 OWASP Chch Meetup 2016 OWASP NYC Meetup 2016 NodeConf EU 2016 NodeJS Meetup Auckland 2016 AWS Meetup Auckland 2016 OWASP NZ Day Auckland 2019  There are many Static Analyse Security Testing (SAST) tools available. As Developers we need both static and dynamic application security testing.\nThe Proof of Concept I created several years ago was to work out exactly what Developers and their Teams needed in terms of Dynamic Application Security Testing (DAST) capabilities to compliment the many Static Application Security Testing (SAST) tools already available and able to be plugged into or consumed by your CI/build pipelines.\nI\u0026rsquo;ve written extensively in the past on SAST offerings, for example the Web Applications chapter of my 2nd book Holistic Info-Sec for Web Developers covers:\n The perils of consuming free and open source libraries Countermeasures to the above perils Tooling options for SAST  Journey If you\u0026rsquo;re a Developer creating internet facing applications, you know security is something you need to be thinking about right? As Developers we all need as much automated help with improving our AppSec as possible. As we\u0026rsquo;re creating it, no blockers, just enablers.\nMany organisations spend many thousands of dollars on security defect remediation of the software projects they create. Usually this effort is also performed late in the development life-cycle, often even after the code is considered done. This fact makes the remediation effort very costly and often too short. Because of this there are many bugs left in the software that get deployed to production.\n\n \nPurpleteam strikes at the very heart of this problem. Purpleteam is a CLI and back-end/API (SaaS). The CLI can be run manually, but it\u0026rsquo;s sweet spot is being inserted into Development Team\u0026rsquo;s build pipelines, where it can find the security defects in your running web applications and APIs, and provide immediate and continuous notification of what and where your security defects are, along with tips on how to fix them.\n\n \nThe purpleteam back-end runs smart dynamic application security testing against your web applications or APIs. The purpleteam CLI drives the purpleteam back-end.\n\n \nI have also created the ability to add testers, There is currently a TLS checker and server scanner stubbed out and ready to be implemented. Feel free to dive in and start implementing.\n\n \nIf there is a tester that you need that purpleteam doesn\u0026rsquo;t have, you can now create it.\nEnvironments local The local environment is free and open source. It is also now an OWASP project.\n There\u0026rsquo;s quite a bit of set-up to do You need to set-up all the micro-services All the set-up should be documented here. Documentation will be moving to a proper doc site soon.  You will need to set-up the following:\n Lambda functions Stage 2 containers Orchestrator Testers (only app currently) Get the purpleteam CLI on your system  Install it, the options are:  Clone the repository Local NPM install Global NPM install  Configure it and create your Job file  Run your System under Test (SUT). we use purpleteam-iac-sut to build/deploy our cloud SUTs Run the purpleteam CLI  cloud The cloud environment costs because purpleteam-labs have to maintain the infrastructure that the SaaS runs on, but is the easiest and quickest to get going.\nAll infrastructure set-up is done for you. You just need to set-up the following:\n Get the purpleteam CLI on your system (same as step 5.1 of local). Configure the CLI and create your Job file (similar to step 5.2 of local) Run your SUT (same as step 6 of local) Run the purpleteam CLI (same as step 7 of local)  Architecture and Tech local Redis pub/sub is used to transfer Tester messages (live update data) from the Tester micro-services to the Orchestrator. The Build User can configure the purpleteam CLI to receive these messages via Server Sent Events (SSE) or Long Polling (LP). The Orchestrator also needs to be configured to use either SSE or LP. With Long Polling (LP) if the CLI goes off-line at some point during the Test Run and then comes back on-line, no messages will be lost due to the fact that the Orchestrator persists the messages it\u0026rsquo;s subscribed to back to Redis lists, then pops them off the given lists as a LP request comes in and returns them to the CLI. LP is request-\u0026gt;response, SSE is one way. In saying that, LP can be quite efficient as we are able to batch messages into arrays to be returned.\nOrchestrator The Orchestrator is responsible for:\n Organising and supervising the Testers Sending real-time Tester messages to the CLI via either SSE or LP Packaging and sending the outcomes (test reports, test results) back to the CLI as they become available Validating, filtering and sanitising the Build User\u0026rsquo;s input  Testers Each Tester is responsible for:\n Obtaining resources, cleaning up and releasing resources once the Test Run is finished Starting and Stopping Stage Two Containers (hosted on docker-compose-ui) dynamically (via Lambda Functions hosted locally via sam cli) based on the number of Test Sessions provided by the Build User in the Job file which is sent from the CLI to the Orchestrator, then disseminated to the Testers. The following shows two Test Sessions from a test resource Job that we use: ... \u0026#34;included\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;testSession\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;lowPrivUser\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;user1\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;User1_123\u0026#34;, \u0026#34;aScannerAttackStrength\u0026#34;: \u0026#34;HIGH\u0026#34;, \u0026#34;aScannerAlertThreshold\u0026#34;: \u0026#34;LOW\u0026#34;, \u0026#34;alertThreshold\u0026#34;: 12 }, \u0026#34;relationships\u0026#34;: { \u0026#34;data\u0026#34;: [{ \u0026#34;type\u0026#34;: \u0026#34;route\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;/profile\u0026#34; }] } }, { \u0026#34;type\u0026#34;: \u0026#34;testSession\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;adminUser\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;admin\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;Admin_123\u0026#34; }, \u0026#34;relationships\u0026#34;: { \u0026#34;data\u0026#34;: [{ \u0026#34;type\u0026#34;: \u0026#34;route\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;/memos\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;route\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;/profile\u0026#34; }] } }, ...  The actual (app, server, tls, etc) test plan  Sam Cli Sam Cli stays running and listening for the Tester requests to run the lambda functions which start and stop the Stage Two Containers.\ndocker-compose-ui In local docker-compose-ui is required to be running in order to start/stop it\u0026rsquo;s hosted (Stage Two) containers (it has access to the hosts Docker socket).\ncloud The cloud environment is similar in terms of functionality, a good number of components are quite different though.\nFor the Tester messages only Long Polling (LP) is available due to streaming APIs not being supported by AWS API Gateway. We could have used API Gateway WebSockets for bi-directional comms, but that doesn\u0026rsquo;t support OAuth client-credentials flow, which I had already completed.\nWhen the CLI makes a request to the back-end (directly to the Orchestrator in local, but AWS API Gateway in cloud), first that request is intercepted and a request to the purpleteam auth domain is made with: grant_type, client_id of the user pool app client, scopes, client_secret. Cognito Authorisation server returns an access_token if all good. The CLI then makes requests with the access_token to the resource server which in our case is the API Gateway. The resource server/API Gateway validates the access_token with the User pool. If all good, the original request is allowed to continue on it\u0026rsquo;s way.\nTesters run their lambdas, lambdas tell ECS to spin up and tear down n (where n is the number of Test Sessions) stage 2 containers. I originally used AWS ALB but that didn\u0026rsquo;t support our authentication requirements, so I had to back out and swap it for API Gateway and NLB.\nPressures Keeping NodeJS Dedendencies up to date The never ending battle of staying on top of a constantly moving NodeJS ecosystem. Never ending security and feature updates. This issue has a check list of our last major updates after we finished the IaC for the cloud environment.\nForking/adopting libraries Then there is the forking and/or rewriting of libraries when authors lose interest, no longer maintain or just no longer have the bandwidth. This must be expected and planned for when consuming free and open source libraries. Yes it\u0026rsquo;s great to have the head start of being able to just use someone else\u0026rsquo;s code, but nothing is really free, everything ultimately costs. Just realise that if you are consuming free and open source libraries in your project, then at some stage you are going to have to dive into their code and either help out, or ultimately end up forking or rewriting.\nFollowing are some of the libraries we have forked, ported and/or rewritten:\n mocksse was a rewrite/port of MockEvent. We use this library for mocking Server Sent Events (SSE) Cucumber functionality that was removed docker-compose-ui has been archived. This means we will have to either fork, rewrite, research to see if we can use something else. This isn\u0026rsquo;t currently urgent  Competitors When I started developing purpleteam, as part of the business plan creation I needed to list my competitors. There was really only one. Now that competitor has mostly gone away and we have several new ones.\nJust to be clear, when I say competitor, I\u0026rsquo;m talking about Dynamic Application Security Tools for the web that can be used natively in any build pipeline.\nOur current competitors are doing things differently to us, with different offerings. We think purpleteam has unique aspects that make it stand out from the rest.\nNext Steps purpleteam local is now an OWASP project.\nConsuming purpleteam How can you start using purpleteam today?\nAs discussed in the Environments sub section you have a few options\n local: set everything up yourself cloud: Sign-up for an account, set-up your test Job, get the CLI on your system  You can use the purpleteam CLI manually or consume it within your build pipelines.\n Manual examples:  bin/purpleteam via npm script bin/purpleteam directly purpleteam CLI directly  Within your NodeJS app or build pipeline Within your non NodeJS app or build pipelines  Contributing to purpleteam  Is purpleteam missing something you need that would otherwise allow you to use it? Do you need to add a different kind of Tester? Have you found a bug?  Ways you can contribute to building #owasp #purpleteam https://t.co/yxdb9XJaIT\n\u0026mdash; purpleteam (@purpleteamlabs) February 20, 2021  As you can see, there are plenty of avenues that you can contribute to:\n Github Discussions OWASP purpleteam Slack Project Board Submit Issue Submit PR Reporting Security Issues Public Roadmap CONTRIBUTING.md  purpleteam-labs also has a submission in with Google Summer of Code for students this year. We\u0026rsquo;ve got plenty to work on, so here\u0026rsquo;s hoping!\npurpleteam Next Steps We will be getting started on a documentation site (not just a hosted doc git repo) soon. We will also be working on a real website. If you have a Dev Team that is keen to try purpleteam out, reach out to us if you need to. We are always looking for people to work on the codebase. Even if you\u0026rsquo;re a student, it\u0026rsquo;s a great way to learn about security, by coding it.\n","date":1613535431,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613535431,"objectID":"6b53c23e158407a1e23fbe429caca057","permalink":"https://binarymist.io/blog/2021/02/17/purpleteam-at-alpha/","publishdate":"2021-02-17T17:17:11+13:00","relpermalink":"/blog/2021/02/17/purpleteam-at-alpha/","section":"post","summary":"Where has Kim been for the last couple of years? This post explains why he's been so quiet and what he has been working on.","tags":["agile","application-security","bdd","blue-team","build-pipeline","build-tool","cd","ci","cli","cloud","cloud-security","continuous-deployment","continuous-integration","cybersecurity","dev-sec-ops","dev-ops","docker","free-and-open-source","information-security","infosec","owasp","owasp-zap","penetration-testing","purpleteam","red-team","security","security-regression-testing","software","software-security","security-testing","terminal","testing","tool","web","web-application","web-application-security","web-security","zap"],"title":"Purpleteam at Alpha","type":"post"},{"authors":null,"categories":null,"content":"Let me take you on the journey of trials, errors, and lessons learnt from getting a web app/API security regression testing proof of concept (PoC) to the next stage (alpha release).\nIn 2019, I gave a talk at OWASP New Zealand Day on a security regression testing PoC I had developed based on developer feedback. Since then, on top of a normal day job, I’ve been working on this project with every spare minute of time.\n  \nLet’s walk through the:\n Architecture: How the micro-services hang together and communicate with each other. Design decisions, including backing out of some and redesigning when I got them wrong Environments: local: you set-up all the purpleteam micro-services on your own machine or within your network. cloud: all set-up is done for you, just create a job file and run it Technologies: Micro-services written in NodeJS. Docker containers. Authentication/authorisation in the cloud. Lambda functions (local and cloud). Redis pub/sub and lists, along with Server Sent Events for messaging. Many AWS services. Terraform and Terragrunt for IaC Pressures: The never ending battle of keeping your NodeJS dependencies up to date. Forking/adopting libraries when maintainers disappear. Keeping relationships alive. Keeping yourself alive (eating, sleeping, fitness). Dealing with competitors  \n \nWe will then discuss the next steps for purpleteam, and how you can start using - and contributing to it if it’s missing something you need.\n\n","date":1613093100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613093100,"objectID":"6274cabd589238f584393472a318ce86","permalink":"https://binarymist.io/talk/appsecnz-2021-talk-building-purpleteam-a-security-regression-testing-saas-from-poc-to-alpha/","publishdate":"2021-02-13T16:00:00+13:00","relpermalink":"/talk/appsecnz-2021-talk-building-purpleteam-a-security-regression-testing-saas-from-poc-to-alpha/","section":"talk","summary":"Developers / Engineers know that a build pipeline is an essential part of creating robust and reliable software, but what to put in it? This talk covers the creation of purpleteam from PoC to Alpha release, and why it’s an ideal fit for the security regression testing slot of your build pipeline.\n","tags":["talk","conference","agile","application-security","bdd","blue-team","build-pipeline","build-tool","cd","ci","cli","cloud","cloud-security","continuous-deployment","continuous-integration","cybersecurity","dev-sec-ops","dev-ops","docker","free-and-open-source","information-security","infosec","owasp","owasp-zap","penetration-testing","purpleteam","red-team","security","security-regression-testing","software","software-security","security-testing","terminal","testing","tool","web","web-application","web-application-security","web-security","zap"],"title":"Talk - Building purpleteam (a Security Regression Testing SaaS) - From PoC to Alpha","type":"talk"},{"authors":null,"categories":null,"content":" Trineo\n Kim’s expertise and insights helped shape our security strategy. Kim’s experience enabled us to adopt best practices in a way that fits our teams and focuses on what really works.\nSecurity is difficult to do alone. The more experience you can leverage the better. Kim can help you on your security journey by showing you what works and what doesn’t, and help you avoid common mistakes. We\u0026rsquo;re in a stronger position for having hired him.\nAs a person, Kim is highly-focused, knowledgeable, and always to the point: someone you can collaborate with who will make the most of the time you spend with him.\n","date":1572480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572480000,"objectID":"cf3109820684613fbebbb91170f2de56","permalink":"https://binarymist.io/project/testimonial-pete-nicholls/","publishdate":"2019-10-31T00:00:00Z","relpermalink":"/project/testimonial-pete-nicholls/","section":"project","summary":"Trineo","tags":["testimonial"],"title":"Pete Nicholls","type":"project"},{"authors":null,"categories":null,"content":" Security threat model and roadmap\n    Provided a security threat model/roadmap and product backlog items ready to be pulled into WIP.\nWorked with Trineo to create a detailed programme to deploy Security Champions within Trineo's Teams.\nSee similar service for details.    See testimonial by Pete Nicholls\n","date":1572480000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572480000,"objectID":"f7718a2883d19e5a6d098222addbf6f7","permalink":"https://binarymist.io/project/portfolio-trineo/","publishdate":"2019-10-31T00:00:00Z","relpermalink":"/project/portfolio-trineo/","section":"project","summary":"Security threat model \u0026#38; roadmap","tags":["portfolio","security-portfolio"],"title":"Trineo","type":"project"},{"authors":["Kim Carter"],"categories":[],"content":" Who devs wins, who doesn’t didn’t.\nWe had twelve Jade Development Teams go head-to-head in the Jade Secure Coding Tournament on Tuesday. This was both a fun and educational event for many of our Software Developers. The Secure Coding Tournament provided a great opportunity to identify code with security defects, locate and apply secure code mitigations, and have a great time doing it.\n  We used the Secure Code Warrior (SCW) tournament environment, which is an integrated platform, leader-board and challenge environment. The SCW environment allows participants to select the language and framework from a large collection that they would like to be challenged in.\nLanguages and Frameworks Available  Angular 1 \u0026amp; 2 C# C# - MVC C# - Webforms C# - Core Go Java - Enterprise Java - Spring Java - Struts Node.JS - Express PHP Symfony Python - Django Python - Flask React Ruby On Rails Scaala - Play Android - Java Android - Kotlin IOS - Objective C IOS - Swift React Native C C++ Cobol Oracle PL/SQL Pseudocode  This was just one initiative to help build security into the Jade culture, and introduce our Security Champions to the entire company.\nEvaluated Options As part of the tournament investigation, I evaluated the following set of offerings:\nTournament    Offering license Description Pros Cons Lang Challenge Type Doc     SCW Proprietary Integrated platform and challenges Covers all mainstream languagesSelf containedMost of the work done for usVery structured There will be sales pitchesObviously a SCW tournament, not really branded to bespokeChallenges are code snippets, no business context, can not debugNo plain JavaScriptVery structuredStatistics at game end N/A N/A N/A   CTFd Proprietary Platform No need for hosting Costs a littleNot as flexible as open source platforms N/A N/A N/A   fbctf Free \u0026amp; open\nnon-commercial Platform Fully featured Takes some set-up N/A N/A Plenty   OWASP NodeGoat Free \u0026amp; open Challenges Kim is a core contributor ? Web\nJS\nNode White box Plenty   Google Gruyere Free (CC) Challenges Beginner level ? Python White \u0026amp; black box Plenty   OWASP Juice Shop Free \u0026amp; open Challenges \u0026amp; optional platform Slick offering ? JS\nNode\nExpress\nAngular Black box Plenty   OWASP Security Shepherd Free \u0026amp; open Challenges \u0026amp; optional platform OWASP flagship ? web Black box Plenty   OWASP WebGoat.net Free \u0026amp; open Challenges ? Unmaintained,\nNo official tutorials, but some community provided web\nC# Black box\nsource available d1   dvta Free \u0026amp; open Challenges ? Unmaintained,\nNo official tutorials, but some community provided Thick client\nC# Black box / white box, not sure but source is available d2\nd3\nd4\nd5\nd6\nd7\nd8\n    Quiz    Offering Pros Cons     Kim\u0026rsquo;s Quiz If we\u0026rsquo;re all co-located, this is ready to role, if not, it\u0026rsquo;s just a matter of putting into a Google QuizHave run this before and attendees enjoyed it and learnt quite a bitTrivial to organise It\u0026rsquo;s not coding    The Event We had Tim Aston and Mitchell Mendonca from SCW to run the environment, and they were knowledgeable and excellent at doing so. I had the joy of MCing the event.\nThe tournament schedule looks like this:\n   Activity Timing     Introductions 30 minutes   Game 1.5 hours   Prize giving - Outro 30 minutes    The main reasons we chose SCW for the first Jade secure coding tournament, was because:\n The large collection of programming languages available Many (hundreds for each language) challenges The platform and challenges were integrated and ready to roll. As SCW calls it: \u0026ldquo;Tournament in a box\u0026ldquo; Ability to participate in tournament remotely. This was great for our Development Teams in other cities and countries I had seen the SCW tournament run previously at an internal AppSec conference I\u0026rsquo;d been invited to speak at, and from a spectators point-of-view, it looked amazing and was a very engaging event  The SCW integrated environment is useful for learning to spot code-only defects and apply countermeasures. There is little in the way of an overall project context with the questions, the context is at a code level.\nWhere I think we may be able to do better than the SCW integrated platform is by providing challenges that are more holistic, rather than just multi-choice and tunnel vision (“is it this snippet of code or this other snippet of code”). Often finding security defects in software is not as naively simplistic as: \u0026ldquo;Is it this line of code that’s defective or this other line?\u0026rdquo;. Often defects are a combination of code, config, how the solution has been deployed, and a variety of other aspects. In saying that, I still think that the SCW integrated environment is quite a valuable educational tool for spotting code level defects and learning which mitigations to apply.\nThe SCW integrated environment would be useful for measuring the progress of how your Developers are improving at spotting code-only defects and applying countermeasures over time, provided you ran this same tournament regularly (say every 6 to 12 months). This is where I see the statistics provided at game end becoming quite valuable. Although\u0026hellip; I’m thinking that you could get similar measurability from using a purpose built platform that you can add your own chosen challenges, although this requires that you actually put this together.\nConclusion Overall this initial tournament was a great success, it brought many Developers together in a fun, focussed, application security learning environment. The game-end statistics were useful and should be even more useful if we use the SCW tournament environment again. This was a good step along the journey of establishing a security culture at Jade.\n","date":1567166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567166400,"objectID":"4c3d4d0c1a07cdea86d84dfb527c53c6","permalink":"https://binarymist.io/blog/2019/08/31/who-devs-wins/","publishdate":"2019-08-31T00:00:00+12:00","relpermalink":"/blog/2019/08/31/who-devs-wins/","section":"post","summary":"Twelve Jade Development Teams go head-to-head in the Jade Secure Coding Tournament","tags":["application-security","security","software-security","tournament"],"title":"Who Devs Wins","type":"post"},{"authors":null,"categories":null,"content":" This workshop was specifically taylored to initialise, train, motivate, and empower the new Security Champions within Jade, to scale security capability within all Jade Development Teams.\nWith the primary objective of revealing the secrets of shifting the focus on security from late in the software development life-cycle to within the Development Teams.\nNot only does this significantly reduce the number of security defects being pushed to production systems, but also significantly reduces the total cost of development.\nCheapest place to deal with defects There have been many studies specifically looking at the costs of finding and fixing defects early, as opposed to the planning of how to fix defects once the product is delivered, or not planning at all.\nThe following table shows the average cost of fixing defects based on when they were introduced versus when they are detected. Putting these practises in the right order can reduce costs of fixing security defects by up to 100 times.\n\nSo\u0026hellip; by simply shifting the security expertise from the end of the project to within the development team, thus enabling developers to find and fix their defects as they are being introduced, huge cost savings can be enjoyed.\nThis is not as difficult as you may think.\nOn the Day Kim will lead the class through the tools, techniques and thought processes of both red (attacking) and blue (defending) teams along with how to combine these attributes into the purple team focussing on security, productivity, and tasked with continuously delivering sustainable maintainable technical solutions to market.\nKim will explain the roles of \u0026rsquo;T\u0026rsquo; shaped professionals, including placement of security champions to create your purple Development Teams.\nWe will work through how to implement the Sensible Security Model (SSM) within each and every Sprint, including:\n Creating actionable countermeasure Product Backlog Items Integrating them into the same Product Backlog that your Development Team has been pulling business focussed items from Ordering them based on the risk ratings you create for each  Kim will discuss how and where Agile Development Teams often fail, along with how to succeed with security with a familiar anecdote. Then augmenting your Scrum process within each and every Sprint, with a collection of development focussed processes and practises, tools and techniques that have proven their value at drastically reducing defects before production deployment.\nKim will walk us through the SSM threat modelling process with theory and hands on exercises in areas such as Physical, People, VPS, Network, Cloud and Web Applications. Including sub topics such as Docker, Serverless, PowerShell and many others.\n\nMore Detail Training material will be augmented with Extracts from Kim\u0026rsquo;s interviews on Software Engineering Radio with security experts such as Diogo Mónica (Docker Security Team Lead) and Haroon Meer (creator of Canary tools and tokens).\nLearnings Coverage of topic chapters:\n Physical People VPS Network Cloud Web Applications  \n","date":1552420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552420800,"objectID":"cb772a9b1f60704c64d685043f5476b8","permalink":"https://binarymist.io/talk/jade-2019-security-titans-workshop/","publishdate":"2019-03-13T09:00:00+13:00","relpermalink":"/talk/jade-2019-security-titans-workshop/","section":"talk","summary":"Workshop to initialise, train and deploy the Jade Security Champions across the Jade Development Teams.\n","tags":["workshop","security","physical-security","people-security","vps-security","network-security","cloud","cloud-security","dev-ops","dev-sec-ops","docker","web-application-security","web-security","web-application","holistic-info-sec-for-web-developers","application-security","cybersecurity","information-security","security-weaknesses","software-security","hacking","conference","operational-efficiencies"],"title":"Workshop - Init Security Titans","type":"talk"},{"authors":null,"categories":null,"content":"Reports state very high numbers of security vulnerabilities in official images on Docker Hub. Host kernels contain 20+ M LoC, reachable from untrusted applications via many kernel APIs, providing huge attack surface. Dockers default is to run containers and all commands/processes within a container as root.\nKim will discuss:\n Tooling options around significantly improving visibility of vulnerabilities in Docker components and containers Safe consumption of Docker images from public registries. Addressing origin, authorship with identification using digests and integrity with opt-in Docker Content Trust  Based on Kim\u0026rsquo;s:\n Experience building a full dynamically Dockerised security regression testing SaaS Writing and publishing the Docker Security - Quick Reference book Interviews with experts such as Docker Security Team Lead Diogo Mónica, and Michael Hausenblas of Red Hat (author of the book Container Networking) on Container Networking  Docker host, engine, container, networking and deployment security will be covered with many examples. We will cover:\n Namespaces Controlling system resources accessible to containers with CGrouups LSMs Reducing default Capabilities of the Container root user Reducing default syscalls to only the essentials with Seccomp Filesystem Mounts Coverage of good security practises in Dockerfiles and docker-compose  \n","date":1550804400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550804400,"objectID":"64d46059244d98b25353e99e9f1b2a2e","permalink":"https://binarymist.io/talk/owaspnzday-2019-talk-hardening-your-docker-infrastructure/","publishdate":"2019-02-22T16:00:00+13:00","relpermalink":"/talk/owaspnzday-2019-talk-hardening-your-docker-infrastructure/","section":"talk","summary":"The security defaults of Docker are designed to get you up and running (“just work”) quickly, rather than being the most secure. There are many default configurations that can be improved upon. In this talk Kim will walk through improving the security of Docker hosts, containers, networking and deployments.\n","tags":["talk","application-security","book","capabilities","control-groups","cybersecurity","dev-ops","dev-sec-ops","docker","conference","holistic-info-sec-for-web-developers","information-security","infosec","namespaces","networking","owasp-nz-day","seccomp","security","software-security","web-application-security"],"title":"Talk - Hardening Your Docker Infrastructure","type":"talk"},{"authors":null,"categories":null,"content":"As Developers, we’re still creating defective code. There are many areas we’ve been able to configure and automate to help improve security, but the very human aspect of creating secure code is still a dark art, and in many cases our single point of failure.\nWe’re going to discuss traditional approaches of addressing security in our software, and why they’re just not cutting it any more. A red teaming engagement can be very expensive, is too late in the SDLC to be finding then fixing bugs. In many cases we’re pushing code to production continuously, the traditional approaches and security checks are no longer viable.\n\n \nIn this session, Kim will attempt to demystify how security can become less of a disabler/blocker and more of an enabler/selling point, allowing you to create and deliver robust software with security baked in as frequently and confidently as your business demands.\nWe’re going to unlock the secrets of building and running a Development Team with security super powers (the purpleteam), finding and fixing defects at the very point that they’re introduced.\nOne of the tools often used is the OWASP ZAP API, now we have an officially supported Node API. In this talk we build on the Node API to create a fully featured security regression testing CLI that can be consumed by your CI/nightly builds.\n\n","date":1550795400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550795400,"objectID":"f908c65ab89cd5fc7fbfaea4cee2af79","permalink":"https://binarymist.io/talk/owaspnzday-2019-talk-security-regression-testing-on-owasp-zap-node-api/","publishdate":"2019-02-22T13:30:00+13:00","relpermalink":"/talk/owaspnzday-2019-talk-security-regression-testing-on-owasp-zap-node-api/","section":"talk","summary":"The OWASP ZAP HTTP intercepting proxy is useful for manually attacking your Web apps and APIs. Now, we have the official Node API to programatically drive ZAP to regression test our creations. Kim will show you how to build a fully featured security regression testing CLI, consumable by your CI/nightly builds. ","tags":["talk","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-nz-day","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Talk - Security Regression Testing on OWASP Zap Node API","type":"talk"},{"authors":null,"categories":null,"content":" Who is it for? You! IT security professionals, web developers, software developers, students, wannabes, hackers, enthusiasts, etc\n","date":1540497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540497600,"objectID":"850498abc41d448a8a40502002120818","permalink":"https://binarymist.io/talk/chcon-2018/","publishdate":"2018-10-26T09:00:00+13:00","relpermalink":"/talk/chcon-2018/","section":"talk","summary":"CHCon 2018: A conference for security professionals and hackers in Christchurch, NZ.\n","tags":["conference","cloud-security","cybersecurity","information-security","infosec","security"],"title":"Conference - Christchurch Hacker Con","type":"talk"},{"authors":["Kim Carter"],"categories":null,"content":" \nShow Outline Container Networking Stack  What is container networking, and why do we need to network containers? Let’s talk a bit about what the networking stack is comprised of when it comes to containers. Can you explain briefly the three layers:  Low-level networking Container networking Container orchestration  We talked a bit about how most networks today are becoming the responsibility of Software Engineers in show #302 Network Security with Haroon Meer. I also cover this in my book “Cloud Security”. Can you explain what Software-Defined Networking (SDN) is, and why Software Engineers need to understand it?  Single-Host Container Networking  There are four single host networking modes based on the four Linux kernel network namespace drivers.  bridge host (faster, less secure) container none\nCan you give us a description of these modes, what they give us, how they work, and where we would use each one?  In terms of allocating IP addresses, the bridge mode mostly takes care of this, what about the other modes? In terms of managing ports, we have fixed and dynamic port allocation. How do each of these work, and in which cases would we use each one? There are quite a few things to consider in terms of network security with Docker containers. By default, containers on the same host can communicate with each other due to --icc=true which means comms work by default, but there are risks that need to be considered. What are these risks, and how do Engineers mitigate them? If one container gets compromised, it could potentially access other containers on the host and compromise them also. What else do we need to be thinking about in order to provide solid configuration and mitigation?  Multi-Host Container Networking  We’re going to dive into the section within your book on Multi-Host Container Networking now, just before we do, can you give a quick explanation of what IpTables is? According to the Docker networking communication docs:  With the section on Communicating to the outside world stating Docker’s forward rules permit all external source IPs by default. So by default, any interface outside of the host can access the hosts container Then the section on Container communication between hosts states Docker sets the default policy of the iptables FORWARD chain to DROP, so a host receiving comms from the outside does not by default forward them on to the hosts container\nCan you explain what actually happens here? What are the actual defaults with inter-host comms of containers, how when and why should Engineers go about changing this?  What is an overlay network? What does Dockers support for overlay networks look like? How do you go about creating an overlay network? What’s the difference between an overlay network and a swarm? How do we encrypt traffic between all containers on an overlay network? docker network create --opt encrypted --driver overlay What are some of the network plugins Docker provides, and how do you use them? Can you give us a run-down on the following multi-host container networking options, along with their pros and cons:  Flannel by CoreOS WeaveNet by Weaveworks Project Calico by Metaswitch Open vSwitch from the OpenStack project OpenVpn  What sort of issues arise out of IP address management and how are these addressed?  Orchestration  What is container orchestration, tell us a bit about the different roles involved?  organisational primitives Scheduling Automated health checks Autoscaling upgrade strategies service discovery  What are the main players/products in container orchestration, and what platforms do they run on? What are the organisational primitives that exist, what are they used for and responsible for?  Kubernetes Networking  Give us a rundown on what Kubernetes is, and what the problem is that it’s trying to solve? What are the main components in Kubernetes, and what are they responsible for? Give us a bit of an overview of Kubernetes networking? Containers can communicate with all other containers without NAT Nodes can communicate with all containers (and vice versa) without NAT The IP a container sees itself is the same IP as others see it Tell us a bit about how Kubernetes does:\nIntra-pod networking (container mode networking (all containers share the same IP), isn’t this a security flaw?)\nInter-pod networking\nIngress and egress What are the different options for service discovery in Kubernetes? Tell us a bit about how service meshes work in Kubernetes?  Service Discovery  In terms of registering a container, what happens when the scheduler dies and the registered containers keep running, essentially the containers are now running rogue? There are a few service discovery tools listed in your book Container Networking, such as ZooKeeper, etcd, Consul and a couple of others. Do the orchestrator solutions not have their own service discovery tools? Tell us a bit about the service discovery solutions available, where they shine, and not so much? You also mention a collection of load balancing tools in your book, do the orchestration solutions not have their own integrated load balancers, and if not, how do you go about integrating a load balancer?  Container Network Interface  Tell us a bit about the Container Network Interface (CNI), Docker’s libnetwork and how they differ? What are some of the CNI plugins and what are they responsible for?  ","date":1539129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539129600,"objectID":"4f0158f30fd29f08893f6a0897a92855","permalink":"https://binarymist.io/publication/ser-podcast-container-networking/","publishdate":"2018-10-10T00:00:00Z","relpermalink":"/publication/ser-podcast-container-networking/","section":"publication","summary":"Michael Hausenblas and Kim Carter discuss container networking concepts from Michael’s book Container Networking. Covering Kubernetes, service discovery, orchestration, and many other related topics.\n","tags":["publication","podcast","dev-ops","docker","networking","kubernetes"],"title":"Michael Hausenblas on Container Networking","type":"publication"},{"authors":["Kim Carter"],"categories":null,"content":" \nShow Outline Basic Questions  Can you explain what attack surface is? If we are to reduce attack surface, we need to be able to measure it. How would you go about quantifying the attack surface before and after defects have been found and fixed? How does your threat modelling approach take into consideration the severity as well as number of defects? I’m working on a project. I’ve measured my attack surface, found and fixed some defects, measured again, and the attack surface is now 10% smaller. Is my project now 10% more secure? You mentioned in your “Small is Beautiful” talk that we should:  Base features on user need Track feature use in beta or production Be willing/able to disable features This is great advice, is this assuming we have zero users consuming a specific feature?  Can you go into a little more depth on this?\n(concrete examples of how you do this?) You also mentioned that all code has risk, and that adding a feature is a trade-off. I’d go much further than this, by saying all features are trade-offs, including physical, people, vps, networks, cloud, mobile and IoT. We need to consider the attack surface of everything.\nCan we apply the previous question and your answer to all of these areas, and if so, how so?  Developers - Current State  Can you explain how you are “significantly reducing the number of people harmed by targeted attacks” when any number of bugs that the Project Zero team identifies appear to be completely swamped by the continual onslaught of Developers continuing to create security defects in just about everything produced?\n(Because you focus on the most heavily used software) There was a post on the NPM blog recently called: “Attitudes to security in the JavaScript community” in which 87% of respondents said they were concerned with the security of the code they wrote themselves, compared to only 77% saying the same about open source. This to me sounds like the wakeup call the security community has been pushing for years is starting to be heard.  What are your thoughts on these statistics, do they sound realistic, are you noticing a similar trend in Developers taking security more seriously? What’s your experience and/or thoughts on where the level of security defects are in JavaScript compared to other languages and their environments?\nWhat are your thoughts on these statistics and how can we continue to improve them?  How do we go about considering the security impact of features at design time? Do we need a Red Teamer as part of the Development Team to help drive out defects before we introduce them?  Code Sharing  You mentioned in your “Small is Beautiful” talk that using the same code for multiple purposes can expose it to new and unnecessary attack vectors. While I believe this to be true, code sharing can be a good thing in terms of productivity. High fan in on pieces of code has been an aim of the Development community for a long time. What are your thoughts on rather than telling Developers not to re-use code, we should be trying to help them create more secure pieces of code that can be consumed? You also mentioned that multiple copies of the same code can be difficult to maintain. I’ve noticed with microservices becoming more popular, this seems to be happening more. Do you have any advice other than pulling the common code out into a separate package and consuming as a library? Can you tell us about the Android WebView issues where several Android features contained their own version of WebView, bugs were fixed in one version but not another, then they unified WebView?  Third-party Code I discuss this in depth in the Web Applications chapter of my book Fascicle 1 of Holistic Info-Sec for Web Developers\n(risks, countermeasures)\n In your “Small is Beautiful” talk, you mention:\n That we should “make sure each attack surface only supports needed features” “Avoid multiple copies of the same library”\n  These are both concepts that the Node Package Management ecosystem at least violates. Developers consume vast numbers of packages, even in small projects, often consuming a package to use only one of many features consumed. Firstly, for our listeners, explain what the problem is here?\n  \n Where is the point where you would write something yourself as opposed to consume? You’ve also mentioned tracking third-party software use and having an internal process for use, which I’ve also discussed in my previously mentioned book. Can you explain how you would do this? As we’re on the topic of third-party code management, can you tell us about the example of CVE-2916-4117, that’s the remote code execution in the FireEye Malware Protection System? Are there tools that you would like to see automated as part of our DevSecOps process that you think would help the third-party code problems? Are smaller packages the answer? If so, do we have the package management systems capable of managing very small packages? I mean, how would discoverability work, it’s hard enough now trying to find the most suitable package out of 10 that all do the same thing right? I’m thinking of your “a puppy is forever slide” in your Small is Beautiful talk\u0026hellip; Currently if we depend on a package that the maintainer isn’t keeping patched, we need to fork and maintain it ourselves. Where do you see this ending up? a) Node Security Project (NSP) was acquired by NPM on April 10\nb) Github is now providing visibility into the dependencies of their users repos and alerting on known security issues if they have a Common Vulnerability Exposure (CVE)\nc) Snyke Provides something similar, but they’ve been doing this for much longer than Github and know of many more issues.  What are your thoughts on how the open source ecosystem is progressing in terms of creating visibility around defective code? How can we do better?   Developer Workflow  In your “Small is Beautiful” talk you mentioned that excessive SKUs and branching:\n Make it harder to push security updates Can introduce bugs Can cause incomplete patching\n  While I think few would disagree with this, a well defined and sometimes elaborate branching scheme is necessary for large groups of Software Engineers all collaborating on the same code base. Can you define excessive in this context?\n  \n Can you talk a bit about CVE-2017-0528, that’s the merge error in Android reducing ASLR bits, what happened with this and what were the lessons that were learnt? Before the show you mentioned you also had some anonymised examples of bugs:  Where a vendor failed to patch a security issue due to a complex branching and build system, and their patches were also taking a long time due to this?  How would you propose minimal SKUs and branches in a large project where say 100 Engineers are working on the same project? You’ve talked a bit about:\n Pruning trees regularly Making sure all code has an owner\n  Can you explain what you mean by this?\n What recommendations do you have for reducing the chances of introducing defects due to branching and merging?\n  Defects  Can you tell us a bit about the Samsung image processing defect (CVE-2015-7894), that’s the one where the very old QJpeg library was added to parse the android splash images, but it was somehow added to the Android image subsystem, so that all images from a low privileged user are parsed? Let’s talk about CVE-2017-3558, that’s the Memory corruption issue in VirtualBox, allowing guest-to-host escalation. You mentioned this was due to old code not being fully removed? It was fixed upstream, but not downstream? Can you talk a bit about this? What could have been done so that this never happened? CVE-2015-7894, that’s the 7 memory corruption issues in Samsung S6 Edge image processing. This was due to old / no longer used code being left in the system? Can you talk a bit about this one?  What could have been done so that this never happened?   You mentioned that the following bugs were in the JavaScript engines, not the language JavaScript:\n Can you tell us about the Array.species bug (CVE-2016-7200), the issue with Array.filter in MS Edge? What was the Array index accessor bug (CVE-2017-2447) in Safari’s Function.bind? What about the TypedArray.sort defect in MS Edge (CVE-2016-7288) You mentioned in one of your talks that standards can lead to security issues, can you explain what you meant by that?  ","date":1531785600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531785600,"objectID":"61dd86883d4480ef0e07c0a45df290ef","permalink":"https://binarymist.io/publication/ser-podcast-attack-surface-reduction/","publishdate":"2018-07-17T00:00:00Z","relpermalink":"/publication/ser-podcast-attack-surface-reduction/","section":"publication","summary":"Natalie Silvanovich from Google Project Zero talks with Kim Carter about what attack surface reduction is about.\n","tags":["publication","podcast","application-security","cybersecurity","javascript","information-security","infosec","security","webassembly","web-security"],"title":"Natalie Silvanovich on Attack Surface Reduction","type":"publication"},{"authors":null,"categories":null,"content":"","date":1527465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527465600,"objectID":"01faff4d7e53d432959083786580f7b2","permalink":"https://binarymist.io/project/external-project-purpleteam/","publishdate":"2018-05-28T00:00:00Z","relpermalink":"/project/external-project-purpleteam/","section":"project","summary":"Automated security regression testing of your web applications and APIs, no setup required.\n1. Write [test conditions](https://f0.holisticinfosecforwebdevelopers.com/chap06.html#process-and-practises-agile-development-and-practices-evil-test-conditions) - convert to [Cucumber](https://cucumber.io/)\n2. Provide minimal configuration\n3. Consume node CLI package\n4. Run single command `purpleteam test`\nPerfect for your CI/nightly build","tags":["project","software","application-security","bdd","ci","continuous-integration","cucumber","cybersecurity","deployment","dev-ops","dev-sec-ops","gherkin","purpleteam","information-security","infosec","javascript","nightly-build","penetration-testing","security","security-regression-testing","selenium","software-security","test-conditions","testing","web","web-application","web-application-security","web-security","zap"],"title":"purpleteam","type":"project"},{"authors":["Kim Carter"],"categories":null,"content":" Following on from last months news of my new Docker Security - Quick Reference book, I bring you Cloud Security - Quick Reference.\nThis book is purposed to help Software Developers/DevOps Engineers, and also the likes of Product Owner and Product Manager types gain a good understanding of the risks and countermeasures when dealing with Cloud Service Providers (CSPs) and your environments within.\nThere are quite a few anecdotes based on my own experience consulting for organisations navigating the perils of the many Cloud environments available today, along with tips, tricks, tools, advice, and implementation details from many client lessons learnt the hard way.\nAlso be sure to have a listen to the show on Cloud Security I recorded with Scott Piper (AWS Cloud Specialist) as guest for Software Engineering Radio.\nThe following is a snapshot of what you can expect inside of the book, laid out in the Sensible Security Model (SSM) threat modelling approach:\n Asset Identification Identify Risks Countermeasures Risks that Solution Causes Costs and Trade-offs  \n   1 Asset Identification      Productivity    Competitive Advantage    Control    Data   2 Identify Risks    Shared Responsibility Model ⭐️    \u0026mdash; CSP Responsibility ⭐️    \u0026mdash; CSP Customer Responsibility ⭐️    CSP Evaluation ⭐️    Cloud Service Provider vs In-house    \u0026mdash; Skills    \u0026mdash; EULA    \u0026mdash; Giving up Secrets    \u0026mdash; Location of Data    \u0026mdash; Vendor lock-in    \u0026mdash; Possible Single Points of Failure    Review Other Chapters    People    Application Security    Network Security    Violations of Least Privilege    \u0026mdash; Machine Instance Single User Root    \u0026mdash; CSP Account Single User Root    Storage of Secrets    \u0026mdash; Private Key Abuse    \u0026mdash;\u0026mdash; SSH ⭐️    \u0026mdash;\u0026mdash; TLS ⭐️    \u0026mdash; Credentials and Other Secrets    \u0026mdash;\u0026mdash; Entered by People (manually)    \u0026mdash;\u0026mdash; Entered by Software (automatically)    Serverless    \u0026mdash; Third Party Services    \u0026mdash; Perimeterless    \u0026mdash; Functions    \u0026mdash; DoS of Lambda Functions    Infrastructure and Configuration Management    AWS    \u0026mdash; Password-less sudo   3 Countermeasures    Shared Responsibility Model    \u0026mdash; CSP Responsibility    \u0026mdash; CSP Customer Responsibility    CSP Evaluation (Includes Answers)    Cloud Service Provider vs In-house    \u0026mdash; Skills    \u0026mdash; EULA    \u0026mdash; Giving up Secrets    \u0026mdash; Location of Data    \u0026mdash; Vendor lock-in    \u0026mdash; Possible Single Points of Failure    Review Other Chapters    People    Application Security    Network Security    Violations of Least Privilege ⭐️    \u0026mdash; Machine Instance Single User Root ⭐️    \u0026mdash; CSP Account Single User Root ⭐️    Storage of Secrets    \u0026mdash; Private Key Abuse    \u0026mdash;\u0026mdash; SSH ⭐️    \u0026mdash;\u0026mdash; TLS ⭐️    \u0026mdash; Credentials and Other Secrets    \u0026mdash;\u0026mdash; Entered by People (manually) ⭐️    \u0026mdash;\u0026mdash; Entered by Software (automatically) ⭐️    Serverless    \u0026mdash; Third Party Services    \u0026mdash; Perimeterless    \u0026mdash; Functions    \u0026mdash; DoS of Lambda Functions    \u0026mdash; Centralised logging of AWS Lambda Functions    \u0026mdash; Frameworks    Infrastructure and Configuration Management    AWS    \u0026mdash; Password-less sudo    \u0026mdash; Additional Tooling ⭐️   4 Risks that Solution Causes    Shared Responsibility Model    CSP Evaluation    Cloud Service Provider vs In-house    People    Application Security    Network Security    Violations of Least Privilege    Storage of Secrets    \u0026mdash; Private Key Abuse    \u0026mdash;\u0026mdash; SSH    \u0026mdash;\u0026mdash; TLS    \u0026mdash; Credentials and Other Secrets    \u0026mdash;\u0026mdash; Entered by People (manually)    \u0026mdash;\u0026mdash; Entered by Software (automatically)    Serverless    \u0026mdash; Functions    \u0026mdash; DoS of Lambda Functions    \u0026mdash; Frameworks    Infrastructure and Configuration Management    AWS    \u0026mdash; Password-less sudo   5 Costs and Trade-offs    Shared Responsibility Model    CSP Evaluation    Cloud Service Provider vs In-house    People    Application Security    Network Security    Violations of Least Privilege ⭐️    Storage of Secrets    \u0026mdash; Private Key Abuse    \u0026mdash;\u0026mdash; SSH    \u0026mdash;\u0026mdash; TLS    \u0026mdash; Credentials and Other Secrets    \u0026mdash;\u0026mdash; Entered by People (manually)    \u0026mdash;\u0026mdash; Entered by Software (automatically)    Serverless    \u0026mdash; Functions    \u0026mdash; DoS of Lambda Functions    \u0026mdash; Frameworks    Infrastructure and Configuration Management    AWS    \u0026mdash; Password-less sudo    \n⭐️ I\u0026rsquo;ve provided a few of the sections from the book below, and linked to from the book contents above. Enjoy 😃\nOh, and for less than the cost of a lunch you can own the complete book\n Own The Book\n\nShared Responsibility Model The shared responsibility model is one that many have not grasped or understood well. Let\u0026rsquo;s look at the responsibilities of the parties involved.\nCSP Responsibility The CSP takes care of the infrastructure, not the customer specific configuration of it. Due to the sheer scale of what they are building, the CSP is often able to build in good security controls, in contrast to the average system administrator, who has limited resources or ability to focus on security to the same degree.\nAgain, due to sheer scale, the average CSP has a concentrated group of good security professionals versus a business who\u0026rsquo;s core focus is often not security related. CSPs provide good security mechanisms, but the customer has to know and care enough to use them.\nCSPs who architect infrastructure, build components, frameworks, hardware, and platform software in most cases take security seriously and are doing a reasonable job.\nCSP Customer Responsibility CSP customers are expected to be responsible for their own security as it pertains to:\n Their people working with the technology Application security, specific to shortcomings in people: lack of skills, experience, engagement, etc. Configuring the infrastructure and/or platform components, again referencing people defects  All too often the customer\u0026rsquo;s responsibility is neglected, which renders the Cloud no better for the customer in terms of security.\n The primary problem with the Cloud is this: customers have the misconception that someone else is taking care of all their security. That is not how the shared responsibility model works though. Yes, the CSP is probably taking care of infrastructure security, but other forms of security as listed above are even more important than before the shift to the Cloud. These items are now the lowest hanging fruit for the attacker.\n The following are a set of questions (verbatim) I have been asked recently, and that I hear similar versions of frequently:\n As a software engineer, do I really care about physical network security and network logging? Surely \u0026ldquo;as a software engineer\u0026rdquo;, I can just use TLS and that is the end of it? If the machine is compromised, do we give up on security because we aren\u0026rsquo;t responsible for the network? What is the difference between application security and network security? Aren\u0026rsquo;t they just two aspects of the same thing? If I have implemented TLS for communication, have I fixed all of the network security problems?  CSP Evaluation CSPs are constantly changing their terms and conditions, as well as many other components and aspects of what they offer. I have compiled a set of must-answer questions to quiz your CSP with as part of your threat modelling before (or even after) you sign their service agreement.\nMost of these questions were already part of my Cloud vs In-house talk at the Saturn Architects conference I spoke at. I recommend using these as a basis for identifying risks that are important for you to consider. This should make you well armed to come up with countermeasures and think of any additional risks.\n Do you keep a signed audit log of what actions users performed, and when, via UIs and APIs?\nBoth authorised and unauthorised users are more careful about the actions they take, or do not take, when they know their actions are being recorded and are potentially being watched\n How do you enact the shared responsibility model between CSPs and their customers? Please explain your role and my role in the protection of my and my customers data.\nYou will almost certainly not have complete control over the data you entrust to your CSP, but they will also not assume responsibility over the data you entrust to them, or how it is accessed. One example of this might be, how do you preserve secrecy for data at rest? For example, are you using the most suitable Key Derivation Function (KDF) as I discuss in depth in the Web Applications chapter of Holistic Info-Sec for Web Developers, Fascicle 1 and adjusting the number of iterations applied each year (as discussed in the MembershipReboot subsection of the Web Applications chapter of Holistic Info-Sec for Web Developers Fascicle 1) to the secrets stored in your data stores? The data you hand over to your CSP is no more secure than I discuss in the Management of Application Secrets subsections of the Web Applications chapter of Holistic Info-Sec for Web Developers Fascicle 1, and in many cases has the potential to be less secure for some of the following reasons:\n An often encountered false assumption is that somehow the data you provide is safer by default on your CSP\u0026rsquo;s network Your CSP can be forced by governing authorities to give up the data you entrust to them, as we discuss in the Giving up Secrets subsection\n  Do you encrypt all communications between servers within your data centres as well as your service providers?\nHow is your data encrypted in transit (as discussed in the Management of Application Secrets subsections of the Web Applications chapter)? In reality, you have no idea what paths it will take once in your CSPs possession, and could very well be intercepted without your knowledge.\n You have little to no control over the network path that the data you provide will travel on There are more parties involved in your CSPs infrastructure than on your own network\n  Do you provide access to logs, if so, what sort of access, and to what sort of logs?\nHopefully you will have easy access to any and all logs, just as you would if it was your own network. That includes hosts, routing, firewall, and any other service logs\n What is your process around terminating my contract with you and/or moving to another CSP?\nNo CSP is going to last forever, termination or migration is inevitable, it is just a matter of when\n Where do your servers, processes and data reside physically?\nAs we discuss a little later in the Cloud Services Provider vs In-house subsection of Countermeasures, your data is governed by different people and jurisdictions depending on where it physically resides. CSPs have data centres in different countries and jurisdictions, each having different data security laws\n Who can view the data I store in the Cloud?\nWho has access to view this data? What checks and controls are in place to make sure that this data cannot be exfiltrated?\n What is your Service Level Agreement (SLA) for uptime?\nMake sure you are aware of what the uptime promises mean in terms of real time. Some CSPs will allow 99.95% uptime if you are running on a single availability zone, but closer to 100% if you run on multiple availability zones. Some CSPs do not have a SLA at all.\nCSPs will often provide credits for the downtime, but these credits in many cases may not cover the losses you encounter during high traffic events\n Are you ISO/IEC 27001:2013 Certified? If so, what is within its scope?\nIf the CSP can answer this with a \u0026ldquo;everything\u0026rdquo; and prove it, they have done a lot of work to make this possible. This shows a certain level of commitment to their security posture. Just be aware, as with any certification, it is just that, it doesn\u0026rsquo;t necessarily prove sound security\n Do you allow your customers to carry out regular penetration testing of production and/or test environments, and allow the network to be in-scope?\nCSPs that allow penetration testing of their environments demonstrate that they embrace transparency and openness. If their networks stand up to penetration tests they obviously take security seriously. Ideally, this is what you are looking for. CSPs that do not permit penetration testing of their environments are usually trying to hide something. It may be that they know they have major insecurities, or a skills shortage in terms of security professionals. Worse, they may be unaware of where their security stature lies and are not willing to have their faults demonstrated\n Do you have bug bounty programmes running, if so, what do they look like?\nThis is another example if their programme is run well, it conveys that the CSP is open and transparent about their security faults and are willing to mitigate them as soon as possible\n  \u0026nbsp;\nSSH SSH key-pair auth is no better than password auth if it is abused in the following way, in-fact it may even be worse. I have seen some organisations who store a single private key with no pass-phrase for all of their EC2 instances in their developer wiki. All or many of the developers have access to this, with the idea being that they just copy the key from the wiki to their local ~/.ssh/. There are a number of things wrong with this.\n Private key is not private if it is shared amongst the team No pass-phrase, means no second factor of authentication Because there is only one user (single key-pair) being used on the VPSs, there is also no audit trail The weakest link is the weakest wiki password of all the developers, and we all know how weak that is likely to be, with a bit of reconnaissance, probably guessable in a few attempts without any password profiling tools. I have discussed this and demonstrated a collection of password profiling tools in the \u0026ldquo;Weak Password Strategies\u0026rdquo; subsection of the People chapter of Fascicle 0. Once the attacker has the weakest password, then they own all of the EC2 (if on AWS) instances, or any resource that is using key-pair authentication. If the organisation is failing this badly, then they almost certainly will not have any password complexity constraints on their wiki either  Most developers will also blindly accept what they think are the server key fingerprints without verifying them, which opens them up to a MItM attack, as discussed in the VPS chapter under the SSH subsection. This quickly moves from just being a technical issue to a cultural one, where people are trained to accept that the server is who it says it is. The fact that they have to verify the fingerprint is essentially a step that gets in their way.\nTLS When Docker reads the instructions in the following Dockerfile, an image is created that copies your certificate, private key, and any other secrets you have declared, and adds them to an additional layer and forms the resulting image. Both COPY and ADD will bake what ever you are copying or adding into an additional layer or delta, as discussed in the Consumption from Registries subsection in my Docker Security book. Whoever can access this image from a public or less public registry now has access to your certificate and even worse your private key.\nAnyone can see how these images were built using the following tools:\n dockerfile-from-image ImageLayers  The ENV command similarly adds the dirty little secret value as the mySecret key into the image layer.\nPrivate key abuse with Dockerfile FROM nginx # ... COPY /host-path/star.mydomain.com.cert /etc/nginx/certs/my.cert COPY /host-path/star.mydomain.com.key /etc/nginx/certs/my.key ENV mySecret=\u0026#34;dirty little secret\u0026#34; COPY /host-path/nginx.conf /etc/nginx/nginx.conf # ... \u0026nbsp;\nViolations of Least Privilege When you create IAM policies, grant only the permissions required to perform the task(s) necessary for given users. If the user needs additional permissions, then they can be added, rather than adding everything up front and potentially having to remove again at some stage. Adding as required, rather than removing as required, will cause much less friction technically and socially.\nFor example, in AWS, you need to keep a close watch on which permissions are assigned to policies that your groups and roles have applied, and subsequently, which groups and roles your users are in or part of.\nThis is the recommended sequence for granting least privilege in AWS, other CSPs will be similar:\n First, work out which permissions a given user requires Create or select an existing group or role Attach policy to the group or role that has the permissions that your given user requires. You can select existing policies or create new ones Add the given user to the group or role  Regularly review all of the IAM policies you are using, making sure only the required permissions (Services, Access Levels, and Resources) are available to the users and/or groups attached to the specific policies.\nEnable Multi Factor Authentication (MFA) on the root user, and all IAM users with console access, especially privileged users at a minimum. AWS provides the ability to mandate that users use MFA, you can do this by creating a new managed policy based on the AWS guidance to Enable Your Users to Configure Their Own Credentials and MFA Settings. Attach the new policy to a group that you have created and add users that must use MFA to that group.\nThis process was pointed out to me by Scott Piper during our Cloud Security interview by way of his blog post and generous Github pull request.\nThe Access Advisor tab, is visible on the IAM console details page for Users, Groups, Roles, or Policies after you select a list item. This provides information about which services are accessible for any of your users, groups, or roles. This can also be helpful for auditing permissions that should not be available to any of your users who are part of the group, role or policy you selected.\nThe IAM Policy Simulator is accessible from the IAM console. This is good for granular reporting on the permissions of your specific Users, Groups and Roles, filtered by service and actions.\nAWS Trusted Advisor should be run periodically to check for security issues. It is accessible from the Console, CLI and API. Trusted Advisor has a collection of core checks and recommendations which are free to use. These include security groups, specific ports unrestricted, IAM use, MFA on root user, EBS and RDS public snapshots.\n Running services as root: Make sure that Docker containers are not running under the root account. There are full details in my Docker Security book Configuration Settings Changed Ad Hoc: One option is to have solid change control in place. AWS Config can assist with this. AWS Config continuously monitors and records how the AWS resources were configured and how they have changed, including how they are related to each other. This enables you to assess, audit, and evaluate the configurations of your AWS resources, and have notifications sent to you when AWS Config detects a violation, including created, modified or deleted rules changes.\nAWS Config records IAM policies assigned to users, groups, or roles, and EC2 security groups, including port rules. Changes to your configuration settings can trigger Amazon Simple Notification Service (SNS) notifications, which you can have sent to your personnel tasked with controlling changes to your configurations.\nYour custom rules can be codified and therefore source controlled. AWS calls this Compliance as Code. I discussed AWS CloudTrail briefly in item 1 of the CSP Evaluation countermeasures subsection. AWS Config is integrated with CloudTrail, which captures all API calls from AWS Config console or API, SDKs, CLI tools, and other AWS services. The information collected by CloudTrail provides insight on what request was made, from which IP address, by who, and when\n Machine Instance Access To Open: Reduce your attack surface by disabling access to your machine instances from any source IP address\n  There are also a collection of IAM specific items that you should review in the Identity and Access Management subsection of the CIS AWS Foundations document.\nMachine Instance Single User Root As part of the VPS and container builds, there should be specific users created for specific jobs, every user within your organisation that needs VPS access should have their own user account on every VPS, including SSH access if required (ideally this should be automated). With Docker, I discussed how this is done in the Dockerfile in my Docker Security book and blog post.\nDrive a least privilege policy around this, configuring a strong password policy for your users, and implement multi-factor authentication, which will help with poor password selection. I discuss this in more depth in the Storage of Secrets subsection.\nCSP Account Single User Root As I discuss in the Credentials and Other Secrets Countermeasures subsection of this chapter, create multiple accounts with least privileges required for each; the root user should hardly ever be used. Create groups and attach restricted policies to them, then add the specific users to them.\nAlso as discussed in the Credentials and Other Secrets countermeasures subsection, there should be almost no reason to generate key(s) for the AWS Command Line Tools for the AWS account root user. But if you do, consider setting up notifications for when they are used. As usual, AWS has plenty of documentation on the topic.\nAnother idea is to set-up monitoring and notifications on activity of your AWS account root user. AWS documentation explains how to do this.\nThere are also a collection of monitoring specific items that you should review in the Monitoring subsection of the CIS AWS Foundations document.\nAnother great idea is to generate an AWS key Canarytoken from canarytokens.org, and put it somewhere more obvious than your real AWS key(s). When someone uses it, you will be automatically notified. I discussed these with Haroon Meer on the Software Engineering Radio Network Security podcast. Jay also wrote a blog post on the thinkst blog on how you can set this up, and what the inner workings look like.\nAlso consider rotating your IAM access keys for your CSP services. AWS EC2, for example, provides auto-expire, auto-renew access keys when using roles.\n\u0026nbsp;\nSSH There are many ways to harden SSH as we discussed in the SSH subsection of the VPS chapter of Holistic Info-Sec for Web Developers, Fascicle 1. Usually the issue will be specific to lack of knowledge, desire and a dysfunctional culture in the work place. You will need to address the people issues before looking at basic SSH hardening techniques.\nIdeally, SSH access should be reduced to a selected few. Most of the work we do now by SSHing should be automated. If you review the commands in history on most VPSs, the majority of the commands are either deployment or monitoring which should all be automated.\nWhen you create an AWS EC2 instance you can create a key pair using EC2 or you can provide your own. Either way, to be able to log-in to your instance, you need to have provided EC2 with the public key of your key pair and specified it by name.\nEvery user should have their own key-pair, the private part should always be private, kept in the users local ~/.ssh/ directory (not the server) with permissions 600 or more restrictive, and not shared on your developer wiki, or anywhere else for that matter. The public part can be put on every server that the user needs access to. There is no excuse for users not to have their own key pair, you can have up to five thousand key pairs per AWS region. AWS has clear directions on how to create additional users and provide SSH access with their own key pairs.\nFor generic confirmation of the host\u0026rsquo;s SSH key fingerprint when prompted before establishing the SSH connection, follow the procedure I laid out for Establishing your SSH Servers Key Fingerprint in the VPS chapter of Holistic Info-Sec for Web Developers, Fascicle 1, and make it organisational policy. We should never blindly accept key fingerprints. The key fingerprints should be stored in a relatively secure place, so that only trusted parties can modify them. I would like to see, as part of the server creation process, the entity (probably the wiki) that specifies the key fingerprints is automatically updated by something on the VPS that keeps watch of the key fingerprints. Something like Monit, would be capable of the monitoring and executing a script to do this.\nTo SSH to an EC2 instance, you will have to view the console output of the keys being generated. You can see this only for the first run of the instance when it is being created, this can be seen by first fetching https://console.aws.amazon.com, then:\n Click the \u0026ldquo;EC2\u0026rdquo; link Click \u0026ldquo;Instances\u0026rdquo; in the left column Click the instance name you want Click the select button \u0026ldquo;Actions\u0026rdquo; and choose \u0026ldquo;Get System Log\u0026rdquo; (a.k.a. \u0026ldquo;Console Output\u0026rdquo;) In the console output, you should see the keys being generated. Record them  Then, to SSH to your EC2 instance, the command to use can be seen by fetching\nhttps://console.aws.amazon.com, then:\n EC2 Instances Select your instance Click the Connect button for details  TLS So, how do we stop baking secrets into our Docker images?\nThe easiest way is to avoid adding secrets to the process of building your images. You can add them at run time in several ways. If you have a look at Namespaces in my Docker Security book, also discussed in my Docker Security blog post, we used volumes. This allows us to keep the secrets entirely out of the image and only include in the container as mounted host directories, rather than adding those secrets to the Dockerfile:\nMitigate private key abuse via terminal docker run -d -p 443:443 -v /host-path/star.mydomain.com.cert:/etc/nginx/certs/my.cert -v /host-path/star.mydomain.com.key:/etc/nginx/certs/my.key -e \u0026#34;mySecret=dirty little secret\u0026#34; nginx An even easier technique is to just implement adding of secrets in the docker-compose.yml file, thus saving time when you run the container:\nMitigate private key abuse using docker-compose.yml nginx: build: . ports: - \u0026#34;443:443\u0026#34; volumes: - /host-path/star.mydomain.com.key:/etc/nginx/ssl/nginx.key - /host-path/star.mydomain.com.cert:/etc/nginx/ssl/nginx.crt - /host-path/nginx.conf:/etc/nginx/nginx.conf env_file: - /host-path/secrets.env Using the env_file we can hide our environment variables in the .env file.\nOur Dockerfile would now look like the following, even our config is volume mounted and will no longer reside in our image:\nMitigate private key abuse using Dockerfile FROM nginx # ... # ... \u0026nbsp;\nEntered by People (manually) Protecting against outsiders\nThe most effective alternative to storing user-names and passwords in an insecure manner is to use a group or team password manager. There are quite a few offerings available with all sorts of different attributes. The following are some of the points you will need to consider as part of your selection process:\n Cost in terms of money Cost in terms of set-up and maintenance Closed or open source. If you care about security, which you must if you are considering a team password manager, it is important to see how secrets are handled. I need to be able to see how the code is written, and which Key Derivation Functions (KDFs) and cyphers are used. If it is of high quality, we can have more confidence that our precious sensitive pieces of information are, in fact, going to be private Do you need a web client? Do you need a mobile client (iOS, Android)? What platforms does it need to support? Does it need to be able to manage secrets of multiple customers? Auditing of user actions? Who is accessing and changing what? Ability to be able to lock out users, when they leave the organisation, for example? Multi-factor authentication Options: Does it have all the features you need? Who is behind the offering? Are they well known for creating solid, reliable, secure solutions?  The following are my personal top three, with the first being my preference, based on research I performed for one of my customers recently. All the points above were considered for a collection of about ten team password managers that I reviewed:\n Pleasant Password Server (KeePass backed) Password Manager Pro LastPass  Protecting against insiders\nThe above alone is not going to stop an account take over if you are sharing the likes of the AWS account root user email and password, even if it is in a group password manager. As AWS has already stated, only use the root user for what is absolutely essential (remember: least privilege). This is usually just to create an Administrators group to which you attach the AdministratorAccess managed policy, then add any new IAM users to that group who require administrative access.\nOnce you have created IAM users within an Administrators group as mentioned above, these users should set up groups to which you attach further restricted managed policies such as a group for PowerUserAccess, a group for ReadOnlyAccess, a group for IAMFullAccess, progressively becoming more restrictive. Use the most restrictive group possible in order to achieve specific tasks, simply assigning users to the groups you have created.\nBe sure to use multi-factor authentication.\n\u0026nbsp;\nYour AWS users are not assigned access keys to use for programmatic access by default, do not create these unless you actually need them, and again consider least privilege. There should be almost no reason to create an access key for the root user.\nConfigure strong password policies for your users, make sure they are using personal password managers and know how to generate long complex passwords.\nEntered by Software (automatically) There are many places in software that require access to secrets, to communicate with services, APIs, datastores. Configuration and infrastructure management systems have a problem storing and accessing these secrets in a secure manner.\nHashiCorp Vault. The most fully featured of these tools, has the following attributes/features:\n Open Source written in Go-Lang Deployable to any environment, including development machines Arbitrary key/value secrets can be stored of any type of data Supports cryptographic operations of the secrets Supports dynamic secrets, generating credentials on-demand for fine-grained security controls Auditing: Vault forces a mandatory lease contract with clients, which allows the rolling of keys, automatic revocation, along with multiple revocation mechanisms providing operators a break-glass for security incidents Non-repudiation Secrets protected in transit and at rest Not coupled to any specific configuration or infrastructure management system Can read secrets from configuration, infrastructure management systems and applications via its API Applications can query Vault for secrets to connect to services such as datastores, thus removing the need for these secrets to reside in configuration files (See the Risks that Solution Causes for the caveat) Requires multiple keys generally distributed to multiple individuals to read its encrypted secrets Check the Secret Backends for integrations  Docker secrets\n Manages any sensitive data (including generic string or binary content up to 500 kb in size) that a container needs at runtime, but you do not want to store in the image, source control, or the host systems file-system as we did in the TLS section above Only available to Docker containers managed by Swarm (services). Swarm manages the secrets Secrets are stored in the Raft log, which is encrypted if using Docker 1.13 and higher Any given secret is only accessibly to services (Swarm managed container) that have been granted explicit access to the secret Secrets are decrypted and mounted into the container in an in-memory filesystem which defaults to /run/secrets/\u0026lt;secret_name\u0026gt; in Linux, C:\\ProgramData\\Docker\\secrets in Windows  Ansible Vault\nAnsible is an Open Source configuration management tool, and has a simple secrets management feature.\n Ansible tasks and handlers can be encrypted Arbitrary files, including binary data can be encrypted From version 2.3 can encrypt single values inside YAML files Suggested workflow is to check the encrypted files into source control for auditing purposes  AWS Key Management Service (KMS)\n Encrypt up to 4 KB of arbitrary data (passwords, keys) Supports cryptographic operations of the secrets: encrypt and decrypt Uses Hardware Security Modules (HSM) Integrated with AWS CloudTrail to provide auditing of all key usage AWS managed service Create, import and rotate keys Usage via AWS Management Console, SDK and CLI  AWS offers Parameter Store\n Centralised store on AWS to manage configuration data, plain text, or encrypted secrets via AWS KMS All calls to the parameter store are recorded with AWS CloudTrail, supports access controls.  Also see the Additional Resources section for other similar tools and resources.\n\u0026nbsp;\nAdditional Tooling  Security Monkey: Monitors AWS and GCP accounts for policy changes, and alerts on insecure configurations, conceptually similar to AWS Config, as discussed in the Violations of Least Privilege countermeasures subsection. Security Monkey is free and open source. Although not strictly security related, the Simian Army tools from Netflix are also well worth mentioning if you are serious about doing things the right way in AWS. They include:  Chaos Monkey Janitor Monkey Conformity Monkey  CloudSploit: Aims to solve the problem of misconfigured AWS accounts with background scanning through hundreds of resources, settings, and activity logs looking for potential issues. Their blog also has some good resources on it. Scan reports include in-depth remediation steps. Has a free and paid hosted tiers. Auto scanning scheduling for the paid plans. Is open source on github Amazon Inspector: At this time only targets EC2 instances. Inspector agent needs to be installed on all target EC2 instances CloudMapper by Scott Piper for visualising your AWS environments. Along with his blog post at duo.com Awesome AWS has many useful resources  \u0026nbsp;\nViolations of Least Privilege It is worth investing the effort to make sure only the required user permissions are granted. As discussed, there are tools you can use to help speed this process up and make it more accurate.\n Running services as root: Always start with the minimum permissions possible and add if necessary, it is far easier to add than to remove Configuration Settings Changed Ad Hoc: Remember detection works where prevention fails. Where your change control fails, because it is decided not to use it, you need something to detect changes and notify someone who cares. For this, there are also other options specifically designed to perform this function. For a collection of such tools, review the Tooling sections.\nYou need to have these tools set up so that they are continually auditing your infrastructure and notifying the person(s) responsible for issues resolution, rather than having people continually manually reviewing settings, permissions, and so forth\n Machine Instance Access To Open: Set-up a bastion host and lock the source IP address down to the public facing IP address of your bastion host required to access your machine instances. I discussed locking the source IP address down in the Hardening SSH subsection of the VPS chapter of Holistic Info-Sec for Web Developers, Fascicle 1.\nYour bastion host will be hardened as discussed throughout the VPS chapter. All authorised workers can VPN to the bastion host and SSH from there, or just SSH tunnel from wherever they are through the bastion host via port forwarding to any given machine instances.\nIf you have Windows boxes you need to reach, you can tunnel RDP through your SSH tunnel, see my blog post about this.\nRather than tunnelling, another option SSH gives us (using the -A option) is to hop from the bastion host to your machine instances by forwarding the private key. This does include the risk that someone could gain access to your forwarded SSH agent connection, thus being able to use your private key while you have an SSH connection established. ssh-add -c can provide some protection with this.\nIf you do decide to use the -A option, then you are essentially considering your bastion host as a trusted machine. I commented on the -A option in the Tunnelling SSH subsection of the VPS chapter of Holistic Info-Sec for Web Developers, Fascicle 1. There is plenty of good documentation on setting up the bastion host in AWS. AWS provides some Best Practices for security on bastion hosts, and also discusses recording the SSH sessions that your users establish through a bastion host for auditing purposes\n  If you\u0026rsquo;re invested in the Cloud, and let\u0026rsquo;s face it, who isn\u0026rsquo;t now days, this book will provide visibility into what you may currently be doing wrong and how to secure your Cloud environments.\n Get The Full Book\nAt this stage, it\u0026rsquo;s only $12 NZ, do not procrastinate with your organisations assets at risk, get your self a copy now.\n\nAs always, let me know if there\u0026rsquo;s anything you don\u0026rsquo;t understand, or submit a pull request or open an issue if you find any errors. 😃\nAdditional Resources  My latest podcast for Software Engineering Radio was with guest \u0026ldquo;Head of Cryptography Engineering at Tresorit, Péter Budai\u0026rdquo; on End to End Encryption.\nNext up for guests on my interview schedule is Natalie Silvanovich of the Google Project Zero team on the topic of Attack Surface Reduction. This should be released in a couple of months. Keep your eye on my Publications if this interests you, or even leave a comment below and I\u0026rsquo;ll let you know when it\u0026rsquo;s available.\n  The following are the additional resources in the Cloud Security book.\nInterview I hosted with Scott Piper on Cloud Security\nhttps://binarymist.io/publication/ser-podcast-cloud-security/\nSecrets out of Docker images\nhttps://www.ctl.io/developers/blog/post/tutorial-protecting-sensitive-info-docker\nDarkreading: 10 Password Managers For Business Use\nhttps://www.darkreading.com/endpoint/10-password-managers-for-business-use/d/d-id/1322326\nUsing Vault with MySQL\nhttps://dzone.com/articles/using-vault-with-mysql\nInfrastructure Secret Management Overview\nhttps://gist.github.com/binarymist/66206419df712bd738c3d664542157d8\nForked from maxvt.\nSecrets Management show on Software Engineering Radio\nhttp://www.se-radio.net/2017/12/se-radio-episode-311-armon-dadgar-on-secrets-management/\nflaws.cloud AWS CTF by Scott Piper\nhttp://flaws.cloud/\n","date":1524830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524830400,"objectID":"720c5cb461e19b7f9f0b21a92e225656","permalink":"https://binarymist.io/blog/2018/04/28/cloud-security/","publishdate":"2018-04-28T00:00:00+12:00","relpermalink":"/blog/2018/04/28/cloud-security/","section":"post","summary":"Discussion about Kim's new book on Cloud Security, some of the content, and links to other useful resources around securing your Cloud environments.\n","tags":["application-security","book","cloud","cloud-security","cybersecurity","dev-ops","dev-sec-ops","information-security","infosec","networking","network-security","security","security-weaknesses","serverless","software-security"],"title":"Cloud Security","type":"post"},{"authors":["Kim Carter"],"categories":null,"content":" The book also covers:\n Techniques and tools for storing and accessing secrets in the Cloud securely Risks and countermeasures of serverless offerings Infrastructure and configuration management techniques and tools An interview with Scott Piper (AWS security specialist) Many other tips, tricks and tools  \nPlease note that the entire content of this book is included in The Cloud chapter of Holistic InfoSec for Web Developers F1.\n\nErrata (errors, typos, etc.)  Submit an issue Open issues Closed issues  ","date":1522627200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522627200,"objectID":"e37de7297505955fc8fc04c47006114b","permalink":"https://binarymist.io/publication/cloud-security/","publishdate":"2018-04-02T00:00:00Z","relpermalink":"/publication/cloud-security/","section":"publication","summary":"Are you looking to achieve a good understanding of your responsibilities as well as your CSPs responsibilities to make sure your security stature in the Cloud is where you need it to be? Do you need the technical direction required to create your secure Cloud environment? You can think of this book as your technical Cloud consultant.\n","tags":["publication","book","application-security","cloud","cloud-security","cybersecurity","dev-ops","dev-sec-ops","information-security","infosec","networking","network-security","security","security-weaknesses","serverless","software-security"],"title":"Cloud Security - Quick Reference","type":"publication"},{"authors":["Kim Carter"],"categories":null,"content":" If you are a Software Developer/DevOps Engineer working with Docker, and are one of those types that take their profession seriously (hint: most people that call themselves Engineers do), believe that if a job is worth doing, it\u0026rsquo;s worth doing well, take quality, good design, and security seriously, then I may have just the book you\u0026rsquo;ve been looking for. 😌\nI recently released a book on Docker Security, which addresses many of the concerns with the default level of security around Docker and Docker deployments. The book is purposed to help Software Developers/DevOps Engineers address these concerns quickly. The following is a snapshot of what\u0026rsquo;s included in the book:\n\n   1 Habitat      Consumption from Registries    Doppelganger images    The Default User is Root ⭐️   2 Hardening Docker Host, Engine and Containers ⭐️    Haskell Dockerfile Linter    Lynis    Docker Bench    CoreOS Clair    Banyanops collector    Anchore    TwistLock ⭐️    Possible contenders to watch    Namespaces (Risks) ⭐️    Namespaces (Countermeasures ⭐️)    Control Groups (Risks)    Control Groups (Countermeasures)    Capabilities (Risks)    Capabilities (Countermeasures)    Linux Security Modules (Risks)    Linux Security Modules (Countermeasures)    SecComp (Risks)    SecComp (Countermeasures)    Read-only Containers ⭐️   3 runC and Where it Fits in  ⭐️    Using runC Standalone   4 Application Security    Additional Resources ⭐️    \n⭐️ I\u0026rsquo;ve provided a few of the sections from the book below, and linked to from the book contents above. Enjoy 😃\nOh, and for less than the cost of a lunch you can own the complete book\n Own The Book\n\nThe Default User is Root What is worse, Docker\u0026rsquo;s default is to run containers, and all commands / processes within a container as root. This can be seen by running the following command from the CIS_Docker_1.13.0_Benchmark:\nQuery User running containers docker ps --quiet | xargs docker inspect --format \u0026#39;{{ .Id }}: User={{ .Config.User }}\u0026#39; If you have two containers running, and the user has not been specified, you will see something like the below, which means your two containers are running as root.\nResult of user running containers output \u0026lt;container n Id\u0026gt;: User= \u0026lt;container n+1 Id\u0026gt;: User= Images derived from other images inherit the same user defined in the parent image explicitly or implicitly, so unless the image creator has specifically defined a non-root user, the user will default to root. That means all processes within the container will run as root.\nIn order to run containers as a non-root user, the user needs to be added in the base image (Dockerfile) if it is under your control, and set before any commands you want run as a non-root user. Here is an example of the NodeGoat image:\nNodeGoat Dockerfile 1FROM node:4.4 2 3# Create an environment variable in our image for the non-root user we want to use. 4ENV user nodegoat_docker 5ENV workdir /usr/src/app/ 6 7# Home is required for npm install. System account with no ability to login to shell 8RUN useradd --create-home --system --shell /bin/false $user 9 10RUN mkdir --parents $workdir 11WORKDIR $workdir 12COPY package.json $workdir 13 14# chown is required by npm install as a non-root user. 15RUN chown $user:$user --recursive $workdir 16# Then all further actions including running the containers should 17# be done under non-root user, unless root is actually required. 18USER $user 19 20RUN npm install 21COPY . $workdir 22 23# Permissions need to be reapplied, due to how docker applies root to new files. 24USER root 25RUN chown $user:$user --recursive $workdir 26RUN chmod --recursive o-wrx $workdir 27 28RUN ls -liah 29RUN ls ../ -liah 30USER $user As you can see on line 4 we create our nodegoat_docker user.\nOn line 8 we add our non-root user to the image with no ability to login.\nOn line 15 we change the ownership of the $workdir so our non-root user has access to do the things that we normally have permissions to do without root, such as installing npm packages and copying files, as we see on line 20 and 21. But first we need to switch to our non-root user on line 18. On lines 25 and 26 we need to reapply ownership and permissions due to the fact that docker does not COPY according to the user you are set to run commands as.\nWithout reapplying the ownership and permissions of the non-root user as seen above on lines 25 and 26, the container directory listings would look like this:\nNo reapplication of ownership and permissions Step 12 : RUN ls -liah ---\u0026gt; Running in f8692fc32cc7 total 116K 13 drwxr-xr-x 9 nodegoat_docker nodegoat_docker 4.0K Sep 13 09:00 . 12 drwxr-xr-x 7 root root 4.0K Sep 13 09:00 .. 65 drwxr-xr-x 8 root root 4.0K Sep 13 08:59 .git 53 -rw-r--r-- 1 root root 178 Sep 12 04:22 .gitignore 69 -rw-r--r-- 1 root root 1.9K Nov 21 2015 .jshintrc 61 -rw-r--r-- 1 root root 55 Nov 21 2015 .nodemonignore 58 -rw-r--r-- 1 root root 715 Sep 13 08:59 Dockerfile 55 -rw-r--r-- 1 root root 6.6K Sep 12 04:16 Gruntfile.js 60 -rw-r--r-- 1 root root 11K Nov 21 2015 LICENSE 68 -rw-r--r-- 1 root root 48 Nov 21 2015 Procfile 64 -rw-r--r-- 1 root root 5.6K Sep 12 04:22 README.md 56 drwxr-xr-x 6 root root 4.0K Nov 21 2015 app 66 -rw-r--r-- 1 root root 527 Nov 15 2015 app.json 54 drwxr-xr-x 3 root root 4.0K May 16 11:41 artifacts 62 drwxr-xr-x 3 root root 4.0K Nov 21 2015 config 57 -rw-r--r-- 1 root root 244 Sep 13 04:51 docker-compose.yml 67 drwxr-xr-x 498 root root 20K Sep 12 03:50 node_modules 63 -rw-r--r-- 1 root root 1.4K Sep 12 04:22 package.json 52 -rw-r--r-- 1 root root 4.6K Sep 12 04:01 server.js 59 drwxr-xr-x 4 root root 4.0K Nov 21 2015 test ---\u0026gt; ad42366b24d7 Removing intermediate container f8692fc32cc7 Step 13 : RUN ls ../ -liah ---\u0026gt; Running in 4074cc02dd1d total 12K 12 drwxr-xr-x 7 root root 4.0K Sep 13 09:00 . 11 drwxr-xr-x 32 root root 4.0K Sep 13 09:00 .. 13 drwxr-xr-x 9 nodegoat_docker nodegoat_docker 4.0K Sep 13 09:00 app With reapplication of the ownership and permissions of the non-root user, as the Dockerfile is currently above, the container directory listings look like the following:\nWith reapplication of ownership and permissions Step 15 : RUN ls -liah ---\u0026gt; Running in 8662e1657d0f total 116K 13 drwxr-x--- 21 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 . 12 drwxr-xr-x 9 root root 4.0K Sep 13 08:51 .. 65 drwxr-x--- 20 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 .git 53 -rw-r----- 1 nodegoat_docker nodegoat_docker 178 Sep 12 04:22 .gitignore 69 -rw-r----- 1 nodegoat_docker nodegoat_docker 1.9K Nov 21 2015 .jshintrc 61 -rw-r----- 1 nodegoat_docker nodegoat_docker 55 Nov 21 2015 .nodemonignore 58 -rw-r----- 1 nodegoat_docker nodegoat_docker 884 Sep 13 08:46 Dockerfile 55 -rw-r----- 1 nodegoat_docker nodegoat_docker 6.6K Sep 12 04:16 Gruntfile.js 60 -rw-r----- 1 nodegoat_docker nodegoat_docker 11K Nov 21 2015 LICENSE 68 -rw-r----- 1 nodegoat_docker nodegoat_docker 48 Nov 21 2015 Procfile 64 -rw-r----- 1 nodegoat_docker nodegoat_docker 5.6K Sep 12 04:22 README.md 56 drwxr-x--- 14 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 app 66 -rw-r----- 1 nodegoat_docker nodegoat_docker 527 Nov 15 2015 app.json 54 drwxr-x--- 5 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 artifacts 62 drwxr-x--- 5 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 config 57 -rw-r----- 1 nodegoat_docker nodegoat_docker 244 Sep 13 04:51 docker-compose.yml 67 drwxr-x--- 1428 nodegoat_docker nodegoat_docker 20K Sep 13 08:51 node_modules 63 -rw-r----- 1 nodegoat_docker nodegoat_docker 1.4K Sep 12 04:22 package.json 52 -rw-r----- 1 nodegoat_docker nodegoat_docker 4.6K Sep 12 04:01 server.js 59 drwxr-x--- 8 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 test ---\u0026gt; b88d816315b1 Removing intermediate container 8662e1657d0f Step 16 : RUN ls ../ -liah ---\u0026gt; Running in 0ee2dcc889a6 total 12K 12 drwxr-xr-x 9 root root 4.0K Sep 13 08:51 . 11 drwxr-xr-x 34 root root 4.0K Sep 13 08:51 .. 13 drwxr-x--- 21 nodegoat_docker nodegoat_docker 4.0K Sep 13 08:51 app An alternative to setting the non-root user in the Dockerfile is to set it in the docker-compose.yml, provided that the non-root user has been added to the image in the Dockerfile. In the case of NodeGoat, the mongo Dockerfile is maintained by DockerHub, and it adds a user called mongodb. In the NodeGoat projects docker-compose.yml, we just need to set the user, as seen on line 13 below:\nNodeGoat docker-compose.yml 1 version: \u0026#34;2.0\u0026#34; 2 3 services: 4 web: 5 build: . 6 command: bash -c \u0026#34;node artifacts/db-reset.js \u0026amp;\u0026amp; npm start\u0026#34; 7 ports: 8 - \u0026#34;4000:4000\u0026#34; 9 links: 10 - mongo 11 mongo: 12 image: mongo:latest 13 user: mongodb 14 expose: 15 - \u0026#34;27017\u0026#34; Alternatively, a container may be run as a non-root user by running the following command:\ndocker run -it --user lowprivuser myimage but this is not ideal, the specific user should usually be part of the build.\nHardening Docker Host, Engine and Containers Considering that these processes run as root, and have indirect access to most of the Linux Kernel (20+ million lines of code written by humans) APIs, such as networking, USB, storage stacks, and others via System calls, the situation may look bleak.\nSystem calls are how programmes access the kernel to perform tasks. This attack surface is huge, and all before any security is added on top in the form of LXC, libcontainer (now opencontainers/runc), or Linux Security Modules (LSM) such as AppArmor or SELinux. These are often seen as an annoyance and just disabled like many other forms of security.\nIf you run a container, you may have to install kmod, then run lsmod in the container, and also on the host system. You will see that the same modules are loaded, this is because as mentioned, the container shares the host kernel, so there is not a lot between processes within the container and the host kernel. As mentioned above, the processes within the container may be running as root as well, it pays for you to have a good understanding of the security features Docker provides, and how to employ them.\nThe Seccomp section below discusses Docker\u0026rsquo;s attempt to put a stop to some System calls accessing the kernel APIs. There are also many other features that Docker has added or leveraged in terms of mitigating a lot of this potential abuse. Although the situation initially looks bad, Docker has done a lot to improve it.\nAs you can see in the above image, the host kernel is open to receiving potential abuse from containers. Make sure you keep it patched. We will now walk though many areas of potential abuse.\nMake sure you keep your host kernel well patched, as it is a huge attack surface, with all of your containers accessing it via System calls.\nThe space for tooling to help find vulnerabilities in code, packages, etc within your Docker images has been noted, and tools provided. The following is a sorted list of what feels like does the least and is the simplest in terms of security/hardening features to what does the most, not understating tools that do a little, but do it well.\nThese tools should form a part of your secure and trusted build pipeline, or software supply-chain.\nTwistLock TwistLock is a fairly comprehensive and complete proprietary offering with a free developer edition. The following details were taken from TwistLock marketing pages:\nFeatures of Trust:\n Discover and manage vulnerabilities in images Uses CVE data sources similar to CoreOS Clair Can scan registries: Docker Hub, Google Container Registry, EC2 Container Registry, Artifactory, Nexus Registry, and images for vulnerabilities in code and configuration Enforce and verify standard configurations Hardening checks on images based on CIS Docker benchmark Real-time vulnerability and threat intelligence Provide out-of-box plugins for vulnerability reporting directly into Jenkins and TeamCity Provides a set of APIs for developers to access almost all of the TwistLock core functions  Features of Runtime:\n Policy enforcement Detect anomalies, uses open source CVE feeds, commercial threat and vulnerability sources, as well as TwistLock\u0026rsquo;s own Lab research Defend and adapt against active threats and compromises using machine learning Governs access control to individual APIs of Docker Engine, Kubernetes, and Docker Swarm, providing LDAP/AD integration.  Namespaces (Risks) The first place to read for solid background on Linux kernel namespaces is the man-page, otherwise I\u0026rsquo;d just be repeating what is there. A lot of what follows about namespaces requires some knowledge from the namespaces man-page, so do yourself a favour and read it first.\nLinux kernel namespaces were first added between 2.6.15 (January 2006) and 2.6.26 (July 2008).\nAccording to the namespaces man page, IPC, network and UTS namespace support was available from kernel version 3.0, while mount, PID and user namespace support was available from kernel version 3.8 (February 2013), and cgroup namespace support was available from kernel version 4.6 (May 2016).\nEach aspect of a container runs in a separate namespace and its access is limited to that namespace.\nDocker leverages the Linux (kernel) namespaces which provide an isolated workspace wrapped with a global system resource abstraction. This makes it appear to the processes within the namespace that they have their own isolated instance of the global resource. When a container is run, Docker creates a set of namespaces for that container, providing a layer of isolation between containers:\n mnt: (Mount) Provides filesystem isolation by managing filesystems and mount points. The mnt namespace allows a container to have its own isolated set of mounted filesystems, the propagation modes can be one of the following: [r]shared, [r]slave or [r]private. The r means recursive.\nIf you run the following command, then the host\u0026rsquo;s mounted host-path is shared with all others that mount host-path. Any changes made to the mounted data will be propagated to those that use the shared mode propagation. Using slave means only the master (host-path) is able to propagate changes, not vice-versa. Using private which is the default, will ensure no changes can be propagated.\nMounting volumes in shared mode propagation docker run \u0026lt;run arguments\u0026gt; --volume=[host-path:]\u0026lt;container-path\u0026gt;:[z][r]shared \u0026lt;container image name or id\u0026gt; \u0026lt;command\u0026gt; \u0026lt;args...\u0026gt; If you omit the host-path you can see the host path that was mounted when running the following command:\nQuery docker inspect \u0026lt;name or id of container\u0026gt; Find the \u0026ldquo;Mounts\u0026rdquo; property in the JSON produced. It will have a \u0026ldquo;Source\u0026rdquo; and \u0026ldquo;Destination\u0026rdquo; similar to:\nResult ... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;\u0026lt;container id\u0026gt;\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/\u0026lt;container id\u0026gt;/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;\u0026lt;container-path\u0026gt;\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;shared\u0026#34; } ] ... An empty string for Mode means that it is set to its read-write default. For example, a container can mount sensitive host system directories such as /, /boot, /etc, /lib, /proc, /sys, along with the rest as I discuss in the Lock Down the Mounting of Partitions section of my book Fascicle 1 of Holistic Info-Sec for Web Developers, particularly if that advice is not followed. If it is followed, you have some defence in depth working for you, and although Docker may have mounted a directory as read-write, the underlying mount may be read-only, thus stopping the container from being able to modify files in these locations on the host system. If the host does not have the above directories mounted with constrained permissions, then we are relying on the user running any given Docker container that mounts a sensitive host volume to mount it as read-only. For example, after the following command has been run, users within the container can modify files in the hosts /etc directory:\nVulnerable mount docker run -it --rm -v /etc:/hosts-etc --name=lets-mount-etc ubuntu Query docker inspect -f \u0026#34;{{ json .Mounts }}\u0026#34; lets-mount-etc Result [ { \u0026#34;Type\u0026#34;:\u0026#34;bind\u0026#34;, \u0026#34;Source\u0026#34;:\u0026#34;/etc\u0026#34;, \u0026#34;Destination\u0026#34;:\u0026#34;/hosts-etc\u0026#34;, \u0026#34;Mode\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;:true, \u0026#34;Propagation\u0026#34;:\u0026#34;\u0026#34; } ] Also keep in mind that, by default, the user in the container, unless otherwise specified, is root, the same root user as on the host system.\nLabelling systems such as Linux Security Modules (LSM) require that the contents of a volume mounted into a container be labelled. This can be done by adding the z (as seen in above example) or Z suffix to the volume mount. The z suffix instructs Docker to share the mounted volume with other containers, and in so doing, Docker applies a shared content label. Alternatively, if you provide the Z suffix, Docker applies a private unshared label, which means only the current container can use the mounted volume. Further details can be found at the dockervolumes documentation. This is something to keep in mind if you are using LSM, and have a process inside your container that is unable to use the mounted data.\n--volumes-from allows you to specify a data volume from another container.\nYou can also mount your Docker container mounts on the host by doing the following:\nmount --bind /var/lib/docker/\u0026lt;volumes\u0026gt;/\u0026lt;container id\u0026gt;/_data \u0026lt;/path/on/host\u0026gt;  PID: (Process ID) Provides process isolation, separates container processes from host and other container processes.\nThe first process that is created in a new PID namespace is the \u0026ldquo;init\u0026rdquo; process with PID 1, which assumes parenthood of the other processes within the same PID namespace. When PID 1 is terminated, so are the rest of the processes within the same PID namespace.\nPID namespaces are hierarchically nested in ancestor-descendant relationships to a depth of up to 32 levels. All PID namespaces have a parent namespace, other than the initial root PID namespace of the host system. That parent namespace is the PID namespace of the process that created the child namespace.\nWithin a PID namespace, it is possible to access (make system calls to specific PIDs) all other processes in the same namespace, as well as all processes of descendant namespaces. However, processes in a child PID namespace cannot see processes that exist in the parent PID namespace or further removed ancestor namespaces. The direction any process can access another process in an ancestor/descendant PID namespace is one way.\nProcesses in different PID namespaces can have the same PID, because the PID namespace isolates the PID number space from other PID namespaces.\nDocker takes advantage of PID namespaces. Just as you would expect, a Docker container can not access the host system processes, and process Ids that are used in the host system can be reused in the container, including PID 1, by being reassigned to a process started within the container. The host system can however access all processes within its containers, because as stated above, PID namespaces are hierarchically nested in parent-child relationships. Processes in the hosts PID namespace can access all processes in their own namespace down to the PID namespace that was responsible for starting the process, such as the process within the container in our case.\nThe default behaviour can however be overridden to allow a container to be able to access processes within a sibling container, or the hosts PID namespace. Example:\nSyntax --pid=[container:\u0026lt;name|id\u0026gt;],[host] Example # Provides access to the `PID` namespace of container called myContainer # for container created from myImage. docker run --pid=container:myContainer myImage Example # Provides access to the host `PID` namespace for container created from myImage docker run --pid=host myImage As an aside, PID namespaces give us the functionality of: \u0026ldquo;suspending/resuming the set of processes in the container and migrating the container to a new host while the processes inside the container maintain the same PIDs.\u0026rdquo; with a handful of commands:\nExample docker container pause myContainer [mySecondContainer...] docker export [options] myContainer # Move your container to another host. docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]] docker container unpause myContainer [mySecondContainer...] net: (Networking) Provides network isolation by managing the network stack and interfaces. It\u0026rsquo;s also essential to allow containers to communicate with the host system and other containers. Network namespaces were introduced into the kernel in 2.6.24, January 2008, with an additional year of development they were considered largely done. The only real concern here is understanding the Docker network modes and communication between containers. This is discussed in the Countermeasures.\n UTS: (Unix Timesharing System) Provides isolation of kernel and version identifiers.\nUTS is the sharing of a computing resource with many users, a concept introduced in the 1960s/1970s.\nA UTS namespace is the set of identifiers returned by uname, which include the hostname and the NIS domain name. Any processes which are not children of the process that requested the clone will not be able to see any changes made to the identifiers of the UTS namespace.\nIf the CLONE_NEWUTS constant is set, then the process being created will be created in a new UTS namespace with the hostname and NIS domain name copied and able to be modified independently from the UTS namespace of the calling process.\nIf the CLONE_NEWUTS constant is not set, then the process being created will be created in the same UTS namespace of the calling process, thus able to change the identifiers returned by uname.\nWhen a container is created, a UTS namespace is copied (CLONE_NEWUTS is set)(--uts=\u0026quot;\u0026quot;) by default, providing a UTS namespace that can be modified independently from the target UTS namespece it was copied from.\nWhen a container is created with --uts=\u0026quot;host\u0026quot;, a UTS namespace is inherited from the host, the --hostname flag is invalid.\n IPC: (InterProcess Communication) manages access to InterProcess Communications). IPC namespaces isolate your container\u0026rsquo;s System V IPC and POSIX message queues, semaphores, and named shared memory from those of the host and other containers, unless another container specifies on run that it wants to share your namespace. It would be a lot safer if the producer could specify which consuming containers could use its namespace. IPC namespaces do not include IPC mechanisms that use filesystem resources such as named pipes.\nAccording to the namespaces man page: \u0026ldquo;Objects created in an IPC namespace are visible to all other processes that are members of that namespace, but are not visible to processes in other IPC namespaces.\u0026ldquo;\nAlthough sharing memory segments between processes provide Inter-Process Communications at memory speed, rather than through pipes or worse, the network stack, this produces a significant security concern.\nBy default a container does not share the host\u0026rsquo;s or any other container\u0026rsquo;s IPC namespace. This behaviour can be overridden to allow a (any) container to reuse another container\u0026rsquo;s or the host\u0026rsquo;s message queues, semaphores, and shared memory via their IPC namespace. Example:\nSyntax # Allows a container to reuse another container\u0026#39;s IPC namespace. --ipc=[container:\u0026lt;name|id\u0026gt;],[host] Example docker run -it --rm --name=container-producer ubuntu root@609d19340303:/# # Allows the container named container-consumer to share the IPC namespace # of container called container-producer. docker run -it --rm --name=container-consumer --ipc=container:container-producer ubuntu root@d68ecd6ce69b:/# Now find the Ids of the two running containers:\nQuery docker inspect --format=\u0026#34;{{ .Id }}\u0026#34; container-producer container-consumer Result 609d193403032a49481099b1fc53037fb5352ae148c58c362ab0a020f473c040 d68ecd6ce69b89253f7ab14de23c9335acaca64d210280590731ce1fcf7a7556 You can see from using the command supplied by the CIS_Docker_1.13.0_Benchmark that container-consumer is using the IPC namespace of container-producer:\nQuery docker ps --quiet --all | xargs docker inspect --format \u0026#39;{{ .Id }}: IpcMode={{ .HostConfig.IpcMode }}\u0026#39; Result d68ecd6ce69b89253f7ab14de23c9335acaca64d210280590731ce1fcf7a7556: IpcMode=container:container-producer 609d193403032a49481099b1fc53037fb5352ae148c58c362ab0a020f473c040: IpcMode= When the last process in an IPC namespace terminates, the namespace will be destroyed along with all IPC objects in the namespace.\n user: Not enabled by default. Allows a process within a container to have a unique range of user and group Ids within the container, known as the subordinate user and group Id feature in the Linux kernel. These do not map to the same user and group Ids of the host, container users to host users are remapped. For example, if a user within a container is root, which it is by default unless a specific user is defined in the image hierarchy, it will be mapped to a non-privileged user on the host system.\nDocker considers user namespaces to be an advanced feature. There are currently some Docker features that are incompatible with using user namespaces, and according to the CIS Docker 1.13.0 Benchmark, functionalities that are broken if user namespaces are used. the Docker engine reference provides additional details around known restrictions of user namespaces.\nIf your containers have a predefined non-root user, then, currently, user namespaces should not be enabled, due to possible unpredictable issues and complexities, according to \u0026ldquo;2.8 Enable user namespace support\u0026rdquo; of the CIS Docker Benchmark.\nThe problem is that these mappings are performed on the Docker daemon rather than at a per-container level, so it is an all or nothing approach. This may change in the future though.\nAs mentioned, user namespace support is available, but not enabled by default in the Docker daemon.\n  Namespaces (Countermeasures)  mnt: Keep the default propagation mode of private unless you have a very good reason to change it. If you do need to change it, think about defence in depth and employ other defence strategies.\nIf you have control over the Docker host, lock down the mounting of the host systems partitions as I discussed in the Lock Down the Mounting of Partitions subsection of the VPS chapter of my book Fascicle 1 Holistic Info-Sec for Web Developers.\nIf you have to mount a sensitive host system directory, mount it as read-only:\ndocker run -it --rm -v /etc:/hosts-etc:ro --name=lets-mount-etc ubuntu  If any file modifications are now attempted on /etc they will be unsuccessful.\nQuery docker inspect -f \u0026#34;{{ json .Mounts }}\u0026#34; lets-mount-etc Result [ { \u0026#34;Type\u0026#34;:\u0026#34;bind\u0026#34;, \u0026#34;Source\u0026#34;:\u0026#34;/etc\u0026#34;, \u0026#34;Destination\u0026#34;:\u0026#34;/hosts-etc\u0026#34;, \u0026#34;Mode\u0026#34;:\u0026#34;ro\u0026#34;, \u0026#34;RW\u0026#34;:false, \u0026#34;Propagation\u0026#34;:\u0026#34;\u0026#34; } ] Also, as discussed previously, lock down the user to non-root.\nIf you are using LSM, you will probably want to use the Z option as discussed in the risks section.\n PID: By default enforces isolation from the containers PID namespace, but not from the host to the container. If you are concerned about host systems being able to access your containers, as you should be, consider putting your containers within a VM\n net: A network namespace is a virtualisation of the network stack, with its own network devices, IP routing tables, firewall rules and ports.\nWhen a network namespace is created the only network interface that is created is the loopback interface, which is down until brought up.\nEach network interface, whether physical or virtual, can only reside in one namespace, but can be moved between namespaces.\nWhen the last process in a network namespace terminates, the namespace will be destroyed, destroy any virtual interfaces within it, and move any physical network devices back to the initial network namespace, not the process parent.\nDocker and Network Namespaces\nA Docker network is analogous to a Linux kernel network namespace.\nWhen Docker is installed, three networks are created bridge, host and null, which you can think of as network namespaces. These can be seen by running:\ndocker network ls NETWORK ID NAME DRIVER SCOPE 9897a3063354 bridge bridge local fe179428ccd4 host host local a81e8669bda7 none null local  When you run a container, if you want to override the default network of bridge, you can specify which network in which you want to run the container with the --network flag as the following:\ndocker run --network=\u0026lt;network\u0026gt;  The bridge can be seen by running ifconfig on the host:\ndocker0 Link encap:Ethernet HWaddr 05bb41:b7 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80:fbff57a5/64 Scope:Link  When the Docker engine (CLI) client or API tells the Docker daemon to run a container, part of the process allocates a bridged interface, unless specified otherwise, that allows processes within the container to communicate to the system host via the virtual Ethernet bridge.\nVirtual Ethernet interfaces, when created, are always created as a pair. You can think of them as one interface on each side of a namespace wall with a tube through the wall connecting them. Packets come in one interface and exit the other, and vice versa.\nCreating and Listing Network NameSpaces\nSome of these commands you will need to run as root.\nCreate:\nSyntax ip netns add \u0026lt;yournamespacename\u0026gt; Example ip netns add testnamespace This ip command adds a bind mount point for the testnamespace namespace to /var/run/netns/. When the testnamespace namespace is created, the resulting file descriptor keeps the network namespace alive and persisted. This allows system administrators to apply configuration to the network namespace without fear that it will disappear when no processes are within it.\nVerify it was added ip netns list Result testnamespace However, a network namespace added in this way cannot be used for a Docker container. In order to create a Docker network called kimsdockernet run the following command:\n# bridge is the default driver, so not required to be specified docker network create --driver bridge kimsdockernet  You can then follow this with a\ndocker network ls\nto confirm that the network was added. You can base your network on one of the existing network drivers created by Docker, the bridge driver is used by default.\nbridge: As seen above with the ifconfig listing on the host system, an interface is created called docker0 when Docker is installed. A pair of veth (Virtual Ethernet) interfaces are created when the container is run with this --network option. The veth on the outside of the container will be attached to the bridge, the other veth is put inside the container\u0026rsquo;s namespace, along with the existing loopback interface.\nnone: There will be no networking in the container other than the loopback interface which was created when the network namespace was created, and has no routes to external traffic.\nhost: Uses the network stack that the host system uses inside the container. The host mode is more performant than the bridge mode due to using the hosts native network stack, but also less secure.\ncontainer: Allows you to specify another container to use its network stack.\nWhen running: docker network inspect kimsdockernet before starting the container, and then again after, you will see the new container added to the kimsdockernet network.\nNow you can run your container using your new network:\ndocker run -it --network kimsdockernet --rm --name=container0 ubuntu  When one or more processes, Docker containers in this case, uses the kimsdockernet network, it can also be seen opened by the presence of its file descriptor at:\n/var/run/docker/netns/\u0026lt;filedescriptor\u0026gt;\nYou can also see that the container named container0 has a network namespace by running the following command, which shows the file handles for the namespaces, and not just the network namespace:\nQuery Namespaces sudo ls /proc/`docker inspect -f \u0026#39;{{ .State.Pid }}\u0026#39; container0`/ns -liah  Result total 0 1589018 dr-x--x--x 2 root root 0 Mar 14 16:35 . 1587630 dr-xr-xr-x 9 root root 0 Mar 14 16:35 .. 1722671 lrwxrwxrwx 1 root root 0 Mar 14 17:33 cgroup -\u0026gt; cgroup:[4026531835] 1722667 lrwxrwxrwx 1 root root 0 Mar 14 17:33 ipc -\u0026gt; ipc:[4026532634] 1722670 lrwxrwxrwx 1 root root 0 Mar 14 17:33 mnt -\u0026gt; mnt:[4026532632] 1589019 lrwxrwxrwx 1 root root 0 Mar 14 16:35 net -\u0026gt; net:[4026532637] 1722668 lrwxrwxrwx 1 root root 0 Mar 14 17:33 pid -\u0026gt; pid:[4026532635] 1722669 lrwxrwxrwx 1 root root 0 Mar 14 17:33 user -\u0026gt; user:[4026531837] 1722666 lrwxrwxrwx 1 root root 0 Mar 14 17:33 uts -\u0026gt; uts:[4026532633]  If you run\nip netns list\nagain, you may think that you should be able to see the Docker network, but you will not, unless you create the following symlink:\nln -s /proc/`docker inspect -f \u0026#39;{{.State.Pid}}\u0026#39; container0`/ns/net /var/run/netns/container0 # Don\u0026#39;t forget to remove the symlink once the container terminates, # else it will be dangling.  If you want to run a command inside of the Docker network of a container, you can use the nsenter command of the util-linux package:\n# Show the ethernet state: nsenter -t `docker inspect -f \u0026#39;{{ .State.Pid }}\u0026#39; container0` -n ifconfig # Or nsenter -t `docker inspect -f \u0026#39;{{ .State.Pid }}\u0026#39; container0` -n ip addr show # Or nsenter --net=/var/run/docker/netns/\u0026lt;filedescriptor\u0026gt; ifconfig # Or nsenter --net=/var/run/docker/netns/\u0026lt;filedescriptor\u0026gt; ip addr show  Deleting Network NameSpaces\nThe following command will remove the bind mount for the specified namespace. The namespace will continue to persist until all processes within it are terminated, at which point any virtual interfaces within it will be destroyed and any physical network devices if they were assigned, would be moved back to the initial network namespace, not the process parent.\nSyntax ip netns delete \u0026lt;yournamespacename\u0026gt;  Example ip netns delete testnamespace  To remove a docker network docker network rm kimsdockernet  If you still have a container running, you will receive an error:\nError response from daemon: network kimsdockernet has active endpoints\nStop your container and try again.\nIt also pays to understand container communication with each other.\nAlso checkout the Additional Resources.\n UTS Do not start your containers with the --uts flag set to host\nAs mentioned in the CIS_Docker_1.13.0_Benchmark \u0026ldquo;Sharing the UTS namespace with the host provides full permission to the container to change the hostname of the host. This is insecure and should not be allowed.\u0026rdquo;. You can test that the container is not sharing the host\u0026rsquo;s UTS namespace by making sure that the following command returns nothing, instead of host:\ndocker ps --quiet --all | xargs docker inspect --format \u0026#39;{{ .Id }}: UTSMode={{ .HostConfig.UTSMode }}\u0026#39;  IPC: In order to stop another untrusted container sharing your containers IPC namespace, you could isolate all of your trusted containers in a VM, or if you are using some type of orchestration, that will usually have functionality to isolate groups of containers. If you can isolate your trusted containers sufficiently, then you may still be able to share the IPC namespace of other near by containers.\n user: If you have read the risks section and still want to enable support for user namespaces, you first need to confirm that the host user of the associated containers PID is not root by running the following CIS Docker Benchmark recommended commands:\nps -p $(docker inspect --format=\u0026#39;{{ .State.Pid }}\u0026#39; \u0026lt;CONTAINER ID\u0026gt;) -o pid,user  Or, you can run the following command and make sure that the userns is listed under the SecurityOptions\ndocker info --format \u0026#39;{{ .SecurityOptions }}\u0026#39;  Once you have confirmed that your containers are not being run as root, you can look at enabling user namespace support on the Docker daemon.\nThe /etc/subuid and /etc/subgid host files will be read for the user and optional group supplied to the --userns-remap option of dockerd.\nThe --userns-remap option accepts the following value types:\n uid uid:gid username username:groupname\n  The username must exist in the /etc/passwd file, the sbin/nologin users are also valid. Subordinate user Id and group Id ranges need to be specified in /etc/subuid and /etc/subuid respectively.\n\u0026ldquo;_The UID/GID we want to remap to does not need to match the UID/GID of the username in /etc/passwd_\u0026ldquo;. It is the entity in the /etc/subuid that will be the owner of the Docker daemon and the containers it runs. The value you supply to --userns-remap if numeric Ids, will be translated back to the valid user or group names of /etc/passwd and /etc/group which must exist, if username, groupname, they must match the entities in /etc/passwd, /etc/subuid, and /etc/subgid.\nAlternatively, if you do not want to specify your own user and/or user:group, you can provide the default value to --userns-remap, and a default user of dockremap along with subordinate uid and gid ranges that will be created in /etc/passwd and /etc/group if it does not already exist. Then the /etc/subuid and /etc/subgid files will be populated with a contiguous 65536 length range of subordinate user and group Ids respectively, starting at the offset of the existing entries in those files.\n# As root, run: dockerd --userns-remap=default  If dockremap does not already exist, it will be created:\n/etc/subuid and /etc/subgid \u0026lt;existinguser\u0026gt;65536 dockremap65536  There are rules about providing multiple range segments in the /etc/subuid, /etc/subgid files, but that is beyond the scope of what I am providing here. For those advanced scenario details, check out the Docker engine reference. The simplest scenario is to use a single contiguous range as seen in the above example, this will cause Docker to map the hosts user and group Ids to the container process using as much of the 165536:65536 range as necessary. For example, the host\u0026rsquo;s root user would be mapped to 165536, the next host user would be mapped to container user 165537, and so on until the 65536 possible Ids are all mapped. Processes run as root inside the container are owned by the subordinate uid outside of the container.\nDisabling user namespace for specific containers\nIn order to disable user namespace mapping, on a per container basis, once enabled for the Docker daemon, you could supply the --userns=host value to either of the run, exec or create Docker commands. This would mean the default user within the container was mapped to the host\u0026rsquo;s root.\n  Read-only Containers In order to set up read-only hosts, physical or virtual, there is a lot of work to be done, and in some cases, it becomes challenging to stop an Operating System writing to some files. I discussed this in depth in the subsections \u0026ldquo;Partitioning on OS Installation\u0026rdquo; and \u0026ldquo;Lock Down the Mounting of Partitions\u0026rdquo; in the VPS chapter of my book: Fascicle 1 of Holistic Info-Sec for Web Developers. In contrast, running Docker containers as read-only is trivial.\nRunning a container with the --read-only flag stops writes to the container.\nThis can sometimes be a little to constraining, as your application may need to write some temporary data locally. You could volume mount a host directory into your container, but this would obviously expose that temporary data to the host, and also other containers that may mount the same host directory. To stop other containers sharing your mounted volume, you would have to employ labeling with the likes of LSM and apply the Z suffix at volume mount time.\nA better, easier and simpler solution would be to apply the --tmpfs flag to one or more directories. --tmpfs allows the creation of tmpfs (appearing as a mounted file system, but stored in volatile memory) mounts on any local directory, which solves the problem of not being able to write to read-only containers.\nIf an existing directory is specified with the --tmpfs option, you will experience similar behaviour to that of mounting an empty directory onto an existing one. The directory is initially empty, any additions or modifications to the directories contents will not persist past container stop.\nThe following is an example of running a container as read-only with a writeable tmpfs /tmp directory:\ndocker run -it --rm --read-only --tmpfs /tmp --name=my-read-only-container ubuntu The default mount flags with --tmpfs are the same as the Linux default mount flags, if you do not specify any mount flags the following will be used:\nrw,noexec,nosuid,nodev,size=65536k\nrunC and Where it Fits in Docker engine is now built on containerd and runC. Engine creates the image indirectly via containerd -\u0026gt; runC using libcontainer -\u0026gt; and passes it to containerd.\ncontainerd (daemon for Linux or Windows):\ncontainerd is based on the Docker engine\u0026rsquo;s core container runtime. It manages the complete container life-cycle, managing primitives on Linux and Windows hosts such as the following, whether directly or indirectly:\n Image transfer and storage Container execution and supervision Management of network interfaces Local storage Native plumbing level API Full Open Container Initiative (OCI) support: image and runtime (runC) specification\n  containerd calls containerd-shim which uses runC to run the container. containerd-shim allows the runtime, which is docker-runc in Docker\u0026rsquo;s case, to exit once it has started the container, thus allowing the container to run without a daemon. You can see this if you run\nps aux | grep docker\nIn fact, if you run this command you will see how all the components hang together. Viewing this output along with the diagram below, will help solidify your understanding of the relationships between the components.\nrunC is the container runtime that runs containers (think, run Container) according to the OCI specification, runC is a small standalone command line tool (CLI) built on and providing interface to libcontainer, which does most of the work. runC provides interface with:\n Linux Kernel Namespaces Cgroups Linux Security Modules Capabilities Seccomp  These features have been integrated into the low level, light weight, portable, container runtime CLI called runC, with libcontainer doing the heavy lifting. It has no dependency on the rest of the Docker platform, and has all the code required by Docker to interact with the container specific system features. More correctly, libcontainer is the library that interfaces with the above mentioned kernel features. runC leverages libcontainer directly, without the Docker engine being required in the middle.\nrunC was created by the OCI, whose goal is to have an industry standard for container runtimes and formats, attempting to ensure that containers built for one engine can run on other engines.\nIf you\u0026rsquo;re working with Docker, you owe it to yourself to get this book.\n Get The Full Book\nAt this stage, it\u0026rsquo;s only $9 NZ, get your self a copy before I realise it\u0026rsquo;s too cheap.\n\nAs always, let me know if there\u0026rsquo;s anything you don\u0026rsquo;t understand, or submit a pull request or open an issue if you find any errors. 😃\nAdditional Resources The following are the additional resources in the Docker Security book.\n I\u0026rsquo;m also going to be interviewing Michael Hausenblas in a couple of months on the topic of Docker Networking. Keep your eye on my Publications if this interests you, or even leave a comment below and I\u0026rsquo;ll let you know when it\u0026rsquo;s available.   Cisecurity\nhas an excellent resource for hardening docker images, which the Docker Security team helped with. The CIS Benchmark for Docker should be consulted in parallel to reading my Docker Security book\nI also conducted an interview called \u0026ldquo;Docker Security\u0026ldquo;\nfor Software Engineering Radio in which Docker Security Team Lead Diogo Monica appeared as guest and provided some excellent advice, opinions, and food for thought, be sure to listen to it\nNetwork Namespace source code\nhttps://github.com/torvalds/linux/blob/master/net/core/net_namespace.c\nIP-NETNS man page\nhttp://man7.org/linux/man-pages/man8/ip-netns.8.html\nIntroducing Linux Network Namespaces\nhttp://blog.scottlowe.org/2013/09/04/introducing-linux-network-namespaces/\nNetwork namespaces\nhttps://blogs.igalia.com/dpino/2016/04/10/network-namespaces/\ndocker network\nhttps://docs.docker.com/engine/reference/commandline/network/\nNamespaces in operation\nhttps://lwn.net/Articles/580893/\ndockerscan may be worth keeping an eye on for offensive testing\nhttps://github.com/cr0hn/dockerscan\nDocker SELinux Man Page\nhttps://www.mankier.com/8/docker_selinux\nIncreasing Attacker Cost using Immutable Infrastructure\nhttps://diogomonica.com/2016/11/19/increasing-attacker-cost-using-immutable-infrastructure/\nDiogo Monica on Mutual TLS\nhttps://www.youtube.com/watch?v=apma_C24W58\nDiogo Monica on Orchestrating Least Privilege\n https://www.youtube.com/watch?v=xpGNAiA3XW8 https://www.slideshare.net/Docker/orchestrating-least-privilege-by-diogo-monica-67186063  Comparison of secrets across orchestrators\nhttps://medium.com/on-docker/secrets-and-lie-abilities-the-state-of-modern-secret-management-2017-c82ec9136a3d#.f6yba66ti\nDescription of how PKI automatically gets setup in swarm\nhttps://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/\nImage signing, and why it is important\nhttps://blog.docker.com/2015/08/content-trust-docker-1-8/\nDocker security scanning (content integrity)\nhttps://blog.docker.com/2016/05/docker-security-scanning/\n","date":1522407600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522407600,"objectID":"7ece4b96390b7d7802b91908ed36135c","permalink":"https://binarymist.io/blog/2018/03/31/docker-security/","publishdate":"2018-03-31T00:00:00+13:00","relpermalink":"/blog/2018/03/31/docker-security/","section":"post","summary":"Discussion about Kim's new [book on Docker Security](/publication/docker-security/), some of the content, and links to other useful resources around securing your Docker deployments.\n","tags":["application-security","book","cybersecurity","dev-ops","dev-sec-ops","docker","information-security","infosec","namespaces","networking","network-security","security"],"title":"Docker Security","type":"post"},{"authors":null,"categories":null,"content":" There are often many issues with any given Development Teams process, such as the following points:\n The way the individuals communicate Obstacles that slow the Team down unnecessarily Waiting on information and decisions from people outside of the team Team members getting asked to do tasks not on the critical path Lack of autonomy lack of necessary skills and knowledge to create robust, scalable, extensible, maintainable, and secure systems High level of multi-tasking Low morale due to many issues Many others  Similarly there can be many technical issues that negatively affect the rapid development of the type of software solution you are trying to get to market, such as:\n High defect counts Code tightly coupled and hard to extend Interfaces, encapsulation and abstractions breaking down Lack of test coverage, and in some cases too much test coverage in the wrong areas, and even the wrong types of tests Not knowing where and how to start in terms of improving your information security stature  As Software Developers, often we can\u0026rsquo;t even see the faults in front of us. Sometimes it\u0026rsquo;s just a matter of not wanting to rock the boat.\n\nImagine Being Able To See What You Could Never See Before \nThis is where a second pair of eyes with the knowledge and experience of working with and mentoring many high performance, security focussed Development Teams, can really provide the visibility you\u0026rsquo;ve been looking for to make the best decisions.\nKim\u0026rsquo;s ability to sit within a Development Team for a short period of time, intuitively working with your key stake holders, discussing in brutal honesty where the lowest hanging fruit is in terms of items that are slowing your Team(s) down, and stopping them from reaching their maximum performance and effectiveness has proven immensely valuable to many organisations.\nWe will provide you with the visibility and actionable items you need in order to make the positive changes your Development Team(s) need.\nThis is not a road map, but will provide you with the visibility and quick tips you need in order to make the most important changes quickly. We can help create a road map for you if you need additional detail and direction.\n\nGive Your Development Teams The Leading Edge \nThis service provides a teardown of either one of the following. There will be some cross-over between the two options, but this engagement is only for one of the following two options:\n Your Development Team\u0026rsquo;s process and practises.\nIf we are performing teardown on the process and practises, it will be focussed primarily on the people involved and how they do what they do\n Your chosen software project you are currently developing and/or maintaining, reviewing.\nIf performing the project based teardown, the work will be mostly of a technical nature\n  \nHere\u0026rsquo;s How It Works \nIf the area of focus is on your Development Team\u0026rsquo;s process and practises,\nKim will visit your site in person or work with you remotely. We will review the target Development Team and supporting personnel, their process and practises, and how they interact with each other. We will look at how they are performing, document and discuss potential areas for improvement, as well as their areas of strength. We will capitalise on the Teams strengths, and create actionable work items to improve the Teams weak areas and further leverage the Teams strengths.\nIf the area of focus is on your chosen software project,\nSimilarly Kim will visit your site or work with you remotely, reviewing as many of the following artefacts that you can make available as possible, document and discuss potential issues, improvements, and areas where the system is in good shape that can be further capitalised on:\n Build Pipeline / Supply Chain Test Suites (Unit, Integration, Behavioural) Coding Standards, etc  If working remotely, Kim can video or take annotated screen shots of potential issues and provide guidance on how to improve.\n Each member of the Development Team will receive free copies of the first two parts of Kim\u0026rsquo;s book series \u0026ldquo;Holistic Info-Sec for Web Developers\u0026rdquo; (weighing in at approximately 700 pages) which much of Kim\u0026rsquo;s knowledge and experience has been distilled into. this will serve as an invaluable ongoing self learning, and reference resource to help keep the Team on Track.   \n If you\u0026rsquo;re ready to lift your Development Teams game and give them the edge they need\u0026hellip;\n \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nMoney-Back Guarantee! We are so sure we can provide the high quality advice you would expect, that we offer a money back guarantee. If at the end of the engagement, you feel that you have not gotten your money\u0026rsquo;s worth, just let us know and we will refund your payment.\n\nReview our Portfolio and Testimonials for some of the teams we have helped reduce costs, security defects, and improve code quality, process and practises by providing consulting services.\nWhat our customers are saying  Andrew Balfour\n Owner/Managing Director, Solvam Corporation Ltd\n Kim Carter was engaged on a contract basis to implement and guide our future software development for School-links. www.school-links.co.nz\nIn doing that he -\n Brought to our product a much higher level of expertise and capability complementing our development team Directed a disciplined and methodical software development process as the Scrum Master of ‘Scrum’ Helped with the restructuring and planning of our infrastructure in order to scale the product successfully Brings security expertise at a high level with the ability to implement ongoing security hardening program and audits Introduced the Scrum process which provided more consistent and accurate release cycles enabling our marketing efforts to be better coordinated and focused  Kim is a good team member and we will look to reengage with his services when required.\n \n Stefan Streichsbier\n Numisec Pte. Ltd\n I\u0026rsquo;ve met Kim at DevSecCon Singapore in 2017 where he gave a well-received workshop. A few months later we had a project where his top-notch strong Node.js security code review skills were required and this gave us the chance to work together closely.\nOver a 2 week period he was doing security code reviews of containerized Node.js microservices in a very thorough way. We communicated well and progressed quickly. Kim has a very broad yet deep understanding of modern application security that comes from years of experience. I can recommend Kim to anyone who needs an application security expert and wants a professional second opinion on the security posture of an application.\n \nKim has had the unique opportunity to work in both defensive (development) and offensive (penetration testing) teams, across many domains, for a large number of years. This has produced a deep understanding of what Development Team(s) need in order to help you create solutions that will effectively resist attacks from your adversaries.\n  \nKim\u0026rsquo;s experience within Development Teams is exhibited frequently at conference talks, workshops, podcasts that he hosts, and distilled in the books he writes.\nThe following presentation Kim gave at BSides Wellington was around the additional process and practises that he advocates Development Teams embrace and make part of their culture.\n  \nChapter four of the first part of the Holistic Info-Sec for Web Developers book series addresses process and practises for Software Developers based on the learnings of the attackers.\n\n You owe it to your Development Teams to give them the edge they need to produce the software solutions you require. Don\u0026rsquo;t put it off any longer\u0026hellip;\n \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nKim only has availability for a few of these engagements per month. Scheduling is first come, first served, so the sooner you book your consultation, the sooner your Development Team will be able to really start performing.\n\n","date":1521676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521676800,"objectID":"445aa2fc9f77df9058aa617fc3461872","permalink":"https://binarymist.io/project/service-development-team-security-teardown/","publishdate":"2018-03-22T00:00:00Z","relpermalink":"/project/service-development-team-security-teardown/","section":"project","summary":"We can provide insight into potential issues/defects that are not obvious with your Development Team(s):\n\u0026#8226; Development Process\n\u0026#8226; System Being Developed\nOur Teardown can provide the needed visibility in order to make the improvements.","tags":["service","development-team-security-service","productised-service","agile","security","cybersecurity","infosec","dev-ops","dev-sec-ops","operational-efficiencies","software-security","web-application-security"],"title":"Development Team Security Teardown $995NZ + GST","type":"project"},{"authors":["Kim Carter"],"categories":null,"content":" \nShow Outline Basic Questions  What is end-to-end encryption?\n(plain text -\u0026gt; cipher text. If there are intermediaries, they can not make sense of the data) Why do we need end-to-end encryption, what’s the goal here?\n(One example would be a European organisation which stores its archived data off-site in the USA. Under the terms of the USA PATRIOT Act, American authorities can demand access to all data physically stored within its boundaries, even if it includes personal information on European citizens with no connections to the USA. If the data is E2EE, it’s impossible to yield to the authorities) What are we trying to protect? Who are we trying to protect it from\n(who are the threat actors)? What are your thoughts around adding backdoors for the authorities, but somehow stopping the attackers from using them?\n(Examples where this has happened) For our listeners, can you explain symmetric and asymmetric encryption? What types of systems can we apply end-to-end encryption to? What types of systems should we apply end-to-end encryption to?  Scenarios We’re going to discuss IM, Voice, and Email scenarios briefly, then move into Inter-service communication scenarios.\nIM Scenario We apply end-to-end encryption to Instant Messaging. Some of these offerings are:\n Signal\n(free \u0026amp; open source. Retain your ph number and last login date, nothing else) Wire\n(open source, swiss headquarters, EU servers, Proteus is an implementation of the axolotl protocol (later renamed to Double Ratchet Algorithm)) Facebook messenger if you opt-in\n(Signal protocol, collect lots of metadata from users) WhatsApp\n(Signal protocol, but collect conversation and a lot of other metadata, owned by FaceBook, and users data goes to FaceBook) Telegram\n(controversies around their hand rolled MTProto, store lots of metadata) Viber\n(hand rolled closed source signal protocol) iMessage\n(iOS, end-to-end encrypted, closed source, possibly has a back door)  What are your thoughts around these offerings and their ethics?\nVoice Scenario We’ve got Voice calls with offerings such as:\n Signal has voice and video over IP SilentCircle offerings such as Silent Phone\n(source open for review, but not free) FaceTime\n(iOS, end-to-end encrypted, closed source, possibly has a back door) WhatsApp\n(as with IM) Skype\n(spy-ware)  What are your thoughts around these offerings and their ethics?\nEmail Scenario Not end-to-end encrypted, unless using GPG/PGP, which is a pain. TLS provides encryption to the server, STARTTLS can provide encryption between the servers.\nGoogle made various announcements from late 2013 through to about March 2014 that they now provide not only mandatory TLS encryption between clients and their servers, but also between their own data centres.\nThis is good, but it’s not necessarily E2EE, there are transitional seams at each server when the data goes from resting to in-transit. The NSA and GCHQ more than likely have backdoors into Google servers.\nI think it’s safe to say, if we want email or any cloud privacy for that matter, we need to take the responsibility ourselves.\n Is there any hope here, how can we improve the email situation?  Inter-Service Communication Scenarios As Software Engineers, we’re building complex and distributed systems to run on servers we know very little about (AKA the Cloud), this is untrusted territory.\n Why do we need encryption between these components?\n Why does it need to be end to end?\n(Stop attackers intercepting, both hackers and nation states)\n(How could an attacker leverage the seam?) Securing data at rest and in transit is generally a solved problem, but securing data in use is harder. If we can achieve this, then we can achieve E2EE. If we have to decrypt in order to process, then we have a seam, and this is where attackers will focus their efforts.\nRather than creating a seam in our E2EE by decrypting to perform processing, let’s look at some techniques for securing data in use, thus providing E2EE\u0026hellip;  Full memory encryption (E2EE data in use techniques) The system provides both confidentiality and integrity protections of code and data which are encrypted everywhere outside the CPU boundary\n Can you explain how this works, and how Software Engineers can take advantage of it?  CPU-based Key Storage (E2EE data in use techniques) This is where a kernel patch provides CPU-only based encryption to defend against cold boot attacks, allowing RAM to be treated as untrusted. Can you tell us a bit about this and whether Software Engineers could be, and should be making use of it in our systems?\n(Implementations: TRESOR, Loop-Amnesia)\nEnclaves (E2EE data in use techniques) We touched on Intel Software Guard Extensions (SGX) in the show on Docker Security (#290) Data in enclaves is encrypted in RAM, but clear text within the CPU and its cache. Intel introduced the concept of enclaves as part of its SGX, providing a set of new SGX-enabled CPU instructions (18) allowing user-level code to allocate private regions of memory known as enclaves.\nIntel has the concept of the symmetrical provisioning key which resides in both the SGX-enabled chip and in Intel servers.\nTo establish an enclave, the software needs to offer its provisioning key to Intel, and if there\u0026rsquo;s a match in their database, Intel will issue an attestation key that lets SGX set up the enclave.\nThe SGX patents disclose in no uncertain terms that the Launch Enclave was introduced to ensure that each enclave’s author has a business relationship with Intel, and implements a software licensing system\n SGX has been heavily criticised by security researches (Victor Costan and Srinivas Devadas of MIT). As far as I can tell, by using SGX, we’re just shifting our trust from untrusted clouds to Intel? Can you explain how enclaves work, what theoretical and real benefit this provides us if any?  Cryptographic Protocols (E2EE data in use techniques)  Secure multi-party computation (AKA secure computation or privacy-preserving computation), the idea here is to create methods for parties to jointly compute a function over their inputs while keeping those inputs private Homomorphic encryption allows us to perform computations on ciphertext, the result being the result of the operations as though they had been performed on plaintext but still encrypted\n Can you explain a bit about “Secure multi-party computation” and “Homomorphic encryption” and how they differ? How can your average Software Engineer utilise these within their solutions?  Now that we’ve talked about securing data in use, what are the best options for todays Software Engineers to perform processing on encrypted data?\n  Transition from E2EE to Encryption between points of communication We touched on what CSPs are doing to encrypt our comms between data centres, services and components in the Cloud Security show with AWS security specialist Scott Piper (#314). It basically comes down to: we don’t really know what they’re doing, so this is the Developer’s responsibility.\n Can you add anything to this? We can setup mutual TLS authentication between our components. What other options, tools and techniques do we have available to us as Software Engineers, when performing computation on encrypted data isn’t an option?  Libraries, Ciphers and Tools  There is a huge amount of poor advice on the internet, stackoverflow, etc. Let’s get some solid advice for our Engineers Which ciphers and modes should we be avoiding, and which should we be using for which purpose?\n(Avoid: AES-CBC. Use: AES256 block cipher with the GCM cipher mode) Which Libraries (native and others) should we avoid, and which should we be using? It can be hard for Software Engineers to know which ciphers and KDFs they should use. What do we need to look for in a library?\n(Created by cryptographers, few options, only tried and tested ciphers, if in doubt, ask an expert not stackoverflow)  Tresorit Non-convergent Crypto Tresorit uses non-convergent crypto to store users data, can you talk a bit about what this means and how this works?\n","date":1520899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520899200,"objectID":"b8d335265b0871ac158aef90b368404f","permalink":"https://binarymist.io/publication/ser-podcast-end-to-end-encryption/","publishdate":"2018-03-13T00:00:00Z","relpermalink":"/publication/ser-podcast-end-to-end-encryption/","section":"publication","summary":"Head of Cryptography Engineering at Tresorit, Péter Budai talks with Kim Carter about End to End Encryption.\n","tags":["publication","podcast","application-security","cipher","cloud","cloud-security","crypto","cryptography","cybersecurity","encryption","information-security","infosec","gpg","pgp","security","web-security"],"title":"Péter Budai on End to End Encryption","type":"publication"},{"authors":null,"categories":null,"content":" Continuing on from the last post, in which we set-up the BinaryMist blog and business site on Hugo, it was now time to provide some functionality for you to be able to:\n Leave comments on posts Subscribe to comments on specific blog posts Subscribe to notification by email as new blog posts are published  Hugo uses Disqus as it\u0026rsquo;s default reader commenting system which is a shame, as Disqus is evil, but never fear, I\u0026rsquo;ve gone ahead and got a commenting system set-up for the Academic theme that won\u0026rsquo;t abuse you. Your comments are actually hosted from the same place as this website is running from, your email address is md5 hashed, so it\u0026rsquo;s not visible to the public in clear text anywhere. For example, this is the hash of my email address:\n01486cfc6aa638a6f8e85142c645fcd7\nWhat\u0026rsquo;s on Offer? I reviewed the other offerings promoted by Hugo:\n Disqus: As discussed, No thanks! Texpen: Their site doesn\u0026rsquo;t respond for me IntenseDebate: Closed source (I think). Looks like they want to sign the consumer up, I\u0026rsquo;m guessing this costs money. What ever their deal is, they\u0026rsquo;re not up-front enough about it for me GraphComment: Closed source Mutt: Closed source, costs money isso: Python and open (great), but the consumer has to self host, may not be a show stopper, but we can do better  This leaves the free and open Staticman. You can see some of the other sites that use Staticman here. Staticman ticked all of my boxes, apart from the fact I\u0026rsquo;d like to see some more contributors to the project, but hay, if that is honestly a problem, then I should be contributing, and I guess I am in a small way. In saying that, Worst case scenario, is that the project becomes dormant, and one of the consumers, will need to become a producer, and/or we have to self host it. Big ups to @eduardoboucas for running this project for free, and in his spare time. It\u0026rsquo;s people like this that make the open source world what it is.\nStaticman it is, Let\u0026rsquo;s move on If you subscribe to comments on any of the BinaryMist blog posts, your email address will be stored in a mailing list that I control. You can unsubscribe at any time, and I will not spam you. You can also tell me to remove you at any time and I will make sure your request is honoured. If you check the \u0026ldquo;Notify me of new comments on this post\u0026rdquo; (on this or any other post), your email will go into my private mailing list, and will also only be visible as a hash in a Github pull request. That\u0026rsquo;s right, they look like this (01486cfc6aa638a6f8e85142c645fcd7) remember? You can also see what these look like here.\nNow that I had decided to go the Staticman route, I needed to consolidate on the documentation, examples, and start to build a picture of how this was going to work.\n The Beautifulhugo theme appear(es|ed) to support Staticman, but there was no relevant config in the config.toml or staticman.yml. Let me know if I have missed some of their documentation that explains the required config? The single.html layout and staticman-comments.html was marginally helpful The gohugohq howto was also marginally helpful.  If I had to do this again I would ignore both of the above Beautifulhugo and gohugohq examples.\nThe Staticman official documentation is good, but will be even better with a little more time, the info is there, just that some of it is not as clear as it could be, but I know it\u0026rsquo;s being improved as we speak.\nLeave Comments on Posts The creator of Staticman was nice enough to create a model Hugo site to demo Staticman working with Hugo. The following were the most helpful examples to set this up with Hugo:\n Demo site: https://hugo.staticman.net/post/my-entry/ Config file: https://github.com/eduardoboucas/hugo-plus-staticman/blob/master/staticman.yml The layout partial that handles the markup for the comment display and posting: https://github.com/eduardoboucas/hugo-plus-staticman/blob/master/themes/hugo-type-theme/layouts/partials/post-comments.html I used the style-sheet from the Staticman creators own website (source) for the \u0026ldquo;Notify me of new comments on this post\u0026rdquo; checkbox as a starting point  In order for the comment count to be displayed in the article_metadata.html (That\u0026rsquo;s at the top of each post and listed under each posts title in the list), the blog posts slug needs to be in the front matter of each post:\n# Slug is required for counting comments. slug = \u0026#34;blog-post-file-name-without-md\u0026#34; If you decide to have Staticman issue a pull request for each reader comment (see step 4 of the getting started guide), you can also set-up a webhook to have Static man delete the branch once you have accepted or closed the pull request.\nSubscribe to Comments on Specific Blog Posts This is where you set-up a Mailgun account and your domain within it. Go ahead and sign up for a free Mailgun account.\nThe most useful piece of documentation for this was an issue thread in which @eduardoboucas explained how this should work. Some of the following comments on the thread were also useful.\nFrom the staticman.sample.yml which you copied to your sites root directory and modified, based on the directions in the official documentation, you will need to uncomment the #notifications:, #enabled: true and add your encrypted apiKey and domain that Staticman encrypts for you (also discussed in the issue thread mentioned above) if you use the API.\nSubscribe to notification by email as new blog posts are published Once I had the above set-up and working, this step only took an afternoon. What was involved:\n Added the blogSubscribers section to staticman.yml, I will discus this when we look at the code in the next section Added the post.html (shown below). This will POST your subscription, and display a confirmation screen Some more styling added to override.css On first POST the mailing list will be created in your Mailgun account. I then just gave it a sensible name, so I can see what the purpose of the list is at a glance, as Staticman provides a \u0026ldquo;MD5 hash of the Github username, repository, and entry id concatenated together\u0026rdquo; which is prefixed to the Alias Address of the new Mailgun mailing list that you can send notifications to. If you have moderation: true in your staticman.yml under the section responsible for this (blogSubscribers in my case), you will receive a pull request each time someone subscribes.\nIf you are like me and would like to address notifications to a name/handle, the following is currently required:\nOnce I receive the Github pull request from Staticman for blog subscription, if it looks legitimate, I need to md5sum the email address in the new Mailgun record:\necho -n [the-email-address-from-mailgun-record] | md5sum\nand compare the result with the hashed email in the pull request. Then take the name from that pull request and apply it to the Mailgun entry. This is a small piece of manual work that would be nice if Staticman could send the name as well and have it added to the email records name variable.\nThe pull request can be closed, unless for some reason you want it merged.\n  Sending Email to Subscribers Once you have the above set-up, sending the email is as simple as:\ncurl -s --user \u0026#39;api:key-[key-hash-goes-here]\u0026#39; \\  https://api.mailgun.net/v3/mailgun.binarymist.io/messages \\  -F from=\u0026#39;\u0026lt;your-name\u0026gt; \u0026lt;email-address-that-subscribers-can-reply-to\u0026gt;\u0026#39; \\  -F to=\u0026lt;your-mailgun-email-address\u0026gt; \\  -F subject=\u0026#39;New Blog Post from You\u0026#39; \\  --form-string html=\u0026#39;\u0026lt;html\u0026gt;Hi %recipient.name%.\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;This is a link to the new post: \u0026lt;a href=\u0026#34;https://\u0026lt;your-domain\u0026gt;/\u0026lt;post-slug\u0026gt;\u0026#34;\u0026gt;\u0026lt;name-of-your-post\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt; Enjoy!\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;-You.\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;If at any point you would like to unsubscribe from this mailing list, click \u0026lt;a href=\u0026#34;%mailing_list_unsubscribe_url%\u0026#34;\u0026gt;Unsubscribe\u0026lt;/a\u0026gt;\u0026lt;/html\u0026gt;\u0026#39; Show me the Code Firstly, all of this is up and running on the blog you are reading now.\nYou may also notice the botpot input field on both forms. This is from a mitigations section in the Web Applications chapter of my second book around captchas, and how they place the website owners problem on the end uers. Bots are not the end users problem, so why should they have to jump through hoops to submit a simple form? Check out my research on the topic.\n The problem The solution(s)  Enough ranting\u0026hellip; The following are the new parts I added to config.toml:\nModified File: config.toml # Comment out disqusShortname Key/Value pair #disqusShortname = \u0026#34;\u0026#34; # Add the following new Table somewhere under the params table [params.staticman] endpoint = \u0026#34;https://api.staticman.net/v2/entry\u0026#34; username = \u0026#34;binarymist\u0026#34; repository = \u0026#34;BinaryMistBlog\u0026#34; branch = \u0026#34;master\u0026#34; New File: staticman.yml This is required by Staticman. You\u0026rsquo;ll notice I have a comments section and a blogSubscribers section. The former is used by Staticman when you submit a comment on a specific post, you can see this in action below. The latter is used by Staticman when you subscribe to be notified of a new blog post, you can see this in action here. If all you need is blog comments, you only need the comments section.\nNew Override: /layouts/partials/comments.html comments.html is used for posting and subscribing to each specific blog post comment thread, and was copied from /themes/academic/layouts/partials/ and modified extensively. The first lines diff:\n- {{ if and .Site.DisqusShortname (not (or .Site.Params.disable_comments .Params.disable_comments)) }} + {{ if and (or .Site.DisqusShortname .Site.Params.staticman) (not (or .Site.Params.disable_comments .Params.disable_comments)) }}  Lines 3 - 4 and 6 - 71 are brand new lines:\n1{{ if and (or .Site.DisqusShortname .Site.Params.staticman) (not (or .Site.Params.disable_comments .Params.disable_comments)) }} 2 \u0026lt;section id=\u0026#34;comments\u0026#34;\u0026gt; 3 {{ if .Site.DisqusShortname }} 4 \u0026lt;div class=\u0026#34;disqus-comments\u0026#34;\u0026gt; 5 {{ template \u0026#34;_internal/disqus.html\u0026#34; . }} 6 \u0026lt;/div\u0026gt; 7 {{ end }} 8 {{ if .Site.Params.staticman }} 9 \u0026lt;section class=\u0026#34;staticman-comments post-comments\u0026#34;\u0026gt; 10 \u0026lt;h3\u0026gt;Comments\u0026lt;/h3\u0026gt; 11 12 {{ $comments := readDir \u0026#34;data/comments\u0026#34; }} 13 {{ $.Scratch.Add \u0026#34;hasComments\u0026#34; 0 }} 14 {{ $postSlug := .Source.BaseFileName }} 15 16 {{ range $comments }} 17 {{ if eq .Name $postSlug }} 18 {{ $.Scratch.Add \u0026#34;hasComments\u0026#34; 1 }} 19 {{ range $index, $comments := (index $.Site.Data.comments $postSlug ) }} 20 \u0026lt;div id=\u0026#34;commentid-{{ ._id }}\u0026#34; class=\u0026#34;post-comment\u0026#34;\u0026gt; 21 \u0026lt;div class=\u0026#34;post-comment-header\u0026#34;\u0026gt; 22 \u0026lt;img class=\u0026#34;post-comment-avatar\u0026#34; src=\u0026#34;https://www.gravatar.com/avatar/{{ .email }}?s=70\u0026amp;r=pg\u0026amp;d=identicon\u0026#34;\u0026gt; 23 \u0026lt;p class=\u0026#34;post-comment-info\u0026#34;\u0026gt; 24 \u0026lt;span class=\u0026#34;post-comment-name\u0026#34;\u0026gt;{{ .name }}\u0026lt;/span\u0026gt; 25 \u0026lt;br\u0026gt; 26 \u0026lt;a href=\u0026#34;#commentid-{{ ._id }}\u0026#34; title=\u0026#34;Permalink to this comment\u0026#34;\u0026gt; 27 \u0026lt;time class=\u0026#34;post-time\u0026#34;\u0026gt;{{ dateFormat \u0026#34;Monday, Jan 2, 2006 at 15:04 MST\u0026#34; .date }}\u0026lt;/time\u0026gt; 28 \u0026lt;/a\u0026gt; 29 \u0026lt;/p\u0026gt; 30 \u0026lt;/div\u0026gt; 31 {{ .comment | markdownify }} 32 \u0026lt;/div\u0026gt; 33 {{ end }} 34 {{ end }} 35 {{ end }} 36 37 {{ if eq ($.Scratch.Get \u0026#34;hasComments\u0026#34;) 0 }} 38 \u0026lt;p\u0026gt;Be the first to leave a comment.\u0026lt;/p\u0026gt; 39 {{ end }} 40 41 \u0026lt;h3\u0026gt;Say something\u0026lt;/h3\u0026gt; 42 Your email is used for \u0026lt;a href=\u0026#34;https://gravatar.com\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Gravatar\u0026lt;/a\u0026gt; image and reply notifications only. 43 44 45 \u0026lt;form class=\u0026#34;post-new-comment\u0026#34; method=\u0026#34;post\u0026#34; action=\u0026#34;{{ .Site.Params.staticman.endpoint }}/{{ .Site.Params.staticman.username }}/{{ .Site.Params.staticman.repository }}/{{ .Site.Params.staticman.branch }}/comments\u0026#34;\u0026gt; 46 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[redirect]\u0026#34; value=\u0026#34;{{ .Permalink }}#comment-submitted\u0026#34;\u0026gt; 47 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[slug]\u0026#34; value=\u0026#34;{{ .Source.BaseFileName }}\u0026#34;\u0026gt; 48 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;fields[postName]\u0026#34; value=\u0026#34;{{ .Source.BaseFileName }}\u0026#34;/\u0026gt; 49 \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;fields[name]\u0026#34; class=\u0026#34;post-comment-field\u0026#34; placeholder=\u0026#34;Name *\u0026#34; required/\u0026gt; 50 \u0026lt;input type=\u0026#34;email\u0026#34; name=\u0026#34;fields[email]\u0026#34; class=\u0026#34;post-comment-field\u0026#34; placeholder=\u0026#34;Email address (will not be public) *\u0026#34; required/\u0026gt; 51 \u0026lt;input type=\u0026#34;address\u0026#34; name=\u0026#34;fields[botpot]\u0026#34; placeholder=\u0026#34;botpot (do not fill!)\u0026#34; style=\u0026#34;display: none\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; 52 \u0026lt;textarea name=\u0026#34;fields[comment]\u0026#34; class=\u0026#34;post-comment-field\u0026#34; placeholder=\u0026#34;Comment (markdown is accepted) *\u0026#34; required rows=\u0026#34;10\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; 53 \u0026lt;!-- Following fields used for subscribing to comments --\u0026gt; 54 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[origin]\u0026#34; value=\u0026#34;{{ $.Permalink }}#comments\u0026#34;\u0026gt; 55 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[parent]\u0026#34; value=\u0026#34;{{ .Source.BaseFileName }}\u0026#34;\u0026gt; 56 \u0026lt;input id=\u0026#34;form-submit\u0026#34; type=\u0026#34;checkbox\u0026#34; name=\u0026#34;options[subscribe]\u0026#34; class=\u0026#34;checkbox post-comment-field\u0026#34; value=\u0026#34;email\u0026#34;\u0026gt; 57 \u0026lt;label for=\u0026#34;form-submit\u0026#34; class=\u0026#34;post-comment-field checkbox-label\u0026#34;\u0026gt; \u0026amp;nbsp Notify me of new comments on this post\u0026lt;/label\u0026gt; 58 \u0026lt;!-- End following fields used for subscribing to comments --\u0026gt; 59 \u0026lt;input type=\u0026#34;submit\u0026#34; class=\u0026#34;post-comment-field btn btn-primary comment-buttons\u0026#34; value=\u0026#34;Submit\u0026#34;\u0026gt; 60 \u0026lt;/form\u0026gt; 61 \u0026lt;/section\u0026gt; 62 63 \u0026lt;div id=\u0026#34;comment-submitted\u0026#34; class=\u0026#34;dialog\u0026#34;\u0026gt; 64 \u0026lt;h3\u0026gt;Thank you\u0026lt;/h3\u0026gt; 65 \u0026lt;p\u0026gt;Your comment has been submitted and will be published once it has been approved.\u0026lt;/p\u0026gt; 66 \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://github.com/{{ .Site.Params.staticman.username }}/{{ .Site.Params.staticman.repository }}/pulls\u0026#34;\u0026gt;Click here\u0026lt;/a\u0026gt; to see the pull request you generated.\u0026lt;/p\u0026gt; 67 68 \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;btn btn-primary comment-buttons ok\u0026#34;\u0026gt;OK\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; 69 \u0026lt;/div\u0026gt; 70 71 {{ end }} 72 \u0026lt;/section\u0026gt; 73{{ end }} New Override: /layouts/partials/article_metadata.html article_metadata.html is used for displaying the comment count directly under the title of each blog post in the post list and at the top of each post. You won\u0026rsquo;t see the count unless there are actually comments on the post. article_metadata.html was copied from /themes/academic/layouts/partials/ and modified.\nLine 21 diff:\n- {{ $comments_enabled := and $.Site.DisqusShortname (not (or $.Site.Params.disable_comments $.Params.disable_comments)) }} + {{ $comments_enabled := and (or $.Site.DisqusShortname $.Site.Params.staticman) (not (or $.Site.Params.disable_comments $.Params.disable_comments)) }}  Lines 23 and 27 - 43 are brand new lines:\n1{{ $is_list := .is_list }} 2{{ $ := .content }} 3\u0026lt;div class=\u0026#34;article-metadata\u0026#34;\u0026gt; 4 5 \u0026lt;span class=\u0026#34;article-date\u0026#34;\u0026gt; 6 {{ if ne $.Params.Lastmod $.Params.Date }} 7 {{ i18n \u0026#34;last_updated\u0026#34; }} 8 {{ end }} 9 \u0026lt;time datetime=\u0026#34;{{ $.Date }}\u0026#34; itemprop=\u0026#34;datePublished\u0026#34;\u0026gt; 10 {{ $.Lastmod.Format $.Site.Params.date_format }} 11 \u0026lt;/time\u0026gt; 12 \u0026lt;/span\u0026gt; 13 14 {{ if ne $.Site.Params.reading_time false }} 15 \u0026lt;span class=\u0026#34;middot-divider\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; 16 \u0026lt;span class=\u0026#34;article-reading-time\u0026#34;\u0026gt; 17 {{ $.ReadingTime }} {{ i18n \u0026#34;minute_read\u0026#34; }} 18 \u0026lt;/span\u0026gt; 19 {{ end }} 20 21 {{ $comments_enabled := and (or $.Site.DisqusShortname $.Site.Params.staticman) (not (or $.Site.Params.disable_comments $.Params.disable_comments)) }} 22 {{ if and $comments_enabled ($.Site.Params.comment_count | default true) }} 23 {{ if $.Site.DisqusShortname }} 24 \u0026lt;span class=\u0026#34;middot-divider\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; 25 \u0026lt;a href=\u0026#34;{{ $.Permalink }}#disqus_thread\u0026#34;\u0026gt;\u0026lt;!-- Count will be inserted here --\u0026gt;\u0026lt;/a\u0026gt; 26 {{ end }} 27 {{ if $.Site.Params.staticman }} 28 {{ $.Scratch.Set \u0026#34;commentCountPerPost\u0026#34; 0 }} 29 {{ if $.Slug }} \u0026lt;!-- Can\u0026#39;t count comments without slug --\u0026gt; 30 {{ if fileExists (printf \u0026#34;data/comments/%s\u0026#34; $.Slug) }} \u0026lt;!-- If the comment dir exists, we can count comments --\u0026gt; 31 {{ $comments := readDir (printf \u0026#34;data/comments/%s\u0026#34; $.Slug) }} 32 {{ $.Scratch.Set \u0026#34;commentCountPerPost\u0026#34; (len $comments) }} 33 {{ end }} 34 {{ end }} 35 {{ if gt ( $.Scratch.Get \u0026#34;commentCountPerPost\u0026#34; ) 1 }} 36 \u0026lt;span class=\u0026#34;middot-divider\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; 37 \u0026lt;a href=\u0026#34;{{ $.Permalink }}#comments\u0026#34;\u0026gt;{{ $.Scratch.Get \u0026#34;commentCountPerPost\u0026#34; }} Comments\u0026lt;/a\u0026gt; 38 {{ else if eq ( $.Scratch.Get \u0026#34;commentCountPerPost\u0026#34; ) 1 }} 39 \u0026lt;span class=\u0026#34;middot-divider\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; 40 \u0026lt;a href=\u0026#34;{{ $.Permalink }}#comments\u0026#34;\u0026gt;1 Comment\u0026lt;/a\u0026gt; 41 {{ end }} 42 {{ end }} 43 {{ end}} 44 45 {{ if isset $.Params \u0026#34;categories\u0026#34; }} 46 {{ $categoriesLen := len $.Params.categories }} 47 {{ if gt $categoriesLen 0 }} 48 \u0026lt;span class=\u0026#34;middot-divider\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; 49 \u0026lt;span class=\u0026#34;article-categories\u0026#34;\u0026gt; 50 \u0026lt;i class=\u0026#34;fa fa-folder\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; 51 {{ range $k, $v := $.Params.categories }} 52 \u0026lt;a href=\u0026#34;{{ \u0026#34;/categories/\u0026#34; | relLangURL }}{{ . | urlize | lower }}\u0026#34;\u0026gt;{{ . }}\u0026lt;/a 53 \u0026gt;{{ if lt $k (sub $categoriesLen 1) }}, {{ end }} 54 {{ end }} 55 \u0026lt;/span\u0026gt; 56 {{ end }} 57 {{ end }} 58 59 {{ if ne $is_list 1 }} 60 {{ partial \u0026#34;share.html\u0026#34; $ }} 61 {{ end }} 62 63\u0026lt;/div\u0026gt; New Override: layouts/section/post.html post.html is used for subscribing to new blog posts, and was copied from /themes/academic/layouts/section/ and modified. Lines 14 - 40 are brand new lines.\n1{{ partial \u0026#34;header.html\u0026#34; . }} 2{{ partial \u0026#34;navbar.html\u0026#34; . }} 3 4{{ partial \u0026#34;header_image.html\u0026#34; . }} 5 6\u0026lt;div class=\u0026#34;universal-wrapper\u0026#34;\u0026gt; 7 8 \u0026lt;h1\u0026gt;{{ .Title | default (i18n \u0026#34;posts\u0026#34;) }}\u0026lt;/h1\u0026gt; 9 10 {{ with .Content }} 11 \u0026lt;div class=\u0026#34;article-style\u0026#34; itemprop=\u0026#34;articleBody\u0026#34;\u0026gt;{{ . }}\u0026lt;/div\u0026gt; 12 {{ end }} 13 {{ $paginator := .Paginate .Data.Pages }} 14 {{ if eq ( $paginator.PageNumber ) 1 }} 15 {{ .Scratch.Set \u0026#34;redirectUrl\u0026#34; (print .Permalink \u0026#34;#blogsubscription-submitted\u0026#34;) }} 16 {{ else }} 17 {{ .Scratch.Set \u0026#34;redirectUrl\u0026#34; (print .Permalink \u0026#34;page/\u0026#34; $paginator.PageNumber \u0026#34;/#blogsubscription-submitted\u0026#34;) }} 18 {{ end }} 19 \u0026lt;section class=\u0026#34;subscribe-to-blog\u0026#34;\u0026gt; 20 \u0026lt;form class=\u0026#34;post-blogsubscribe\u0026#34; method=\u0026#34;post\u0026#34; action=\u0026#34;{{ .Site.Params.staticman.endpoint }}/{{ .Site.Params.staticman.username }}/{{ .Site.Params.staticman.repository }}/{{ .Site.Params.staticman.branch }}/blogSubscribers\u0026#34;\u0026gt; 21 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[redirect]\u0026#34; value=\u0026#34;{{ .Scratch.Get \u0026#34;redirectUrl\u0026#34; }}\u0026#34;\u0026gt; 22 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[slug]\u0026#34; value=\u0026#34;post-collection\u0026#34;\u0026gt; 23 \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;fields[name]\u0026#34; class=\u0026#34;post-blogsubscriber-field left\u0026#34; placeholder=\u0026#34;Name *\u0026#34; required/\u0026gt; 24 \u0026lt;input type=\u0026#34;email\u0026#34; name=\u0026#34;fields[email]\u0026#34; class=\u0026#34;post-blogsubscriber-field right\u0026#34; placeholder=\u0026#34;Email address (not publicised) *\u0026#34; required/\u0026gt; 25 \u0026lt;input type=\u0026#34;address\u0026#34; name=\u0026#34;fields[botpot]\u0026#34; placeholder=\u0026#34;botpot (do not fill!)\u0026#34; style=\u0026#34;display: none\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; 26 \u0026lt;!-- Following fields used for subscription --\u0026gt; 27 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[origin]\u0026#34; value=\u0026#34;{{ $.Permalink }}\u0026#34;\u0026gt; 28 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[parent]\u0026#34; value=\u0026#34;post-collection\u0026#34;\u0026gt; 29 \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;options[subscribe]\u0026#34; value=\u0026#34;email\u0026#34;\u0026gt; 30 \u0026lt;!-- End following fields used for subscription --\u0026gt; 31 \u0026lt;input type=\u0026#34;submit\u0026#34; class=\u0026#34;btn btn-primary comment-buttons post-blogsubscriber-btn\u0026#34; value=\u0026#34;Subscribe to new posts \u0026amp;nbsp \u0026amp;nbsp -- \u0026amp;nbsp \u0026amp;nbsp Unsubscribe at any time\u0026#34;\u0026gt; 32 \u0026lt;/form\u0026gt; 33 \u0026lt;/section\u0026gt; 34 \u0026lt;div id=\u0026#34;blogsubscription-submitted\u0026#34; class=\u0026#34;dialog\u0026#34;\u0026gt; 35 \u0026lt;h3\u0026gt;Thank you\u0026lt;/h3\u0026gt; 36 \u0026lt;p\u0026gt;Your subscription request has been submitted.\u0026lt;/p\u0026gt; 37 \u0026lt;p\u0026gt;You will receive a notification email of new posts when they are published.\u0026lt;/p\u0026gt; 38 \u0026lt;p\u0026gt;There will be an unsubscribe link in the notification emails if you wish to unsubscribe.\u0026lt;/p\u0026gt; 39 \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34; class=\u0026#34;btn btn-primary comment-buttons ok\u0026#34;\u0026gt;OK\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; 40 \u0026lt;/div\u0026gt; 41 {{ range $paginator.Pages }} 42 {{ $params := dict \u0026#34;post\u0026#34; . }} 43 {{ partial \u0026#34;post_li\u0026#34; $params }} 44 {{ end }} 45 46 {{ partial \u0026#34;pagination\u0026#34; . }} 47 48\u0026lt;/div\u0026gt; 49{{ partial \u0026#34;footer_container.html\u0026#34; . }} 50{{ partial \u0026#34;footer.html\u0026#34; . }} Modified File: override.css In the config.toml, you can provide style overrides:\ncustom_css = [\u0026#34;override.css\u0026#34;] The relevant styling is all commented and looks like the following:\n122/* Staticman comment section and form */ 123 124.post-comments { 125 margin-top: 60px; 126} 127 128.post-comment { 129 background-color: rgb(247, 247, 247); 130 padding: 20px; 131 margin-top: 20px; 132} 133 134.post-comment-header { 135 margin-bottom: 20px; 136} 137 138.post-comment-avatar { 139 display: inline-block; 140 vertical-align: middle; 141 border-radius: 50%; 142} 143 144.post-comment-info { 145 display: inline-block; 146 margin-left: 20px; 147 margin-bottom: 0; 148 vertical-align: middle; 149} 150 151/* Part of blog subscription also */ 152.post-comment-field, .post-blogsubscriber-btn { 153 display: block; 154 font: inherit; 155 padding: 10px; 156 margin-top: 20px; 157 outline-color: #9b6bcc; 158 width: 100%; 159} 160 161.btn-primary.comment-buttons { 162 background: #9b6bcc !important; 163 border-color: #9b6bcc !important; 164 font-size: 0.9rem; 165 padding: 10px 14px 9px; 166 border-radius: 6px; 167} 168 169.btn-primary.comment-buttons:hover { 170 background: #53237f !important; 171} 172 173.post-comment-info .post-comment-name { 174 font-size: 1.4rem; 175 font-weight: 500; 176 177} 178 179.post-comment-info .post-time { 180 font-size: 14px; 181 font-weight: normal; 182 letter-spacing: 0.03em; 183 color: #888; 184 185} 186 187.post-comment-info .post-time:hover { 188 color: #9b6bcc; 189} 190 191 192/* End staticman comment section and form */ 193 194/* Staticman comment submission confirmation dialog */ 195 196.dialog { 197 display: none; 198 position: fixed; 199 background-color: rgb(247, 247, 247); 200 padding: 25px; 201 padding-top: 20%; 202 top: 0; 203 left: 0; 204 width: 100%; 205 height: 100%; 206 text-align: center; 207} 208 209.dialog:target { 210 display: block; 211} 212 213.dialog .btn-primary.comment-buttons.ok { 214 width: 7rem; 215} 216 217/* End staticman comment submission confirmation dialog */ 218 219/* Notify me of new comments checkbox */ 220 221input[type=checkbox].checkbox { 222 display: none; 223} 224 225.checkbox-label { 226 position: relative; 227 padding-left: 0px; 228 padding-bottom: 0px; 229 margin-top: 10px; 230 margin-bottom: 15px; 231 float: left; 232} 233 234.checkbox-label:before { 235 content: \u0026#39; \u0026#39;; 236 display: inline-block; 237 width: 25px; 238 height: 25px; 239 border-width: 1px; 240 border-style: solid; 241 vertical-align: middle; 242 position: relative; 243 bottom: 2px;color: rgb(169, 169, 169); 244} 245 246.checkbox:checked+.checkbox-label:after { 247 content: \u0026#39;x\u0026#39;; 248 display: inline-block; 249 position: absolute; 250 width: 25px; 251 height: 25px; 252 border-width: 2px; 253 line-height: 25px; 254 top: 11px; 255 left: 1px; 256 font-family: sans-serif; 257 text-align: center; 258} 259 260/* End notify me of new comments checkbox */ 261 262/* Subscribe to blog posts */ 263 264.post-blogsubscriber-field.left { 265 clear: left; 266 float: left; 267 font: inherit; 268 padding: 10px; 269 margin-top: 20px; 270 margin-bottom: 20px; 271 outline-color: #9b6bcc; 272 width: 48%; 273} 274 275.post-blogsubscriber-field.right { 276 clear: none; 277 float: right; 278 font: inherit; 279 padding: 10px; 280 margin-top: 20px; 281 margin-bottom: 20px; 282 outline-color: #9b6bcc; 283 width: 48%; 284} 285 286/* End subscribe to blog posts */ \nContributing back to the Hugo Academic theme The changes we\u0026rsquo;ve just been discussing have now been submitted back to mainline Hugo Academic theme.\n Issue Pull Request  ","date":1519383600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519383600,"objectID":"8c1858686da45536bb34cac2e723ed70","permalink":"https://binarymist.io/blog/2018/02/24/hugo-with-staticman-commenting-and-subscriptions/","publishdate":"2018-02-24T00:00:00+13:00","relpermalink":"/blog/2018/02/24/hugo-with-staticman-commenting-and-subscriptions/","section":"post","summary":"Adding Staticman commenting system to BinaryMist blog and Hugo Academic\n","tags":["hugo","free-and-open-source","web","web-application","css","go","captcha","mta"],"title":"Hugo with Staticman Commenting and Subscriptions","type":"post"},{"authors":null,"categories":null,"content":"Who is it for?\n Web Developers: There will be a choice of two streams in the morning. First stream covering introductory talks to information security, second stream covering deeper technical topics. Afternoon sessions will cover offensive security in stream one, and continue with deeper technical topics in stream two Security Professionals and Enthusiasts: Technical sessions later in the day will showcase new and interesting attack and defence topics  ","date":1517776200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517776200,"objectID":"f1d2c03eb7883e772eddf7332d5fcddc","permalink":"https://binarymist.io/talk/owaspnzday-2018/","publishdate":"2018-02-05T09:30:00+13:00","relpermalink":"/talk/owaspnzday-2018/","section":"talk","summary":"The eighth OWASP New Zealand Day conference, held at the University of Auckland.\n","tags":["conference","cloud-security","cybersecurity","information-security","owasp","owasp-nz-day","infosec","security","web-application-security","web-security"],"title":"Conference - OWASP New Zealand Day","type":"talk"},{"authors":null,"categories":null,"content":" Few organisations understand the secrets of shifting the focus on security from late in the software development life-cycle to within the Development Team.\nNot only does this significantly reduce the number of security defects being pushed to your production systems, but also significantly reduces the total cost of development.\nCheapest place to deal with defects There have been many studies specifically looking at the costs of finding and fixing defects early, as opposed to the planning of how to fix defects once the product is delivered, or not planning at all.\nThe following table shows the average cost of fixing defects based on when they were introduced versus when they are detected. Putting these practises in the right order can reduce costs of fixing security defects by up to 100 times.\n\nSo\u0026hellip; by simply shifting the security expertise from the end of the project to within the development team, thus enabling developers to find and fix their defects as they are being introduced, huge cost savings can be enjoyed.\nThis is not as difficult as you may think.\nOn the Day Kim will lead the class through the tools, techniques and thought processes of both red (attacking) and blue (defending) teams along with how to combine these attributes into the purple team focussing on security, productivity, and tasked with continuously delivering sustainable maintainable technical solutions to market.\nKim will explain the roles of \u0026rsquo;T\u0026rsquo; shaped professionals, including placement of security champions to create your purple Development Teams.\nWe will work through how to implement the Sensible Security Model (SSM) within each and every Sprint, including:\n Creating actionable countermeasure Product Backlog Items Integrating them into the same Product Backlog that your Development Team has been pulling business focussed items from Ordering them based on the risk ratings you create for each  Kim will discuss how and where Agile Development Teams often fail, along with how to succeed with security with a familiar anecdote. Then augmenting your Scrum process within each and every Sprint, with a collection of development focussed processes and practises, tools and techniques that have proven their value at drastically reducing defects before production deployment.\nKim will walk us through the SSM threat modelling process with theory and hands on exercises in areas such as Physical, People, VPS, Network, Cloud and Web Applications. Including sub topics such as Docker, Serverless, PowerShell and many others.\n\nMore Detail Training material will be augmented with Extracts from Kim\u0026rsquo;s interviews on Software Engineering Radio with security experts such as Diogo Mónica (Docker Security Team Lead) and Haroon Meer (creator of Canary tools and tokens).\n Each student will receive free copies of the first two parts of Kim\u0026rsquo;s book series \u0026ldquo;Holistic Info-Sec for Web Developers\u0026rdquo; (weighing in at approximately 700 pages) which this training is based on, as companion course material to accompany the training, to assist with ongoing self learning, and as a valuable reference resource long after the training has finished.   Learnings Coverage of topic chapters:\n Physical People VPS Network Cloud Web Applications  \nWhat others have said Enjoying the variety in @binarymist ‘s training today. So much content :) pic.twitter.com/OWKAFKFwu2\n\u0026mdash; Kylie McDevitt (@kylieengineer) October 26, 2017  \n","date":1517688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517688000,"objectID":"c7c53da44da53e6bdc88436a08bf7520","permalink":"https://binarymist.io/talk/owaspnzday-2018-workshop-building-security-into-your-development-team/","publishdate":"2018-02-04T09:00:00+13:00","relpermalink":"/talk/owaspnzday-2018-workshop-building-security-into-your-development-team/","section":"talk","summary":"Kim's flagship Software Developer focussed training, this time at OWASP New Zealand Day conference.\n","tags":["workshop","security","physical-security","people-security","vps-security","network-security","cloud","cloud-security","dev-ops","dev-sec-ops","docker","web-application-security","web-security","web-application","holistic-info-sec-for-web-developers","application-security","cybersecurity","information-security","security-weaknesses","software-security","hacking","conference","operational-efficiencies","owasp","owasp-nz-day"],"title":"Workshop - Building Security Into Your Development Teams","type":"talk"},{"authors":null,"categories":null,"content":" Synopsis Over the last four to five years I\u0026rsquo;ve been researching alternative bloggnig platforms in order to move from the Wordpress.com platform I\u0026rsquo;ve been blogging from.\nIn this post I\u0026rsquo;ll discuss the migration and consolidation of both the BinaryMist blog, and business site.\nFrom: Business Site Full custom Nodejs/Express in Docker container on AWS EC2, behind Cloudflare, using my aws-docker-host.\nBlog Wordpress.com\nTo: All in one: Business Site with Blog (you\u0026rsquo;re looking at it now)  Hugo with customised Academic theme Staticman for blog commenting (See the bottom of this post for the working example), as we will discuss in the next post, along with sign-up for receiving new post notifications as they are published (See the post list for the working example) Hosted directly from Github (gh-pages) Sitting behind Cloudflare. Cloudflare handles DNS, TLS, caching and expiration, minification, pretty much everything anyone would need for a static and in many cases dynamic website. When Github goes down, Cloudflare continues to serve your cached site  Why? Wordpress.com has so many issues that really bugged me. One of my goals was to do everything for no monetary cost.\nSome of the issues I had with The free Wordpress.com platform, unless I paid them money, and even if I did, most of these issues remain:\n Inflexibility Non-extensibility Buggy (especially for dealing with source code) Archaic workflow (logging in, admin interface, no source control) Very limited customisation Unable to apply styling Always felt like I was fighting the platform to do just about anything Multiple view ports were not well supported No control over improving performance Backups were a pain, I used wget scripts Charged for domain masking. All Github requires is a CNAME file So many other issues.  Requirements  Industry standard markdown instead of some flaky Wordpress editor that always tries to help your formatting, but ends up just getting in your way and doing it wrong. The code highlighting was a prime example of this Ideally I wanted to be able to easily display Github gists Work in source control, stay in the terminal and a text editor Vibrant community. With 104 posts over 8 years on Wordpress.com, it\u0026rsquo;s easy to understand that I take blogging seriously, so I need a platform that is going to be supported for a long time Have complete control of the entire system Easily share blog posts to social media platforms Ability to add tags and categories id attributes added to headings in posts (ideally automatically) Email notification of new blog posts Reader commenting and subscription to comment threads Ability to label posts with the author (Hugo is working on this). Not a show stopper for me Search: Wordpress.com has good search, and I find it really useful to find content that I know I\u0026rsquo;ve written about but can\u0026rsquo;t remember where it is  Platforms Investigated The following platforms are listed in order of least interesting to me -\u0026gt; to most. I have a bias toward Nodejs, but as you\u0026rsquo;ll see, the platform I chose wasn\u0026rsquo;t based on Nodejs. A lot of the information I used leading up to the final decision wasn\u0026rsquo;t recorded, as many of the reviews were carried out over the four to five year period, but I did keep an ordered list which was quite fluid, and this is what it looked like, from lowest scoring to highest.\nWheat Built on Nodejs. No longer actively maintained.\nhowtonode.org was running on Wheat. Browsing to now yields Internal Server Error.\nwheat2 used to be at https://github.com/c9/nog but now yields 404.\nAll the other resources I had links to are now dead.\nI think we can safely say Wheat is dead. Please correct me if you know something I don\u0026rsquo;t on Wheat?\n Github: https://github.com/creationix/wheat  Used to be a React blog (jlongster.com) Cool! I like React. Community, docs, activity? Ah\u0026hellip; no.\nKerouac Built on Nodejs/Express. Allows you to add dynamic functionality as you have full access to express.\n Github: https://github.com/jaredhanson/kerouac  Github stars: 84\nGithub contributors: 1\nJekyll I had a play with this Ruby platform about four years ago, along with octopress and at that point it didn\u0026rsquo;t score very high for me. Don\u0026rsquo;t ask me to much about it now\u0026hellip; it was four years ago. 😨\nHugo vs Jekyll points (From George Cushen (Hugo theme Academic creator))\n Home: https://jekyllrb.com Github: https://github.com/jekyll/jekyll  Github stars: 32618\nGithub contributors: 750\nWintersmith Built on Nodejs with coffee script\n Home: http://wintersmith.io Github https://github.com/jnordberg/wintersmith Good examples: https://github.com/jnordberg/wintersmith/wiki/Showcase  Github stars: 3286\nGithub contributors: 41\nKeystoneJS Built on Nodejs/Express and MongoDB\n Home: http://keystonejs.com Github: https://github.com/keystonejs/keystone  Github stars: 11707\nGithub contributors: 196\nDocPad Built on Nodejs/Express. Completely file based. No databases, but can use one if you want.\n Home: http://docpad.org Github: https://github.com/docpad/docpad  Github stars: 2945\nGithub contributors: 43\nGhost Built on Nodejs/Express. I know a few people that have had good success with Ghost.\n Home: https://ghost.org/ Github: https://github.com/TryGhost/Ghost  Github stars: 24681\nGithub contributors: 278\nHarp Built on Nodejs.\n Home: http://harpjs.com Github: https://github.com/sintaxi/harp  Github stars: 4571\nGithub contributors: 23\nHugo Written in Go, Hugo has been around since June 2013, and is reaching maturity quickly. Has a very large base of consumers and committers. Excellent documentation, both official and community provided. Has hundreds of customisable themes produced by many contributors. Builds your pages of markdown in \u0026lt; 1 ms per page. There is no such thing as waiting for your site to build. I\u0026rsquo;ve spent about four weeks on the BinaryMist site and it\u0026rsquo;s a dream to work with. Instant live reload out of the box also makes working with Hugo frictionless.\nAll the content you will need to create can be done so in markdown, in your file-system, in source control, in the terminal. Backups are no longer an issue.\nAny of the theme aspects you can override, simply by copying the specific template or partial from your chosen theme layout directory to the same structure within your sites root directory and making your desired modifications. If you make large changes, consider submitting them back to the theme repository by way of Pull Request (go-on, give back), which is what I did with my Staticman additions to the Academic theme.\nHugo has shortcodes for many things. such as embedding speakerdeck presentations, different video formats, (examples here) tweets, (example), plus you can create your own custom shortcodes. Gists are easily pulled in with the Hugo gist shortcode\nThe Hugo highlight shortcode is powerful, flexible, and just seems to work well. Many languages and styles are supported out of the box (code examples below are using it). If for some reason, it doesn\u0026rsquo;t give you enough power, then just use something else. You\u0026rsquo;re not locked into anything.\nSearch, although I haven\u0026rsquo;t got this set-up yet. Let me know if you would find this helpful. Either contact me, leave a comment, or submit an issue, as I\u0026rsquo;m generally lazy and may not get a round to it unless someone puts some pressure on me.\nThe biggest problem for me was migrating existing Wordpress.com posts. I ended up just creating a collection of redirects to the legacy posts. In saying that, some appear to have had better success, but I just gave up on migrating.\nExitwp seems to be the main tool for (WP -\u0026gt;) Immigrants.\n Abhishek Pandey Migration Venkatt Guhesan Migration  wp2hugo is another.\nThen there is Hugo migration docs.\n\n Home: https://gohugo.io Github: https://github.com/gohugoio/hugo  Github stars: 22219\nGithub contributors: 521\nHugo Themes Knock yourself out: https://themes.gohugo.io/\nI chose Academic, as it was the closest fit for when I realised I could combine both blog and business site.\nAt this point, I was still thinking I\u0026rsquo;d have to host the website in a Docker container using my aws-docker-host which works flawlessly and costs nothing, but as Docker is completely unnecessary if you have Github with a decent CDN in front of it, like Cloudflare, I\u0026rsquo;ll skip the process I took to work out how that would be done. If you are interested, just ask in the comments section bellow.\nThe Process I needed to move the legacy BinaryMist blog, which was long over due for this, from Wordpress.com to Github. I\u0026rsquo;ve added redirect stubs to the list of posts, that lead to many of the legacy posts on the Wordpress.com platform which haven\u0026rsquo;t been migrated to the new platform. Going forward, all posts will be published from binarymist.io/blog.\nOnce I found the theme for Hugo that would work best for my needs, I realised, I\u0026rsquo;d be able to not only migrate the blog, but also the BinaryMist business site, both to a really flexible platform.\nI can work on blog posts on a specific branch without pushing to Github until finished, or just mark them as draft = true, or put the date to sometime in the future in the post\u0026rsquo;s front-matter. This allows one to work on other content and merge reader comments (if you have them set-up, which I do) which are issued as pull requests directly into this Github repo by Staticman.\nSetting up Hugo As I was playing with the Academic theme, and reading a blog post from the Academic creator, the version of Hugo in the Ubuntu Software Sources was very old, so I installed Hugo (.deb binary) on my machines, starting with the directions here, which linked to Hugo Releases.\ncd ~ wget https://github.com/gohugoio/hugo/releases/download/v0.31/hugo_0.31_Linux-64bit.deb # or what ever the latest version is. # This is where you should check the checksum... Then: sudo dpkg -i hugo*.deb Once I had Hugo installed, I Worked through step 2 and 3 of the quick start guide to create the site, committing each change as I went:\nFrom my local Source directory:\nhugo new site BinaryMistBlog cd BinaryMistBlog git init # As I had decided to use the academic theme: git submodule add https://github.com/gcushen/hugo-academic.git themes/academic Now from step 3, 4 and 5 of the Installation section of the Getting Started post from the Demo/exampleSite\n# Copy the example site to that which will become your personal site cp -av themes/academic/exampleSite/* . # Start hugo hugo server By the way, hugo server is about the only command I use when working on my site. There is one other script that gets used to make my site live, but I\u0026rsquo;ll cover that in a bit.\nOnce you\u0026rsquo;ve done any customisations you may want to do to your new site (of course you can do this latter instead if you like), it\u0026rsquo;s time to set-up how you are going to deploy your static site. For me, hosting directly from where your source control is is a no-brainer. Once this is set-up, there is one script to run every time you want to deploy, which as I said, I\u0026rsquo;ll cover soon.\nI chose to have my source on the master branch, and my generated site (which is generated to the public/ directory of my local sites root directory, on the gh-pages branch.\nBefore the following steps, I needed to install the latest git as there was a bug in the current version in the Ubuntu Software Sources that affects the git worktree feature. The resources I used for this:\n https://github.com/gohugoio/hugo/issues/3232 https://discourse.gohugo.io/t/github-deployment-using-worktrees-failing/5918/7 https://discourse.gohugo.io/t/simple-deployment-to-gh-pages/5003\nwhich led to: https://unix.stackexchange.com/questions/33617/how-can-i-update-to-a-newer-version-of-git-using-apt-get  To get your new git:\nsudo add-apt-repository ppa:git-core/ppa sudo apt-get update sudo apt-get install git Now\u0026hellip; for the next steps, head on over to: Preparations for gh-pages Branch.\nThen add the commands to a script as the documentation suggests. There is a script that you can take and customise. My script looks like this:\n#!/bin/bash # Run from public if [[ $(git status -s) ]] then echo \u0026#34;The working directory is dirty. Please commit any pending changes.\u0026#34; exit 1; fi cd .. echo \u0026#34;Deleting old publication\u0026#34; rm -rf public mkdir public git worktree prune rm -rf .git/worktrees/public/ echo \u0026#34;Checking out gh-pages branch into public\u0026#34; git worktree add -B gh-pages public origin/gh-pages echo \u0026#34;Removing existing files\u0026#34; rm -rf public/* echo \u0026#34;Generating site\u0026#34; hugo echo \u0026#34;Updating gh-pages branch\u0026#34; echo \u0026#34;cd\u0026#39;ing into public\u0026#34; cd public echo \u0026#34;Adding back the CNAME after deletion\u0026#34; echo binarymist.io \u0026gt; CNAME echo \u0026#34;git add\u0026#39;ing all to staging\u0026#34; git add --all echo \u0026#34;git commit\u0026#39;ing\u0026#34; git commit -m \u0026#34;Publishing to gh-pages (publish.sh)\u0026#34; echo \u0026#34;Do you wish to push this commit?\u0026#34; select yn in \u0026#34;Yes\u0026#34; \u0026#34;No\u0026#34;; do case $yn in Yes ) git push origin gh-pages; break;; No ) exit;; esac done \nMy Hugo Workflow OK, so we\u0026rsquo;re ready to start customising our site and blogging. My workflow involves one console (terminator, that\u0026rsquo;s on Linux of course) split into four terminals:\n Terminal 1 runs hugo server, I leave this running, it tells me if I introduce any errors, as I introduce them, and tells me what they are, as Hugo uses live reload, everything is instant, so you know as soon as you make any change if there is an issue Terminal 2 runs my diffing tool (currently diffuse) as in, from within the root directory of my source, I just [up-arrow] -\u0026gt; [Enter] (which gives me diffuse -m) any time I want to check my changes Terminal 3 Stays on my master branch. This is where I git status, git commit, git push from, etc. What happens in master in no way affects what is being pushed to gh-pages (live) though. hugo generates the static site from what ever is in the working directory, see next terminal All that happens in the forth terminal, is I run ../publish-to-gh-pages.sh from the sites root directory, which makes the site live. That\u0026rsquo;s right, one script to make your site live  Now this is frictionless blogging 😆\nIf you are interested in getting a similar site set-up and are struggling, let me know and I\u0026rsquo;ll be happy to help.\nIn the next post we will discuss how commenting and blog subscription was set-up\u0026hellip; Introducing dynamic behaviour to a static website\u0026hellip;\n","date":1516964400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516964400,"objectID":"3b7744f18c4cc920889abd313dfa7465","permalink":"https://binarymist.io/blog/2018/01/27/binarymist-web-migration/","publishdate":"2018-01-27T00:00:00+13:00","relpermalink":"/blog/2018/01/27/binarymist-web-migration/","section":"post","summary":"In this post we discuss the move from the legacy BinaryMist blog on Wordpress.com, along with the BinaryMist website, to a single static site on the Hugo platform hosted on Github Pages.\n","tags":["hugo","go","free-and-open-source","git","web","web-application","deployment","nodejs"],"title":"BinaryMist Web Migration","type":"post"},{"authors":["Kim Carter"],"categories":null,"content":" \n This show made it into the VertitechIT list of Best IT Podcasts for 2018.\nThis is the second show Kim has hosted that\u0026rsquo;s made it into this list.   \u0026nbsp;\nShow Outline Basic Questions  When moving to the Cloud, our servers/compute, storage, and many other physical aspects have now become abstract concepts. As a Software Engineer, what thoughts do you have on how we need to change our approach to security when moving to the cloud? Can you explain what the Shared Responsibility Model is, how it is supposed to work, and what sort of misconceptions are around it? In terms of the Shared Responsibility model, what aspects of security is the CSP (Cloud Service Provider) responsible for?\n(CSP takes care of infrastructure, not customer specific config of it)\n(Due to scale of large CSPs, they should have good security resources) In terms of the Shared Responsibility model, what is the customer responsible for?\n(Their people -\u0026gt; AppSec -\u0026gt; configuring their infrastructure, using CSPs security features, concrete example of which security features we can use?) What do you see as our highest risks in handing everything over to CSPs? (fully understanding the Shared Responsibility Mode, people security (ignorance), application security (appsec with Zane Lackey #309), misconfiguration)  Assets  Has what we are trying to protect as Software Engineers and the organisations we work for changed much from the exodus of on-premise to The Cloud and how so? How do we need to adjust our thinking so that our security focus is in the right areas, and how should our focus have changed? What are the benefits of cloud computing, what are our assets we need to consider when threat modelling The Cloud and the suitability of various providers?\n(productivity, competitive advantage, control, customer data, reputation)  Risks \u0026amp; Countermeasures  I often receive questions from Software Engineers like “As a software engineer, do I really care about network security”. Network security used to be slightly less of an issue for Software Engineers than it is now, network security used to be primarily the Network Administrator\u0026rsquo;s responsibility. Now that our infrastructure and networks are expressed by code, with infrastructure and configuration management tools such as: Terraform (which we’ve had a show on #289 with James Turnbull)), Ansible, Docker and others. What are your thoughts around the responsibility of network security now falling in the laps of Software Engineers? I work a lot with AWS, which provides a security abstraction model. We can create objects like:\n VPC Security groups and roles Ingress and egress rules Access control lists (ACLs) Security roles attached to instances Roles consisting of a set of profiles, etc   Then we have another abstraction layer with tools such as terraform, which allow us to build these resources declaratively, rather than imperatively. This allows us to conceptualize and build what we want without understanding low level constructs such as firewalls (iptables), how to configure Cisco appliances, etc, and where to put these in our network topology. This dumbs down the skill set Software Engineers need. It also allows programmers to become network engineers in a sense. Do you see this as a step forward, or a step backward, or both?\n  \n As customers of The Cloud, we have little visibility of the internal workings or implementations of the infrastructural abstractions provided to us. Trust is a core concept that we are yielding to our providers. All software has bugs, How can we be sure that our chosen CSP is fixing their bugs quickly and not exposing us to undue risk? Is catastrophic data loss more of an issue in the cloud than it was on-prem due to CSP customers just believing the CSP will take care of it and occasionally failing?  Evaluating CSPs I want to talk a bit about how we can evaluate if using any given CSP is going to provide a high enough level of security for us and our customers\u0026hellip; We’re going to discuss techniques we can use to compare different CSPs offerings, and whether or not they’re fit for our purpose. Feel free to mention any you can think of as we work through the following list\u0026hellip;\n What are your thoughts on keeping signed audit logs on UIs and APIs\n(AWS has CloudTrail)? How many CSPs are encrypting all comms between servers and CSP components within their data centres and also their service providers? What can we do to improve this situation? Are CSPs providing customers access to infrastructural logs, what does that access look like, and how much is filtered before we get our hands on them? What happens with our data when we terminate our accounts with our provider or migrate to other providers? Do we know where our services and data physically reside, In many cases CSPs are outsourcing their outsourced services to several providers deep. They do not even have visibility themselves. Often the data is hosted in other jurisdictions. What can we do about this? More crypto, then it doesn’t matter? Do we know who can view the data we store in the cloud (CSP employees), What checks and controls do the major CSPs have in place to make sure that this data can not be read or exfiltrated? How many CSPs allow customers to carry out regular penetration testing of production and/or test environments? What are your thoughts on whether CSPs should run bug bounty programs? Are any CSPs standing out that you think are doing a decent job of their responsibilities, and helping potential customers understand where the lines of separation are in terms of the Shared Responsibility Model?  CSP vs In-house  What are some of the aspects that are more secure in The Cloud than In-House? CSPs are tasked with taking care of aspects such as:\n General infrastructure Hardware Hosting Continuously hardening components and infrastructure Patching components only visible to the CSP Network firewall routes and rules of the CSPs core infrastructure Network component logging NIDS Regular penetration testing   Do those organisations contemplating In-house Cloud solutions need to consider all of these aspects?\n  \n Any thoughts on how we can raise awareness on how the security dynamics change from self-hosting to all in “the Cloud”? What else do people need to think about, evaluate? How can we be better prepared for CSPs being forced to give up our and our customers data to governing authorities and others without our permission or even knowledge in many cases? Does this just come down to using more crypto? What else can we do? On the topic of crypto, where do you see the government crusade against end-to-end encryption leading? What are your thoughts, as in costs and benefits around vendor lock-in in regards to leveraging the proprietary services and offerings of individual CSPs?  Other Risks  CSPs provide many security enhancing services and features, most of which I see Software Developers and people above them in the org chart think of as inconveniences. How can we encourage Developers and others to use the security features? More security by default? Other ideas?\n(culprits: single user root, least privilege violations, storage of secrets - private key abuse - credential sharing) Any thoughts or security concerns around Serverless technologies that “look” new, or that as Software Engineers we need to be thinking about?  Countermeasures - Take Aways  You created FLAWS.cloud as a free online CTF/tutorial to help recognise common misconfigurations and gotchas in AWS. Can you talk a little bit about this? You were on the Purple Squad Security podcast recently discussing “Detecting Intruders on AWS”. Can you give us a bit of a rundown on what was discussed? You also wrote an article recently on “Potential Gaps in Suggested Amazon Web Services’ Security Policies for MFA” What goodness do you have to share with our listeners from this? I know of and documented Security Monkey in the cloud chapter of my second book, for the listeners, can you talk a bit about this and also Airbnb’s StreamAlert? How can Software Engineers help to educate the C levels of the perils often not realised with the exodus to The Cloud, along with the considerations and countermeasures to establish a somewhat secure working environment, other than listening to today\u0026rsquo;s show? If there was only one piece of advice you could offer our Software Engineers today to help lift the security bar within their personal lives and the organisations they work within, what would it be?  ","date":1516060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516060800,"objectID":"46152791ca80107896c5c9e9e9b184d2","permalink":"https://binarymist.io/publication/ser-podcast-cloud-security/","publishdate":"2018-01-16T00:00:00Z","relpermalink":"/publication/ser-podcast-cloud-security/","section":"publication","summary":"Founder of Summit Route / creator of FLAWS, Scott Piper talks with Kim Carter about Cloud Security on Software Engineering Radio.\n","tags":["publication","podcast","cloud","cloud-security","information-security","infosec","security","cybersecurity"],"title":"Scott Piper on Cloud Security","type":"publication"},{"authors":["Kim Carter"],"categories":null,"content":" Check out Kim\u0026rsquo;s blog post which goes into some of the detail within this book, along with what others are saying about Docker Security.\n\nPlease note that the entire content of this book is included in The VPS chapter of Holistic InfoSec for Web Developers F1.\n\nErrata (errors, typos, etc.)  Submit an issue Open issues Closed issues  ","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"67af9463ae212110f0f8dd73a61f43d9","permalink":"https://binarymist.io/publication/docker-security/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/docker-security/","section":"publication","summary":"Are you looking to improve the security of your Docker deployments? Do you want to confirm you haven't missed any important security aspects in your Docker infrastructure?\n","tags":["publication","book","application-security","capabilities","control-groups","cybersecurity","dev-ops","dev-sec-ops","docker","information-security","infosec","linux","lsm","namespaces","seccomp","security","security-weaknesses","software-security","web-application-security"],"title":"Docker Security - Quick Reference","type":"publication"},{"authors":["Kim Carter"],"categories":null,"content":" Cloud Security \u0026nbsp; - \u0026nbsp; Quick Reference \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; Providing insight into the shared responsibility model of the Cloud. Making sure your security stature in the Cloud is where you need it to be? Providing the architectural and technical direction required to create your secure Cloud environment. This entire content is included in The VPS chapter of Holistic InfoSec for Web Developers F1.\n     Docker Security \u0026nbsp; - \u0026nbsp; Quick Reference \u0026nbsp;\u0026nbsp;\u0026nbsp; The security defaults of Docker are established to get you up and running (“just work”) quickly, rather than being the most secure. In this book we improve upon many default configurations. Including knowledge gleaned from the Docker Security Team Lead. This entire content is included in The VPS chapter of Holistic InfoSec for Web Developers F1.\n     Holistic Info-Sec for Web Developers Fascicle 0 The first part of a three part book series providing broad and in-depth coverage on what Software Developers/Engineers, DevOps Engineers and architects need to know in order to create robust, reliable, maintainable and secure software, networks and other, that are delivered continuously, on time, with no nasty surprises.\n     Holistic Info-Sec for Web Developers Fascicle 1 The second part of a three part book series providing broad and in-depth coverage on what Software Developers/Engineers, DevOps Engineers and architects need to know in order to create robust, reliable, maintainable and secure software, networks and other, that are delivered continuously, on time, with no nasty surprises.\n     Holistic Info-Sec for Web Developers Fascicle 2 The third part of a three part book series providing broad and in-depth coverage on what Software Developers/Engineers, DevOps Engineers and architects need to know in order to create robust, reliable, maintainable and secure software, networks and other, that are delivered continuously, on time, with no nasty surprises.\n    \n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"e7dd107a5ae47cd69c777bf673cb2482","permalink":"https://binarymist.io/publication/kims-selected-publications/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/kims-selected-publications/","section":"publication","summary":"Kim is an avid writer on technical topics, be sure to review his releases.","tags":null,"title":"Kim's Books","type":"publication"},{"authors":null,"categories":null,"content":"  Are security reviews and penetration testing efforts costing you too much? Are you struggling with security defect counts being too high in the products your development teams are producing? Maybe you just don\u0026rsquo;t know where to start with introducing security to your development work-flow? Are your competitors beating you to market? Maybe your customers are starting to demand higher security and protection of their data?  What if we told you: That by working with you we can reduce the amount you spend on traditional security reviews, penetration testing, and at the same time reduce the defects being introduced, and significantly improve your security stature, while reducing total project cost?\nTogether we could help get your product to market quicker, and with fewer security defects, or if your product is already in use, provide the assurity you need that it will withstand the attacks of your adversaries.\nWe can provide the visibility you need to make good judgement calls on the direction of your products and customers security.\nWe can give you the ability to prove to your customers that you are taking the security of their data seriously, which is often a great marketing point as well, and that your product(s) are a much safer investment than your competitor\u0026rsquo;s?\nOutcomes: Let us create a roadmap for your development team(s) to follow, thus enabling them to:\n Implement the light weight Process and Practises, Tools and Techniques required to take the ownership of their security Find and fix defects as they are being introduced (cheapest place), rather than late in the development life-cycle (dearest place), as discussed in Kim\u0026rsquo;s training Provide immediate and continuous visibility and measurability of the projects security stature     --\n\n If you would get excited about similar results\u0026hellip;\n \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nReview our Portfolio and Testimonials for some of the teams we have helped reduce costs and security defect counts by shifting the security focus up front of the development life-cycle.\nWhat our customers are saying \n Pete Nicholls\n Trineo\n Kim’s expertise and insights helped shape our security strategy. Kim’s experience enabled us to adopt best practices in a way that fits our teams and focuses on what really works.\nSecurity is difficult to do alone. The more experience you can leverage the better. Kim can help you on your security journey by showing you what works and what doesn’t, and help you avoid common mistakes. We’re in a stronger position for having hired him.\nAs a person, Kim is highly-focused, knowledgeable, and always to the point: someone you can collaborate with who will make the most of the time you spend with him.\n \n Andrew Balfour\n Owner/Managing Director, Solvam Corporation Ltd\n Kim Carter was engaged on a contract basis to implement and guide our future software development for School-links. www.school-links.co.nz\nIn doing that he -\n Brought to our product a much higher level of expertise and capability complementing our development team Directed a disciplined and methodical software development process as the Scrum Master of ‘Scrum’ Helped with the restructuring and planning of our infrastructure in order to scale the product successfully Brings security expertise at a high level with the ability to implement ongoing security hardening program and audits Introduced the Scrum process which provided more consistent and accurate release cycles enabling our marketing efforts to be better coordinated and focused  Kim is a good team member and we will look to reengage with his services when required.\n \nWe have had the unique opportunity to work in both defensive (development) and offensive (penetration testing) teams, across many domains, for a large number of years. This has produced a deep understanding of what development team(s) need in order to help you create solutions that will effectively resist attacks from your adversaries.\n  \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nWe can only take on a very limited number of road-mapping engagements.\n\n","date":1513123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513123200,"objectID":"0f967b2c337316c656a2b62fe0a41f31","permalink":"https://binarymist.io/project/service-development-team-security-roadmap/","publishdate":"2017-12-13T00:00:00Z","relpermalink":"/project/service-development-team-security-roadmap/","section":"project","summary":"Too many security defects in your Development Team(s) deliverables?\nExternal security reviews too costly? Let us create a security roadmap for your Development Team(s).","tags":["service","development-team-security-service","productised-service","agile","security","cybersecurity","infosec","dev-ops","dev-sec-ops","operational-efficiencies","software-security","web-application-security"],"title":"Development Team Security Roadmap $2995NZ + GST","type":"project"},{"authors":null,"categories":null,"content":" Not sure of how secure your business assets are? Maybe you are thinking about establishing a security roadmap or checkpoints, but unsure of where to start, or which step to take next.\nYou may already be on the information security journey, but need some reassurance and clear direction along the way that you are investing in the areas that are most cost effective.\nThere are ways to significantly reduce the costs of security, even use security as a positive marketing avenue. Customers love it when they know you\u0026rsquo;re taking the security of their data seriously.\nMaybe you build software in-house and your development team(s) could do with some assistance and a sounding board to bounce their security related questions off?\nOr maybe you have customers that entrust their personal data to you to manage and store in the Cloud?\nHow it works Our agreement entitles you to unlimited 24\u0026frasl;7 access to Kim via phone, SMS, email, Slack, Skype, Signal, Telegram, or other Instant Messaging service. I return all messages no later than the next business day, although in practice response time is usually much quicker (particularly between 9am to 6pm NZT, but also nights and weekends).\nMeetings are scheduled in advance, typically take place over the phone, and are sometimes supplemented with on-line meeting and/or screen sharing software (e.g. Google Hangouts, appear.in, Skype, etc).\nThere are several possible areas of involvement:\n Regular meetings with the primary project contact to discuss strategy, longer-term issues, and business goals. Strategic and tactical advice based on a series of ongoing meetings with team leaders. These are individualised and mutually agreed upon. In addition, I\u0026rsquo;ll serve as a sounding board as they work to achieve their business and technical goals. Technical review of architecture, work-flows, source code, documentation, and the like. Where appropriate, I\u0026rsquo;ll provide code samples, or proof-of-concept examples. Please note that authoring shipping code, designs, or documentation is not included in this agreement. Situational responsiveness to needs that arise that you deem require my assistance, which are not covered elsewhere.  Our fee covers four months, we arrange and pay for any necessary administrative expenses such as discussed communication mediums. Professional courtesy discounts are available for recurring annual arrangements.\n\nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\n  Founder and CEO, InventoryTech Limited\n Kim provided us with excellent support services during a development transition with our cloud software services.\nKim is a highly capable software developer with deep experience and capabilities.\nI recommend Kim\u0026rsquo;s services, he did a great job for us.\n \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nParticipation is extremely limited. You can elect to be added to the waiting list if spots are not available.\n\n","date":1513123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513123200,"objectID":"7303b0d00bab93c69076d03bb4c9d903","permalink":"https://binarymist.io/project/service-security-strategy-retainer/","publishdate":"2017-12-13T00:00:00Z","relpermalink":"/project/service-security-strategy-retainer/","section":"project","summary":"Our agreement entitles you to unlimited 1 on 1 access to Kim via phone, SMS, email, Slack, Skype, Signal, etc. Participation is limited to 10 people. Fee is for four months.","tags":["service","organisational-security-service","productised-service","cybersecurity","information-security","infosec","operational-efficiencies","security","software-security","web-security"],"title":"Security Strategy Retainer $3495NZ + GST","type":"project"},{"authors":null,"categories":null,"content":" Few organisations understand the secrets of shifting the focus on security from late in the software development life-cycle to within the Development Team.\nNot only does this significantly reduce the number of security defects being pushed to your production systems, but also significantly reduces the total cost of development.\nCheapest place to deal with defects There have been many studies specifically looking at the costs of finding and fixing defects early, as opposed to the planning of how to fix defects once the product is delivered, or not planning at all.\nThe following table shows the average cost of fixing defects based on when they were introduced versus when they are detected. Putting these practises in the right order can reduce costs of fixing security defects by up to 100 times.\n\nSo\u0026hellip; by simply shifting the security expertise from the end of the project to within the Development Team, thus enabling developers to find and fix their defects as they are being introduced, huge cost savings can be enjoyed.\nThis is not as difficult as you may think.\nOn the Day Kim will lead the class through the tools, techniques and thought processes of both red (attacking) and blue (defending) teams along with how to combine these attributes into the purple team focussing on security, productivity, and tasked with continuously delivering sustainable maintainable technical solutions to market.\n Location At your venue  Links  PDF  Source Book Series  Kim's other Workshops     \nKim will explain the roles of \u0026rsquo;T\u0026rsquo; shaped professionals, including placement of security champions to create your purple Development Teams.\nWe will work through how to implement the Sensible Security Model (SSM) within each and every Sprint, including:\n Creating actionable countermeasure Product Backlog Items Integrating them into the same Product Backlog that your Development Team has been pulling business focussed items from Ordering them based on the risk ratings you create for each  Kim will discuss how and where Agile Development Teams often fail, along with how to succeed with security with a familiar anecdote. Then augmenting your Scrum process within each and every Sprint, with a collection of development focussed processes and practises, tools and techniques that have proven their value at drastically reducing defects before production deployment.\nKim will walk us through the SSM threat modelling process with theory and hands on exercises in areas such as Physical, People, VPS, Network, Cloud and Web Applications. Including sub topics such as Docker, Serverless, PowerShell and many others.\nReserve Your Workshop Currently we have availability for select new clients.\nReserve Your Workshop\n\nMore Detail Training material will be augmented with Extracts from Kim\u0026rsquo;s interviews on Software Engineering Radio with security experts such as Diogo Mónica (Docker Security Team Lead) and Haroon Meer (creator of Canary tools and tokens).\n Each student will receive free copies of the first two parts of Kim\u0026rsquo;s book series \u0026ldquo;Holistic Info-Sec for Web Developers\u0026rdquo; (weighing in at approximately 700 pages) which this training is based on, as companion course material to accompany the training, to assist with ongoing self learning, and as a valuable reference resource long after the training has finished.   Minimum of four students per workshop.\nLearnings Coverage of topic chapters:\n Physical People VPS Network Cloud Web Applications  \nWhat others are saying Enjoying the variety in @binarymist ‘s training today. So much content :) pic.twitter.com/OWKAFKFwu2\n\u0026mdash; Kylie McDevitt (@kylieengineer) October 26, 2017  \nReserve Your Workshop Currently we have availability for select new clients.\nReserve Your Workshop\n\n","date":1513036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513036800,"objectID":"12485e23a52740fad07aa714b5b436d5","permalink":"https://binarymist.io/project/service-development-team-security-training/","publishdate":"2017-12-12T00:00:00Z","relpermalink":"/project/service-development-team-security-training/","section":"project","summary":"Full Day Interactive Workshop focussing on building security into your Development Team(s).","tags":["service","development-team-security-service","productised-service","workshop","agile","security","cybersecurity","information-security","infosec","dev-ops","dev-sec-ops","operational-efficiencies","software-security","web-security","people-security","physical-security","vps","vps-security","networking","network-security","web-application-security","docker","cloud","cloud-security","holistic-info-sec-for-web-developers"],"title":"Building Security into Your Development Teams (workshop) $495 + GST per student","type":"project"},{"authors":["Kim Carter"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"4aa253f15a6a9eb6586fd7c5a4425fe7","permalink":"https://binarymist.io/publication/holistic-infosec-for-web-developers/","publishdate":"2017-12-01T00:00:00Z","relpermalink":"/publication/holistic-infosec-for-web-developers/","section":"publication","summary":"A three part book series focused on lifting the security knowledge of Software Developers, Engineers, and their teams, so that they can continuously deliver secure technical solutions on time and within budget, without nasty surprises.\nFirst book is complete, second book is content complete and currently in technical review. ","tags":["publication","book","agile","application-security","arp-poisoning","arp-spoof","asic","ath9k-htc","atdd","backups","bcrypt","bithound","blowfish","burp-suite","capabilities","captcha","cipher","cloud","cloud-security","control-groups","cracking","crypto","cryptography","csrf","css","cybersecurity","debian","dev-ops","dev-sec-ops","dmz","docker","dot-net","dsniff","eksblowfish","encryption","exim","express","field-programmable-gate-arrays","filtering","fire-wall","forever","fpga","free-and-open-source","freebsd","ftp","gnu-linux","gpg","gpu","hacking","hash-dump","hashing","hids","hips","hmac","holistic-info-sec-for-web-developers","hydra","ids","information-security","infosec","ips","javascript","kali","kali-linux","kdf","key-derivation-function","linux","logging","lsass","lsm","namespaces","macof","md5","metasploit","mimikatz","mitm","monit","morgan","mta","networking","network-security","nids","nightly-build","nips","nmap","nodejs","nodemailer","npm","ntp","operational-efficiencies","ossec","owasp","owasp-top-10","owasp-zap","passenger","pbkdf2","penetration-testing","pm2","people-security","pgp","physical-security","posix","power-shell","prf","ps","pseudorandom-function","reconnaissance","relp","requiresafe","retirejs","rsyslog","safenuget","salt","sanitisation","scp","scrum","scrypt","seccomp","secure-boot","security","security-weaknesses","selenium","serverless","sha-1","sha-2","sha-256","sniffing","software-security","sql-injection","ssh","stdd","stealth","supervisor","sys-admin","syslog","systemd","sysvinit","tcp","tdd","telnet","test","testing","tls","tl-wn722n","udp","uefi","upstart","validation","virtualbox","virtualisation","vps","vps-security","waf","wce","web","web-application","web-application-security","web-security","wi-fi","winston","winston-syslog","winston-syslog-posix","wireless","wireless-networking","wireshark","xss","zap"],"title":"Holistic Info-Sec for Web Developers","type":"publication"},{"authors":null,"categories":null,"content":"   \n","date":1511406000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511406000,"objectID":"443b61ad30e28d40261b758dcf76cae7","permalink":"https://binarymist.io/talk/bsides-talk-wellington-secrets-of-a-high-performance-security-focussed-agile-team/","publishdate":"2017-11-23T16:00:00+13:00","relpermalink":"/talk/bsides-talk-wellington-secrets-of-a-high-performance-security-focussed-agile-team/","section":"talk","summary":"At BSides Wellington: Kim discusses that Quality (security included) does not have to be neglected when you’re planning, building and running a high performance development team. He discusses how we fail and how to succeed.\n","tags":["talk","dev-ops","dev-sec-ops","conference","agile","application-security","ci","continuous-integration","cybersecurity","holistic-info-sec-for-web-developers","information-security","nightly-build","owasp-zap","scrum","tdd","testing","web","web-application","web-application-security","web-security","zap"],"title":"Talk - Secrets of a High Performance Security Focussed Agile Team","type":"talk"},{"authors":["Kim Carter"],"categories":null,"content":"\n","date":1510617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510617600,"objectID":"ef9be14813dbec8ec3175b3347427cc1","permalink":"https://binarymist.io/publication/ser-podcast-application-security/","publishdate":"2017-11-14T00:00:00Z","relpermalink":"/publication/ser-podcast-application-security/","section":"publication","summary":"Zane Lackey talks with Kim Carter about Application Security on Software Engineering Radio.\n","tags":["publication","podcast","application-security","software-security","web-application-security","cybersecurity","security","information-security","infosec"],"title":"Zane Lackey on Application Security","type":"publication"},{"authors":null,"categories":null,"content":"","date":1509062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509062400,"objectID":"db576f52f5ac7c2d165950c5c88cfc1b","permalink":"https://binarymist.io/project/external-project-chcon2018/","publishdate":"2017-10-27T00:00:00Z","relpermalink":"/project/external-project-chcon2018/","section":"project","summary":"\nThe third CHCon: A conference aiming to raise awareness and skill levels of information security within our community.\n","tags":["project","conference","cybersecurity","information-security","infosec","security","hacking"],"title":"Christchurch Hacker Con","type":"project"},{"authors":null,"categories":null,"content":" Who is it for? You! IT security professionals, web developers, software developers, students, wannabes, hackers, enthusiasts, etc\n","date":1508961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508961600,"objectID":"82faa8b88b0044c6cf1ef1b879a302fa","permalink":"https://binarymist.io/talk/chcon-2017/","publishdate":"2017-10-26T09:00:00+13:00","relpermalink":"/talk/chcon-2017/","section":"talk","summary":"CHCon 2017: A conference for security professionals and hackers, based in Christchurch, NZ.\n","tags":["conference","cloud-security","cybersecurity","information-security","infosec","security"],"title":"Conference - Christchurch Hacker Con","type":"talk"},{"authors":["Kim Carter"],"categories":null,"content":"   \n","date":1508889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508889600,"objectID":"b7378999ab7d57912e031932ba30e27c","permalink":"https://binarymist.io/publication/alldaydevops2017-interview-secrets-of-a-high-performance-security-focussed-agile-team/","publishdate":"2017-10-25T00:00:00Z","relpermalink":"/publication/alldaydevops2017-interview-secrets-of-a-high-performance-security-focussed-agile-team/","section":"publication","summary":"All Day DevOps Live! Interview with All Day DevOps speaker, Kim Carter. Kim will be speaking about the \"Secrets of a High Performance Security Focused Agile Team\".\n","tags":["publication","podcast","conference","cybersecurity","security","holistic-info-sec-for-web-developers","information-security","infosec","software-security","dev-sec-ops"],"title":"Pre Conference Interview","type":"publication"},{"authors":null,"categories":null,"content":" Kim will explain the roles of \u0026rsquo;T\u0026rsquo; shaped professionals, including placement of security champions to create your purple Development Teams.\nWe will work through how to implement the Sensible Security Model (SSM) within each and every Sprint, including:\n Creating actionable countermeasure Product Backlog Items Integrating them into the same Product Backlog that your Development Team has been pulling business focussed items from Ordering them based on the risk ratings you create for each  Kim will discuss how and where Agile Development Teams often fail, along with how to succeed with security with a familiar anecdote. Then augmenting your Scrum process within each and every Sprint, with a collection of development focussed processes and practises, tools and techniques that have proven their value at drastically reducing defects before production deployment.\nKim will walk us through the SSM threat modelling process with theory and hands on exercises in areas such as Physical, People, VPS, Network, Cloud and Web Applications. Including sub topics such as Docker, Serverless, PowerShell and many others.\nMore Detail Training material will be augmented with Extracts from Kim\u0026rsquo;s interviews on Software Engineering Radio with security experts such as Diogo Mónica (Docker Security Team Lead) and Haroon Meer (creator of Canary tools and tokens).\nCopies of the first two parts of Kim\u0026rsquo;s book series \u0026ldquo;Holistic Info-Sec for Web Developers\u0026rdquo; (weighing in at approximately 700 pages) which this training is based on, will be provided as: companion course material to accompany the training, ongoing self learning, and as a valuable reference resource long after the training has finished.\nLearnings Coverage of topic chapters:\n Physical People VPS Network Cloud Web Applications  \nWhat others have said Enjoying the variety in @binarymist ‘s training today. So much content :) pic.twitter.com/OWKAFKFwu2\n\u0026mdash; Kylie McDevitt (@kylieengineer) October 26, 2017  \n","date":1508875200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508875200,"objectID":"5dfb43fb02ab7b2cbb7b913bc20d2622","permalink":"https://binarymist.io/talk/chcon-workshop-building-security-into-your-development-team/","publishdate":"2017-10-25T09:00:00+13:00","relpermalink":"/talk/chcon-workshop-building-security-into-your-development-team/","section":"talk","summary":"Kim's flagship Software Developer focussed training, this time at Christchurch Hacker Conference (CHCon).\n","tags":["workshop","security","physical-security","people-security","vps-security","network-security","cloud","cloud-security","dev-ops","dev-sec-ops","docker","web-application-security","web-security","web-application","holistic-info-sec-for-web-developers","application-security","cybersecurity","information-security","security-weaknesses","software-security","hacking","conference","operational-efficiencies"],"title":"Workshop - Building Security Into Your Development Teams","type":"talk"},{"authors":null,"categories":null,"content":"   \n","date":1508815800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508815800,"objectID":"1556185fa68839df56872a36cb3eba60","permalink":"https://binarymist.io/talk/all-day-devops-2017-talk-secrets-of-a-high-performance-security-focussed-agile-team/","publishdate":"2017-10-24T16:30:00+13:00","relpermalink":"/talk/all-day-devops-2017-talk-secrets-of-a-high-performance-security-focussed-agile-team/","section":"talk","summary":"Kim discusses how and why Agile Development Teams fail at security, and how to stop failing.\n","tags":["talk","dev-ops","dev-sec-ops","conference","agile","application-security","ci","continuous-integration","cybersecurity","holistic-info-sec-for-web-developers","information-security","nightly-build","owasp-zap","scrum","tdd","testing","web","web-application","web-application-security","web-security","zap"],"title":"Talk - Secrets of a High Performance Security Focussed Agile Team","type":"talk"},{"authors":null,"categories":null,"content":" This post was taken from the content of the Cloud chapter of Kim\u0026rsquo;s book Holistic Info-Sec for Web Developers F1\nRisks The shared responsibility model is one that many have not grasped or understood well. Let’s look at the responsibilities of the parties.\nCSP Responsibility The CSP takes care of the infrastructure, not the customer specific configuration of it, and Due to the shear scale of what they are building, are able to build in good security controls, in contrast to the average system administrator, which just does not have the resources or ability to focus on security to the same degree.\nDue to the share scale, the average CSP has a concentrated group of good security professionals vs a business who’s core business is often not closely related to security. So CSPs do provide good security mechanisms, but the customer has to know and care enough to use them.\nCSPs creating the infrastructural architecture, building the components, frameworks, hardware, platform software in most cases are taking security seriously and doing a reasonable job.\nCSP Customer Responsibility CSP customers are expected to take care of their own security in terms of:\n Their people working with the technology Application security, ultimately leading back to shortcomings in people: Lack of skills, experience, engagement, etc. Configuring the infrastructure and/or platform components: Again leading back to people defects  but all to often the customers responsibility is neglected, which renders The Cloud no better for the customer in terms of security.\n The primary problem with The Cloud is: Customers have the misconception that someone else is taking care of all their security. That is not how the shared responsibility model works though. Yes the CSP is probably taking care of the infrastructure security, but other forms of security such as I just listed above, are even more important than before the shift to The Cloud, this is because these items are now the lowest hanging fruit for the attacker.\n The following are a set of questions (verbatim) I have been asked recently, and that I hear similar versions of frequently:\n As a software engineer, do I really care about physical network security and network logging? Surely “as a software engineer”, I can just use TLS and that is the end of it? Well if the machine is compromised, then we give up on security, we aren’t responsible for the network What is the difference between application security and network security? Aren’t they just two aspects of the same thing? If I have implemented TLS for communication, have I fixed all of the network security problems?  Countermeasures The following responsibilities are those that you need to have a good understanding of in order to establish a good level of security when operating in The Cloud.\nCSP Responsibility There is not a lot you can do about this, just be aware of what you are buying into before you do so. AWS for example states: \u0026ldquo;Customers retain control of what security they choose to implement to protect their own content, platform, applications, systems and networks, no differently than they would for applications in an on-site datacenter.\u0026ldquo;\nCSP Customer Responsibility If you leverage The Cloud, Make sure the following aspects of security are all at an excellent level:\n People security: Discussed in Fascicle 0 under the People chapter Application security: Discussed in the Web Applications chapter. The move to application security was also discussed in the VPS chapter as a response of using Docker containers Configuring the infrastructure and/or platform components: Usually CSP specific, but I cover some aspects in this chapter  The following is in response to the set of frequently asked questions under the risks subsection of CSP Customer Responsibility:\n (Q): As a software engineer, do I really care about physical network security and network logging?\n(A): In the past, many aspects of network security were the responsibility of the Network Administrators, with the move to The Cloud, this has to large degree changed. The networks established (intentionally or not) between the components we are leveraging and creating in The Cloud are a result of Infrastructure and Configuration Management, often (and rightly so) exp3ressed as code. Infrastructure as Code (IaC). As discussed in the Network Security subsection, this is now the responsibility of the Software Engineer (Q): Surely “as a software engineer”, I can just use TLS and that is the end of it?\n(A): TLS is one very small area of network security. Its implementation as HTTPS and the PKI model is effectively broken. If TLS is your only saviour, putting it bluntly, you are without hope. The Network Chapter covers the tip of the network security ice berg, network security is a huge topic, and one that has many books written along with other resources that provide more in-depth coverage than I can provide as part of a holistic view of security for Software Engineers. Software Engineers must come to grips with the fact that they need to implement defence in depth (Q): Well if the machine is compromised, then we give up on security, we aren’t responsible for the network\n(A): For this statement, please refer to the VPS chapter for your responsibilities as a Software Engineer in regards to “the machine”. In regards to “the network”, please refer to the Network Security subsection (Q): What is the difference between application security and network security? Aren’t they just two aspects of the same thing?\n(A): No, for application security, see the Web Applications chapter. For network security, see the Network chapter. Again, as Software Engineers, you are now responsible for all aspects of information security (Q): If I have implemented TLS for communication, have I fixed all of the network security problems?\n(A): If you are still reading this, I’m pretty sure you know the answer, please share it with other Developers, Engineers as you receive the same questions  ","date":1506855600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506855600,"objectID":"0bb5ec923381da9f99bbb1f887b9c3ac","permalink":"https://binarymist.io/blog/2017/10/02/the-cloud-shared-responsibility-model/","publishdate":"2017-10-02T00:00:00+13:00","relpermalink":"/blog/2017/10/02/the-cloud-shared-responsibility-model/","section":"post","summary":"The shared responsibility model is one that many have not grasped or understood well. Let’s look at the responsibilities of the parties.\n","tags":["cloud","security","cloud-security","cybersecurity","docker","holistic-info-sec-for-web-developers","infosec"],"title":"The Cloud Shared Responsibility Model","type":"post"},{"authors":null,"categories":null,"content":" Security Review - Node.js Microservices\n    Security Review of clients (bank in jakarta) Dockerised NodeJS microservices. Common Technologies:  Node.js 8.5 hapi, joi Docker OpenShift     See testimonial by Stefan Streichsbier\n","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"9d80f1094a8b48fac3cd51c911515dd2","permalink":"https://binarymist.io/project/portfolio-numisec/","publishdate":"2017-10-01T00:00:00Z","relpermalink":"/project/portfolio-numisec/","section":"project","summary":"Security Review - Node.js Microservices","tags":["portfolio","security-portfolio"],"title":"Numisec Pte.","type":"project"},{"authors":["Kim Carter"],"categories":null,"content":" \nShow Outline Basic Questions  What is network security? What is application security? Just as with any other form of security, the first thing we need to think about is, what’s valuable to us in regards to network security, what are we attempting to protect and why? One of the comments I received recently was “as a software engineer, do I really care about physical network security” Why should Software Engineers care? What’s changed with computer network security over the last five to ten years? Has this shifted the reliance that your average attacker used to have on network security exploitation skills to other areas such as cloud services, application security, and of course people, and how so? According to FBI investigators, the likely avenue of infiltration of the Yahoo internal network was with a spear phishing email to a semi-privileged unsuspecting/inadvertent Yahoo employee. The successful spear phish allowed the attackers direct access to Yahoo\u0026rsquo;s internal network… What are your thoughts about the fact that the attacker just about always still needs a network in order to access their target, whether the initial foothold be physical, people, VPSs, network components, cloud resources, mobile or IoT devices? In high security environments, unlike Yahoo, what I’ve found is that many of the common application security defects and attacks don’t work, and the attacker has to resort to attacking hosts, networks, physical premises and of course people, as in social engineering them. Can you explain your experience around how high security environments differ from the average or low security environments? What do Software Engineers now need to understanding about computer network technologies in order to mitigate attackers using them as a channel to assist exploiting areas of a business and gaining access to their assets?  Risks Let’s talk about some of the ways an attacker can get access to an organisation’s prized possessions.\nFortress / Candy Bar Mentality Let’s discuss the Fortress or Candy Bar mentality.\n This is where organisations believe that all of their attackers are on the outside of the organisation, and those on the inside are trustworthy. What are your thoughts around this?   IBM X-Force - Cyber Security Intelligence Index researches a large number of organisations each year, and they’ve extracted some interesting data:\n2014\n 55% of all attacks were carried out by insiders 31.5% were malicious inside actors 23.5% were inadvertent inside actors  2015\n 60% of all attacks were carried out by insiders 44.5% were malicious inside actors 15.5% were inadvertent inside actors  2016\n 30% of all attacks were carried out by insiders 7% were malicious inside actors 23% were inadvertent inside actors    The Yahoo data breach and many others every day confirm that a large percentage of all security breaches come from within the organisations walls…\nDo you think that this is an indicator that our workers are succumbing to an increased number of social engineering attacks by outside attackers attempting to get their payloads inside the organisation’s networks? What are your thoughts around establishing a perimeterless network culture, where all components are treated as though they are directly accessible from the Internet? How do we go about achieving this For our listeners, can you define what command and control is? How do we stop insiders and outsiders connecting to our network access points and proliferating malware, C2 (define C2) clients, etc onto our corporate networks? How can we stop our transient staff from picking up malware at home or on the road and then propagating it on our corporate networks?  Segmentation Creating perimeterless networks can be evolutionary. Until we get to that point, segmentation can help us by allowing us to harden sections of our networks at a time. It also provides us with levels of isolation for critical services.\n Can you explain what network segmentation is, and what are some of the risks likely to occur if well thought out segmentation is not implemented? Apparently most of our IoT devices need to have internet access, one of the problems here is that there is little to no thought to building security into the components and the devices as a whole. How would we apply network segmentation to these devices, would it improve the security issues we have with IoT, if so, how?  Visibility  If you don’t have visibility as to what’s happening on your network at all levels, then chances are things are happening that you don’t want happening. There are known attacks that target each of the network layers. What are some of the attacks that we need visibility on? What are some of the techniques and practises for creating visibility on the different levels? Where aboustwhere can we set-up network logging? How do we make sure those logs are reliable and have not been tampered with? What are NIDS, how do they work, what do they give us in terms of visibility? Can you give an explanation of the differences between the signature-based and anomaly-based detection techniques? Maybe with some pros and cons of each? What are some of the well known NIDS? Where would I set a NIDS up?  Spoofing  Can you explain what spoofing is and how it works? What are the different types of spoofing attacks?\n(IP, ARP, DNS, Referrer, EMail Address, Website) Often spoofing is used as a component to a larger attack, can you explain how it might fit into a larger attack?\n(website spoof as part of a phish) (ARP and DNS often combined with other spoofs) What are some of the countermeasures we could put in place to mitigate the different types of spoofing attacks?  Data Exfiltration, Infiltration What is data infiltration, exfiltration?\n What are some of the infiltration, exfiltration techniques and tools commonly used?\n(Dropbox, physical, mobile phone data, DNS/SSH) Let’s say you’re hired as a penetration tester to hack a security conscious organisation and steal their data, a bank for example. The organisation has no public internet facing application that has access to the internal organisations data. The only means of egress is via a very restrictive proxy. Assuming we know where the data is, how would we go about exfiltrating the data?\n(DNS tunnelling) What are some of the countermeasures we could put in place to mitigate the different techniques for infiltration and exfiltration? What could Yahoo have done to:  Slow down the exfiltration of 1 billion user accounts in 2013 \u0026amp; 500 million user accounts in 2014? Protect the secrets, namely MD5 passwords that were exfiltrated in 2013?   Trusting the Loading of Untrusted Web Resources  A very common technique for attackers wishing to get their malicious scripts into the end users browser is by intercepting the request and swapping parts of the response with their malicious scripts. What are some of the evils an attacker may be able to have executed in the end user’s browser? What are some countermeasures to help stop the loading of untrusted web resources and how do they work?\n(CSP, SRI)  TLS Downgrade  A fairly common attack with TLS is to attempt a downgrade, what is a TLS downgrade and how does it work? What are some of the mitigations available to help stopping a downgrade?\n(HSTS, HSTS Preload)  Shift from NetSec to AppSec, CloudSec, SocEng  The most effective targeted attack techniques today are still the simple password stealing, spear phishing (as with Yahoo), web shells, social media and weaponised documents. Most of which have a reliance on network vulnerabilities somewhere. What are the network security vulnerabilities that allow these types of attacks? Another incident that affected Yahoo involved the attackers forging cookies, rather than requiring passwords as a way to break into user accounts, 32 million user accounts were affected using this technique. This was due to the fact that the attacker had the cookie creation code that didn\u0026rsquo;t even need a password, so this sounds like defective code? Application security? What other types of networks do you think we as Software Engineers should be concerned about in order to mitigate attacks via these mediums?  ","date":1505174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505174400,"objectID":"2b513fdb2636846c693771f6512832a7","permalink":"https://binarymist.io/publication/ser-podcast-network-security/","publishdate":"2017-09-12T00:00:00Z","relpermalink":"/publication/ser-podcast-network-security/","section":"publication","summary":"Haroon Meer talks with Kim Carter about network security on Software Engineering Radio.\n","tags":["publication","podcast","application-security","hacking","cybersecurity","arp-poisoning","arp-spoof","security","information-security","infosec","hids","hips","ips","networking","network-security","nids","nips","penetration-testing","software-security","sql-injection","web-application-security","web-security"],"title":"Haroon Meer on Network Security","type":"publication"},{"authors":null,"categories":null,"content":" Numisec Pte. Ltd\n I\u0026rsquo;ve met Kim at DevSecCon Singapore in 2017 where he gave a well-received workshop. A few months later we had a project where his top-notch strong Node.js security code review skills were required and this gave us the chance to work together closely.\nOver a 2 week period he was doing security code reviews of containerized Node.js microservices in a very thorough way. We communicated well and progressed quickly. Kim has a very broad yet deep understanding of modern application security that comes from years of experience. I can recommend Kim to anyone who needs an application security expert and wants a professional second opinion on the security posture of an application.\n","date":1500768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500768000,"objectID":"c9e58a5262dcfbcfd1c469c398ef5b84","permalink":"https://binarymist.io/project/testimonial-stefan-streichsbier/","publishdate":"2017-07-23T00:00:00Z","relpermalink":"/project/testimonial-stefan-streichsbier/","section":"project","summary":"Numisec Pte. Ltd","tags":["testimonial"],"title":"Stefan Streichsbier","type":"project"},{"authors":null,"categories":null,"content":" DevOps Implementation and Security Review\n    Provided security review, devops review, support, detailed road map and Product Backlog detailing path along with work items to improvement. Set-up Process and Practises to introduce higher quality within development teams. Increase speed of Software/Product delivery. Automation of monitoring and actions on various AWS components.    Established culture, tools and techniques across the development teams:\n Security Regression Testing Static analysis, Cyclomatic complexity Continuous Integration (Jenkins, CircleCI) Pair Review and Programming  Additional details on Kim\u0026rsquo;s LinkedIn\n","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"de673f7f526ebb481947da3431a44030","permalink":"https://binarymist.io/project/portfolio-mobiddiction/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/project/portfolio-mobiddiction/","section":"project","summary":"DevOps Implementation \u0026#38; Security Review","tags":["portfolio","architecture-engineering-portfolio","devops-portfolio","security-portfolio"],"title":"Mobiddiction","type":"project"},{"authors":null,"categories":null,"content":" Kim will be covering:\n Threat modelling Developer security Physical security Social Engineering VPS security / hardening Network Security Cloud Security Application Security  There will be prizes worth working for, especially the team that takes first place.\nIf you want to win, I\u0026rsquo;d suggest getting familiar with the content in my book series.\nQuestions have also come from many other sources\nThe below was the quiz:\n \nWhat others have said   \n\n","date":1498633200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498633200,"objectID":"eb3a718d95610b2359d06fe4a10c2521","permalink":"https://binarymist.io/talk/owaspnz-chch-meetup-2017-workshop-quiz-night/","publishdate":"2017-06-28T19:00:00+12:00","relpermalink":"/talk/owaspnz-chch-meetup-2017-workshop-quiz-night/","section":"talk","summary":"Attacking a set of carefully curated questions around info-sec, white hat, black hat, attack and defense.\n","tags":["workshop","hacking","application-security","csrf","cloud-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","networking","network-security","owasp","people-security","physical-security","sanitisation","security","security-weaknesses","software-security","sql-injection","ssh","vps","vps-security","web","xss"],"title":"Workshop - Web Developer Quiz Night","type":"talk"},{"authors":["Kim Carter"],"categories":null,"content":" \nShow Outline Basic Questions Can you give a quick explanation of how Docker containers work for our listeners?\nIf you were an attacker looking to compromise Docker, knowing what the weakest areas are, where would you start and what would be your first targets in terms of the surrounding technologies?\n\u0026nbsp;\nI’m going to address each of the areas in turn, you mentioned a while ago, that we should address\u0026hellip;\nApplication security more important than isolation One of the things you mentioned was that “application security is so much more important than container/VM isolation”, such as:\n Namespaces Control Groups Linux Security Modules (SELinux and AppArmor) Capabilities Secure Computing Mode (Seccomp) Filesystem mounts  Can you give us some more detail around what you mean by this?\nIn your blog post Increasing Attacker Cost using Immutable Infrastructure, the overarching theme is that application security is still the lowest hanging fruit for an attacker. Near the end of your blog post you have a link to Docker Security Features, which seems to be mostly focussed on the isolation features I just mentioned. Why is Docker isolation much less important than appsec?\nOur applications over the past 15 years in general are not getting any more secure. We’ve been trying to educate developers around the issues, but I\u0026rsquo;m not convinced that it\u0026rsquo;s working, any ideas on how we can improve this situation?\nInspect app behaviour inside containers, but not VMs In our pre show discussions, you mentioned that: “You can inspect behaviour of an app inside of a container, but you can’t inside of a VM”. My thoughts around that comment, were that in VMs or VPSs in general we have:\n Application logging Instrumenting from within: statsd, collectd, graphite \u0026hellip; and others Instrumentation externally: Monit and various other PaaS offerings  Is there any reason why we shouldn’t use the same tools, or are there offerings more specific to containers that we can use to inspect app behaviour and if so, what are they?\nImmutability One of your other pre show comments was that “Containers win due to observation and immutability”. Can you explain the immutable copy-on-write filesystem, how it helps us, and how we can take maximum advantage of this?\nRead-only You also mentioned pre show that\u0026hellip; “You can’t run a VM with --read-only, but with Docker it is trivial”. My thoughts around those comments, were that\u0026hellip;\nyou can run anything that has a filesystem that has to be mounted, as read-only. Can you explain the fundamental difference of running a container as read only vs running a VM or any VPS with granular read only filesystem mounts?\nHow does your logging strategy look when running a container as --read-only?\nOrchestration You mentioned in our pre show discussions that you thought the orchestration layers where a lot more interesting and impactful to companies security than isolation concepts, layers such as:\n Mutual TLS/PKI by default Secrets distribution Least privilege orchestration Content scanning Image signatures, Also discussed below under Consumption from Registries Secure/trusted build pipelines  Can you elaborate a bit on each of these in turn?\nSGX, SCONE In our previous discussion, you also mentioned how “Intel Software Guard Extensions (SGX)” along with “Secure CONtainer Environment (SCONE)” was going to make an impact on how we employ security in our Docker environments. SCONE depends on Intels SGX, which itself has come under some heavy criticism from security researchers at MIT.\n Explain Intel Software Guard Extensions (SGX) Explain SCONE  Arguments against SGX The startup configuration file (SCF) has to be sent once the container (enclave) is initialised. So the container owner has to trust the enclave in the untrusted remote cloud system. SGX solves this conundrum with a mechanism known as attestation which relies on a train of trust to Intel verifying the hardware (https://blog.acolyer.org/2016/12/14/scone-secure-linux-containers-with-intel-sgx/). Intel intends the symmetrical provisioning key to reside both in the SGX-enabled chip and in Intel servers. To establish an enclave, the software will offer its provisioning key to Intel, and if there\u0026rsquo;s a match in the database, Intel will issue the attestation key that lets SGX set up the enclave. The SGX patents disclose in no uncertain terms that the Launch Enclave was introduced to ensure that each enclave’s author has a business relationship with Intel, and implements a software licensing system. So we’re effectively trusting Intel as author and owner of our destiny? (http://www.theregister.co.uk/2016/02/01/sgx_secure_until_you_look_at_the_detail/)\nWhat is to stop Intel selling our information to the highest bidder?\nGeneral isolation A monolithic kernel containing tens of millions of lines of code which are reachable from untrusted applications via all sorts of networking, USB and driver APIs Has a huge attack surface. It seems that adding Docker into the mix exposes all these vulnerabilities to each and every running container, thus making the attack surface grow exponentially.\nCan you explain how the security of libcontainer which is now the default Container Format layer works, and what is to stop attackers by-passing it and attacking the underlying huge attack surface of the shared kernel?\nIn terms of performance, containers outperform VMs because they share the same host kernel and operating system resources, would you say that in terms of isolating malware, VMs do a better job?\nFrom the Docker overview, it says: Docker provides the ability to package and run an application in a loosely isolated environment. Initially this doesn’t install a lot of confidence that malware can’t easily spread, or an attacker can’t traverse environments.\nFrom the Docker overview, it says: Encapsulate your applications (and supporting components into Docker containers”. The meaning of encapsulate is to enclose, but If we’re only loosely isolating, then we’re not really enclosing are we? Can you shed some light on this seemingly set of contradictory statements?\nWhat are your thoughts around the recent (Jan 10 Fix) container escape 0day (CVE-2016-9962) reported by Aleksa Sarai to Nathan McCauley that affects Docker \u0026lt;1.12.6?\n(http://seclists.org/fulldisclosure/2017/Jan/21) It allows additional container processes via runc exec to be ptraced by pid 1 of the container, allowing the main processes of the container, if running as root, to gain access to file-descriptors of these new processes during the initialization and can lead to container escapes or modification of runC state before the process is fully placed inside the container.\nMajor Subtopics Consumption from Registries You’ve got the Docker Registry which is an open-source server side application that lets you store and distribute Docker images. Some of the instances of the registry are:\n Docker Hub EC2 Container Registry Google Container Registry CoreOS quay.io Other Private instances  It’s up to the person consuming images from docker hub to assess whether or not they have vulnerabilities in them. I’ve read that No security inspection by Docker is performed on docker hub images whether un-official or official. How true is this?\nThere are a number of good tooling options coming available to help with the finding and mitigation of security vulnerabilities. Can you talk through some of the better ones and how they help?\nI’ve seen a good number of reports stating high numbers of security vulnerabilities within images on Docker Hub, even upto 90% of official images. Can you talk about a case where a registry consumer was compromised due to a vulnerability in the image that they pulled down and spun up?\nWhat guarantees do Docker Hub consumers have around the integrity of images?\nCovering:\n Where an image originated from Who created it Image Provenance: Is Docker fetching the image we think it is? With this point, can you go into:  How Docker uses secure hash’s or the digest Secure signing and where notary fits in The Dockerfile producing different images over time, specifying a tag in the FROM instruction, and using the digest to pull the same image each time   Security Defaults Many of Dockers defaults seem to be designed to allow dev-ops to get up and running with the least amount of friction and in minimal time. In adopting Docker are we trading off security for the other benefits of containerization?\nImages derived from other images inherit the same user defined in the parent image explicitly or implicitly, so in most cases this will default to root.\nDockers default is to run containers, and all commands / processes within a container as root. Was this a decision made with the aim of “making things just work”?\nIs it possible to run Docker as a low privileged user, does this break anything?\nOften I find within my Dockerfile that I perform an action such as copy a bunch of files as a non-root user and Docker applies root ownership to the copied files. Why is Docker not copying files according to the user I am set to run commands as?\nHardening Docker Engine and containers The thing that bugs me the most about Docker is that there is so much that needs to be known in order to establish a somewhat secure environment for running Docker containers, but that’s not well understood - it has been sold as a simple, easy solution.\nIn terms of how to go about providing least privileges to any process within a container to only the syscalls, APIs, sections of memory, etc that it needs, and nothing else, let’s look at:\n Namespaces Control Groups Linux Security Modules (SELinux and AppArmor) Capabilities Secure Computing Mode (Seccomp) Filesystem mounts  Namespaces  What are Linux Namespaces? Which component of Docker creates and manages the namespaces and how does Docker use them? How can Engineers leverage Namespaces to improve their security?  Can you explain a bit about the new User Namespaces, how they help us and how to use them?\n mnt (manages filesystems and mount points) PID (process isolation) net (manages the network stack and interfaces) UTS (Unix Timesharing System, isolating kernel and version identifiers) IPC (manages access to InterProcess Comms) user  Control Groups What are Control Groups, and how can they be used to help secure containers?\nLinux Security Modules Linux Security Modules (LSM) such as AppArmor and SELinux are a framework that’s been part of the Linux kernel since 2.6, that supports security models implementing Mandatory Access Control (MAC).\nCan you briefly explain Linux Security Modules and how they implement mandatory Access Control?\nAppArmor and SELinux are the two most common LSM’s accepted in the Linux kernel. Docker provides a usable interface to these LSMs.\nCan you explain what this interface looks like, and how Docker users should go about using it?\nCapabilities Can you briefly explain what capabilities are in the context of computer science, what they do to the root user, and how can we set them up for a Docker container to apply least privilege?\nSeccomp Can you give us a bit of an idea of what Secure Computing Mode (SecComp) is and does for us, and then explain how Docker takes advantage of it?\nHow can we increase the number of disabled System calls available in a Docker container?\ndocker [run|create] --security-opt seccomp=/path/to/seccomp/profile.json hello-world Filesystem Mounts On a physical server or VPS, we can control the mount attributes of our many file systems with the /etc/fstab. What are the best ways to apply the same attributes to the file systems of our Docker containers, is it just adding the --read-only flag on container start?\nWhat else do we need to be aware of around applying least privilege to our file system mounts and how can we go about doing this?\nrunC Can you explain what runC is, what it gives engineers, and how we should use it?\nShould we be using runC commands now instead of Docker commands?\nShould engineers run run spec to generate the host independent config.json and host specific runtime.json specification files, which they then need to edit and apply sensible security settings around the previously discussed:\n Namespaces Control Groups Linux Security Modules (SELinux and AppArmor) Capabilities Seccomp Filesystem mounts  Docker has many security enhancing capabilities, but which are actually on by default?\nWhat about Docker Engine Can you explain what the Docker engine components are, and are there any risks to each of these components that we haven\u0026rsquo;t discussed and really should?\nThe Docker engine is comprised of:\n The server or daemon process. The REST API which specifies interfaces that programs can use to talk to the daemon and tell it what to do. A command line interface (CLI) client  What can we do to harden each of these components?\nBest Practises Are there any other publicly available best practices for Docker security available besides the Centre for Internet Security Docker Benchmark?\nWhere abouts can we find sample codes and configurations that will help listeners improve the security of their Docker containers and infrastructure?\n","date":1494288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494288000,"objectID":"0da72d3c5077bdd1f268524a068cd9d9","permalink":"https://binarymist.io/publication/ser-podcast-docker-security/","publishdate":"2017-05-09T00:00:00Z","relpermalink":"/publication/ser-podcast-docker-security/","section":"publication","summary":"Diogo Mónica talks with Kim Carter about Docker Security on Software Engineering Radio.\n","tags":["publication","podcast","cybersecurity","dev-ops","dev-sec-ops","security","information-security","infosec","docker","application-security","software-security"],"title":"Diogo Mónica on Docker Security","type":"publication"},{"authors":["Kim Carter"],"categories":null,"content":"","date":1492646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492646400,"objectID":"59c20d221c5cbcf3391f41a9c7dd7795","permalink":"https://binarymist.io/publication/javascriptjabber-interview-kims-career-story/","publishdate":"2017-04-20T00:00:00Z","relpermalink":"/publication/javascriptjabber-interview-kims-career-story/","section":"publication","summary":"Charles Max Wood interviews Kim Carter to find out more about his journey into programming and information security!\n","tags":["publication","podcast","cybersecurity","security","holistic-info-sec-for-web-developers","information-security","infosec","software-security"],"title":"Kim's Career Story","type":"publication"},{"authors":null,"categories":null,"content":"Who is it for?\n Web Developers: There will be a choice of two streams in the morning. First stream covering introductory talks to application security, second stream covering deeper technical topics. Afternoon sessions will cover various defensive topics, with a DevSecOps cluster of talks in stream two after afternoon tea break Security Professionals and Enthusiasts: Technical sessions later in the day will showcase new and interesting attack and defence topics  ","date":1492635600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492635600,"objectID":"8d85c2842876465d0d775601df3e2e22","permalink":"https://binarymist.io/talk/owaspnzday-2017/","publishdate":"2017-04-20T09:00:00+12:00","relpermalink":"/talk/owaspnzday-2017/","section":"talk","summary":"The eighth OWASP New Zealand Day conference, held at the University of Auckland.\n","tags":["conference","cloud-security","cybersecurity","information-security","owasp","owasp-nz-day","infosec","security","web-application-security","web-security"],"title":"Conference - OWASP New Zealand Day","type":"talk"},{"authors":["Kim Carter"],"categories":null,"content":"\n","date":1492473600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492473600,"objectID":"e27f152bd2a56a06c968b23b6d8ea8df","permalink":"https://binarymist.io/publication/ser-podcast-devsecops/","publishdate":"2017-04-18T00:00:00Z","relpermalink":"/publication/ser-podcast-devsecops/","section":"publication","summary":"Francois Raynaud and Kim Carter discuss what’s wrong with the traditional delivery approach and why we need to change. On Software Engineering Radio.\n","tags":["publication","podcast","cybersecurity","security","information-security","infosec","dev-ops","web-security","web-application-security","dev-sec-ops","operational-efficiencies","agile"],"title":"Francois Raynaud on DevSecOps","type":"publication"},{"authors":["Kim Carter"],"categories":null,"content":" \nShow Outline Success Skills  In your own words, what is a software architect? How do the required skills change from the roles of Engineering to Architecture? What are the top 4 skills required to be the best Software Architect anyone can be? How have these changed over the last few years and how do you see them changing over the next 5 \u0026amp; 10 years? What do you think about the idea that Architects are born predisposed with a special set of attributes?  Soft skills Problem solving  Can you discuss clever code, maybe with an anecdote, and why it’s hard to maintain? Eliminating complexity was discussed in the book that you were involved with: “97 Things Every Software Architect Should Know”. How do we eliminate complexity, and do you have any examples? Why is keeping things simple such an important attribute to try an obtain? Keeping things simple is often harder than it sounds, why is that? What do you do as an architect when you just don’t have the skills required for a particular problem?  Productivity \u0026amp; communications, collaborate  What key attributes and activities have you discovered to be important in order to better communicate with stakeholders?  History  Some of the quotes you’ve mentioned on your website such as:  Those who cannot remember the past are condemned to repeat it. –George Santayana The past is never dead. It’s not even past. –William Faulkner\nstrike a chord with me.  Why is history so important, and why should we learn it? How do we help our young engineers understand the importance of learning our history?  Bringing change  What pearls of wisdom do you have around successfully bringing changes into an organisation or team?  Possibly discuss Fearless Change by Mary Lynn Manns \u0026amp; Linda Rising  As an architect, what do the essential sales skills look like? How do you go about selling your ideas? How much experience have you had in changing an organisations culture, and how have you gone about it?  People skills Leadership  Is an architect a manger?  If not why not? How are they different?  What does it take to be a good mentor, what are some of the skills required? What is a level 5 leader? (servanthood vs dictatorship)  Are level 5 leaders made or born?  Refactoring, or keeping technical debt levels low, often goes unseen, and it’s only the conscientious that care enough to take the initiative to do it. How do you as an architect look for these attributes of excellence in individual team members, and train others such as PO’s \u0026amp; managers to understand and recognise these attributes in team members?  Teams  In terms of empowering developers, what are some of the most effective ways you’ve found to do this? What are some of your techniques in creating high performing teams, that also keep levels of technical debt at a manageable level?  Negotiation  For a while I’ve had this metaphor of the Architect\u0026rsquo;s role as being this person that rides the elevator of a tall building all day. Architects seem to be jack of all trades, master of none, or few. Riding the elevator to the basement where the Engineers work, up to the top floor where the C levels work, and translating one to the other. How do you see the Architect\u0026rsquo;s role? What skills does an Architect need to successfully negotiate between all parties within an organisation?  Meetings  What techniques do you use to transfer essential information amongst software engineers, other than adding more meetings, which are often counter-productive?  Possibly discuss pair programming as a means for transferring knowledge  What tips do you have for hyper-productive meetings?  Building a Tech Radar  You’ve written on building a technology radar. Can you talk a bit about that, what the bubble is, the dangers of living inside, how to avoid it, and how to build and maintain that tech radar? You’ve talked about “Avoiding Yesterday’s Best Practice from Becoming Tomorrow’s Antipattern”. What is an anti-pattern and how do we do this? In just about all technical projects I’ve been part of, the biggest problems are just about never technology based, but rather people based. Why is this, and what tips do you have on fixing the people problems?  Technical skills  How do you deal with losing your technical skills due to constantly being pushed up the ladder? I personally have to deal with quite a bit of frustration around this, and feel constantly torn between needing to go deep on technical areas and then losing focus of the bigger picture, and visa-versa. Is this an issue you face, and how do you deal with it? How do you attempt to retain them, or do you just not try? You have also discussed “how to build engineering and DevOps practices to support continuous change… and delivery” What advice do you have for us around this?  Failure  What does failure look like as an Architect \u0026amp; how do you deal with it? If you could go back in time and change the way you progressed through your career, what would you change?  Career Path  What advice do you have for Software Engineers thinking about making the transition toward architect based roles? What do they need to be aware of before moving in that direction?  Accolades  Software Engineering Radio was named the #1 rated developer podcast based on an aggregation of hacker news comments Named number one on the Intel Developer Zone Developer Podcasts: Seven you should be Listening to The Simple Programmer has Software Engineering Radio on The Ultimate List Of Developer Podcasts Number two in 11 podcasts that will make you a better software engineer One of FreeCodeCamp’s 5 Coding Podcasts to Enlighten your Commute Among TechRepublic’s 10 podcasts for programmers and budding developers Number two on FeedSpot’s Top 10 Software Engineering Blogs Among VertitechIT\u0026rsquo;s Best IT Podcasts  ","date":1491955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491955200,"objectID":"9d16c15f2fe62793e7d5b9988ff4b5d9","permalink":"https://binarymist.io/publication/ser-podcast-success-skills-for-architects/","publishdate":"2017-04-12T00:00:00Z","relpermalink":"/publication/ser-podcast-success-skills-for-architects/","section":"publication","summary":"Neal Ford of ThoughtWorks chats with SE Radio’s Kim Carter about the skills required to be a successful software architect.\n","tags":["publication","podcast","architecture"],"title":"Neil Ford on Success Skills for Architects","type":"publication"},{"authors":null,"categories":null,"content":"   \n  Some of the PowerShell plays from Kim\u0026rsquo;s second book:\n   \n","date":1489540500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489540500,"objectID":"10cfa9c783d293617d75dde55ad3d798","permalink":"https://binarymist.io/talk/js-remote-conf-2017-the-art-of-exploitation/","publishdate":"2017-03-15T14:15:00+13:00","relpermalink":"/talk/js-remote-conf-2017-the-art-of-exploitation/","section":"talk","summary":"At JS Remote Conf: Kim examines and demonstrates a collection of essential attacks, commonly used in the exploitation and demise of many individuals and organisations today.\n","tags":["talk","hacking","conference","agile","application-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","operational-efficiencies","penetration-testing","people-security","power-shell","ps","reconnaissance","sanitisation","security","security-weaknesses","software-security","stdd"],"title":"Talk - The Art of Exploitation","type":"talk"},{"authors":null,"categories":null,"content":"   \n  Some of the PowerShell plays from Kim\u0026rsquo;s second book:\n   \n","date":1489028400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1489028400,"objectID":"8991b0b980bfa7db1b286522893ec33d","permalink":"https://binarymist.io/talk/nz-js-con-2017-the-art-of-exploitation/","publishdate":"2017-03-09T16:00:00+13:00","relpermalink":"/talk/nz-js-con-2017-the-art-of-exploitation/","section":"talk","summary":"At NZ.JS: Kim examines and demonstrates a collection of essential attacks, commonly used in the exploitation and demise of many individuals and organisations today.\n","tags":["talk","hacking","conference","agile","application-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","operational-efficiencies","penetration-testing","people-security","power-shell","ps","reconnaissance","sanitisation","security","security-weaknesses","software-security","stdd"],"title":"Talk - The Art of Exploitation","type":"talk"},{"authors":null,"categories":null,"content":"Kim will then discuss and demo a set of light weight processes, practises and tools, that when combined have proven their value in:\n Aiding high throughput (reducing time to market) Significantly increasing quality (finding and removing bugs) Without de-scoping  and all while reducing total project cost (fact). If this sounds like breaking the laws of physics, or too good to be true, then this workshop is for you.\nKim will finish off with the habits of top developers and how we can make them part of our lives.\n \n","date":1487808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487808000,"objectID":"1e86b4c94eeba265060f06b470044468","permalink":"https://binarymist.io/talk/devseccon-asia-2017-workshop-developing-a-high-perf-security-focussed-agile-team/","publishdate":"2017-02-23T13:00:00+13:00","relpermalink":"/talk/devseccon-asia-2017-workshop-developing-a-high-perf-security-focussed-agile-team/","section":"talk","summary":"DevSecCon, Singapore: Quality (security included) does not have to be neglected when you’re planning, building and running a high-performance development team.\n\nKim will set the stage with how and why Agile development teams fail, explained with a familiar anecdote taken from his new book “Holistic Info-Sec for Web Developers”, coupled with how you can change this.\n","tags":["workshop","dev-ops","dev-sec-ops","conference","agile","application-security","ci","continuous-integration","cybersecurity","holistic-info-sec-for-web-developers","information-security","nightly-build","owasp-zap","scrum","tdd","testing","web","web-application","web-application-security","web-security","zap"],"title":"Workshop - Developing a high-performance security focussed Agile Team","type":"talk"},{"authors":null,"categories":null,"content":" Workshop As well as the main conference on Monday, we are pleased to be able to provide training on Sunday at the same venue. All details in the workshop listed below.\nMain Event We are proud to announce the ninth OWASP New Zealand Day conference, held at the University of Auckland on Monday February 5th, 2018. OWASP New Zealand Day is a one-day conference dedicated to information security, with an emphasis on secure architecture and development techniques to help developers build more secure applications.\n\nSome of the tweets from the event \nDeclan from @CERTNZ steps into the limelight to talk about how websites are being hacked in real life #owaspnz pic.twitter.com/0qaF0vVoGn\n\u0026mdash; OWASP NZ Chapter (@owaspnz) February 4, 2018  Now it’s @shantha05 talking about securing API’s in the upstairs room pic.twitter.com/sqnTlgcb8U\n\u0026mdash; OWASP NZ Chapter (@owaspnz) February 4, 2018  Visit @owaspnz to see the rest. ","date":1486252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486252800,"objectID":"cb1e1e7be08ddd69b8183e150cc8c07b","permalink":"https://binarymist.io/project/project-owaspnzday2018/","publishdate":"2017-02-05T00:00:00Z","relpermalink":"/project/project-owaspnzday2018/","section":"project","summary":"\nThe ninth conference of its kind.\nDedicated to information security, with an emphasis on secure architecture and development techniques to help Kiwi developers build more secure applications.\n","tags":["project","conference","application-security","cybersecurity","information-security","infosec","security","software-security","web-application-security","web-security","owasp","owasp-nz-day"],"title":"OWASP New Zealand Day","type":"project"},{"authors":null,"categories":null,"content":" The common payload takes the user supplied shellcode and overwrites the first 0x1000 bytes of the calling instance of PowerShell, creates a thread to execute within the virtual address space of the calling PowerShell instance and starts it.\nAll delivery and persistence techniques ensure AV bypass of shellcode.\nKim has dissected and will explain how the virus and payload works.\nWe will look at delivery mediums (virus):\n Compiled C executable Office document (take your pick) C/- Nishang  Persistence mediums:\n Meterpreter (busted by AV) PowerSploit  Bring your pentesting devices if you want to do this workshop style, and we can do hands on.\nVideo 0   Video 1   \n","date":1485325800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1485325800,"objectID":"8b4957ad0002c9ec444822beb4e75edb","permalink":"https://binarymist.io/talk/isig-2017-workshop-windows-exploitation-and-persistence-with-ps/","publishdate":"2017-01-25T19:30:00+13:00","relpermalink":"/talk/isig-2017-workshop-windows-exploitation-and-persistence-with-ps/","section":"talk","summary":"Kim will walk us through a collection of PowerShell delivery (RAM, not disk) techniques for a common reverse shellcode.","tags":["workshop","hacking","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","penetration-testing","power-shell","ps","security-weaknesses"],"title":"Workshop - Windows Exploitation and Persistence with PowerShell","type":"talk"},{"authors":null,"categories":null,"content":" Founder and CEO, InventoryTech Limited\n Kim provided us with excellent support services during a development transition with our cloud software services.\nKim is a highly capable software developer with deep experience and capabilities.\nI recommend Kim\u0026rsquo;s services, he did a great job for us.\n","date":1484179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1484179200,"objectID":"0aa849e5ad01e4284d996a6280e689f9","permalink":"https://binarymist.io/project/testimonial-peter-montgomery/","publishdate":"2017-01-12T00:00:00Z","relpermalink":"/project/testimonial-peter-montgomery/","section":"project","summary":"InventoryTech Ltd","tags":["testimonial"],"title":"Peter Montgomery","type":"project"},{"authors":null,"categories":null,"content":"","date":1480388400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480388400,"objectID":"a39909f294f00df75149cb478e0c6e3e","permalink":"https://binarymist.io/talk/agilenz-2016-agile-security-for-web-developers/","publishdate":"2016-11-29T16:00:00+13:00","relpermalink":"/talk/agilenz-2016-agile-security-for-web-developers/","section":"talk","summary":"Join Kim at AgileNZ 2016 for an exploration into an insightful set of steps he has learned, from an architectural, engineering and penetration testing perspective.\n","tags":["talk","conference","agile","dev-ops","dev-sec-ops","people-security","penetration-testing","reconnaissance","scrum","owasp-zap","zap"],"title":"Talk - Agile Security for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":"The content is aimed at software engineers to teach them how to think holistically about security. The theme that runs through the training, and the book, is pulling the security focus that’s usually left until the end of the project or “go live” right into each Sprint. Baking security into the product from the cheapest possible place. Thus saving large amounts of money due to re-work and business asset loss. Kim will be teaching attendees a very simple threat modelling process initially blue printed by one of the best security experts the world has known, Bruce Schneier, then how to apply that process to a 10,000′ view and lower for a collection of areas:\n Physical People Cloud VPS Network Web Applications  Within each Sprint.\nA hands on training, taking the attackers perspective and extracting a set of development related processes and practises that can be augmented with your Scrum Teams existing processes and practices, creating minimum disruption and maximum cost effective security. Attendees will be able to take these learnings and apply them within their own Scrum Teams.\n","date":1479240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1479240000,"objectID":"a6344928cc717cf18fc5450bcd5530aa","permalink":"https://binarymist.io/talk/kiwicon-2016-workshop-holistic-info-sec-for-web-developers-intense/","publishdate":"2016-11-16T09:00:00+13:00","relpermalink":"/talk/kiwicon-2016-workshop-holistic-info-sec-for-web-developers-intense/","section":"talk","summary":"Kiwicon hands-on threat modelling, attack and defence strategy training for Web Developers wishing to understand their attackers better, stay ahead of them and create cost effective defence strategies.\n","tags":["workshop","security","physical-security","people-security","vps-security","network-security","cloud","cloud-security","dev-ops","dev-sec-ops","docker","web-application-security","web-security","web-application","holistic-info-sec-for-web-developers","application-security","cybersecurity","information-security","security-weaknesses","software-security","hacking","conference","operational-efficiencies","owasp"],"title":"Workshop - Holistic Info-Sec for Web Developers - Intense","type":"talk"},{"authors":null,"categories":null,"content":" Who is it for? You! IT security professionals, web developers, software developers, students, wannabes, hackers, enthusiasts, etc\n","date":1478894400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1478894400,"objectID":"b02ef629dbd081bb61499c7d5af01609","permalink":"https://binarymist.io/talk/chcon-2016/","publishdate":"2016-11-12T09:00:00+13:00","relpermalink":"/talk/chcon-2016/","section":"talk","summary":"CHCon 2016: A conference for security professionals and hackers in Christchurch, NZ.\n","tags":["conference","cloud-security","cybersecurity","information-security","infosec","security"],"title":"Conference - Christchurch Hacker Con","type":"talk"},{"authors":null,"categories":null,"content":"   ","date":1477629000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477629000,"objectID":"0767f72545e5cf2c9fb6af1788f5181b","permalink":"https://binarymist.io/talk/aws-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","publishdate":"2016-10-28T17:30:00+13:00","relpermalink":"/talk/aws-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","section":"talk","summary":"At AWS Auckland, Kim will demonstrate the OWASP Zap API with NodeGoat, which helps you identify vulnerabilities in your web application as you create it, rather than at the end of a project.\n","tags":["workshop","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Workshop - Security Regression Testing with ZapAPI and NodeGoat","type":"talk"},{"authors":null,"categories":null,"content":"   ","date":1477545300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477545300,"objectID":"4ff3b9424d06a626e2d0f65d8d7304b1","permalink":"https://binarymist.io/talk/nodejs-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","publishdate":"2016-10-27T17:30:00+13:00","relpermalink":"/talk/nodejs-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","section":"talk","summary":"NodeJS Auckland: Kim will demonstrate the OWASP Zap API with NodeGoat, which helps you identify vulnerabilities in your web application as you create it, rather than at the end of a project.\n","tags":["workshop","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Workshop - Security Regression Testing with ZapAPI and NodeGoat","type":"talk"},{"authors":null,"categories":null,"content":"   Kim Carter has developed a strong track record as a technology architect and information security professional over 15 years. He is a Chapter Leader of the Open Web Application Security Project (OWASP) NZ and a Certified Scrum Master. Kim enjoys facilitating and motivating cross-functional, self-managing teams. You’ll find the insights from Kim’s talk in his new book, Holistic Infosec for Web Developers.\nNodeConf gives you unparalleled access to top thought leaders like Kim Carter. Book your tickets now to avail of this unique opportunity.\n\u0026quot;Security Regression Testing with ZapAPI and NodeGoat\u0026quot; w/ @binarymist #NodeConfEU! #node pic.twitter.com/4Snap5Hafj\n\u0026mdash; NodeConf Remote (@NodeConfEU) September 24, 2016  ","date":1476576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476576000,"objectID":"d6970090cf8a455d1f12a6efce782db8","permalink":"https://binarymist.io/talk/nodeconfeu-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","publishdate":"2016-10-16T13:00:00+13:00","relpermalink":"/talk/nodeconfeu-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","section":"talk","summary":"This time in Kilkenny of Ireland, Kim will demonstrate the OWASP Zap API with NodeGoat, which helps you identify vulnerabilities in your web application as you create it, rather than at the end of a project.\n","tags":["workshop","conference","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Workshop - Security Regression Testing with ZapAPI and NodeGoat","type":"talk"},{"authors":null,"categories":null,"content":"","date":1473026400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473026400,"objectID":"2433a965c8b5a899143df631ef8ed8ea","permalink":"https://binarymist.io/talk/uca-2016-workshop-holistic-info-sec-for-comp-sci-students/","publishdate":"2016-09-05T00:00:00+12:00","relpermalink":"/talk/uca-2016-workshop-holistic-info-sec-for-comp-sci-students/","section":"talk","summary":"This time for the students of University of Canterbury. An exploration into an insightful set of steps he has learned, from an architectural, engineering and penetration testing perspective. Based on the content of volume 0 \u0026 1 of Kim’s new book “Holistic Info-Sec for Web Developers”. This time held at the University of Canterbury.\n","tags":["workshop","hacking","application-security","csrf","cloud-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","networking","network-security","owasp","people-security","physical-security","sanitisation","security","security-weaknesses","software-security","sql-injection","ssh","vps","vps-security","web","xss"],"title":"Workshop - Holistic Info-Sec for Computer Science Students","type":"talk"},{"authors":null,"categories":null,"content":" \nWhat others have said \n\n","date":1471500000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1471500000,"objectID":"ddab34f00bff98b245c98d64bd234b1e","permalink":"https://binarymist.io/talk/agile-professionals-network-2016-agile-security-for-web-developers/","publishdate":"2016-08-18T18:00:00+12:00","relpermalink":"/talk/agile-professionals-network-2016-agile-security-for-web-developers/","section":"talk","summary":"Join Kim at Agile Professionals Network for an exploration into an insightful set of steps he has learned, from an architectural, engineering and penetration testing perspective.\n","tags":["talk","agile","dev-ops","dev-sec-ops","people-security","penetration-testing","reconnaissance","scrum","owasp-zap","zap"],"title":"Talk - Agile Security for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":"    What others have said \n\n","date":1469602800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1469602800,"objectID":"8398f279c5e7f7e45829795a41047863","permalink":"https://binarymist.io/talk/owaspny-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","publishdate":"2016-07-21T19:00:00+12:00","relpermalink":"/talk/owaspny-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","section":"talk","summary":"This time in New York City at OWASP, Kim will demonstrate the OWASP Zap API with NodeGoat, which helps you identify vulnerabilities in your web application as you create it, rather than at the end of a project.\n","tags":["workshop","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Workshop - Security Regression Testing with ZapAPI and NodeGoat","type":"talk"},{"authors":null,"categories":null,"content":"\n","date":1469224800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1469224800,"objectID":"0c3f0645e61a0d3c1cdd93afa6fda83f","permalink":"https://binarymist.io/talk/hope-2016-workshop-holistic-info-sec-for-web-developers/","publishdate":"2016-07-23T00:00:00+12:00","relpermalink":"/talk/hope-2016-workshop-holistic-info-sec-for-web-developers/","section":"talk","summary":"Hackers On Planet Earth (HOPE) conference in New York City. An exploration into an insightful set of steps he has learned, from an architectural, engineering and penetration testing perspective. Based on the content of volume 0 \u0026 1 of Kim’s new book “Holistic Info-Sec for Web Developers”.\n","tags":["workshop","conference","hacking","application-security","csrf","cloud-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","networking","network-security","owasp","people-security","physical-security","sanitisation","security","security-weaknesses","software-security","sql-injection","ssh","vps","vps-security","web","xss"],"title":"Workshop - Holistic Info-Sec for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":"   ","date":1467183600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467183600,"objectID":"3405a3bae5e5b63736b441897e16c9eb","permalink":"https://binarymist.io/talk/owaspchch-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","publishdate":"2016-06-29T19:00:00+12:00","relpermalink":"/talk/owaspchch-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","section":"talk","summary":"Kim will demonstrate the OWASP Zap API with NodeGoat at the meetup he usually facilitates, which helps you identify vulnerabilities in your web application as you create it, rather than at the end of a project.\n","tags":["workshop","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Workshop - Security Regression Testing with ZapAPI and NodeGoat","type":"talk"},{"authors":null,"categories":null,"content":"    What others have said \n\n","date":1466665200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466665200,"objectID":"4e0fef74602b452f624976bfb672882b","permalink":"https://binarymist.io/talk/chcjs-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","publishdate":"2016-06-23T19:00:00+12:00","relpermalink":"/talk/chcjs-meetup-2016-workshop-security-regression-testing-with-zapapi-and-nodegoat/","section":"talk","summary":"At CHC.js Kim will demonstrate the OWASP Zap API with NodeGoat, which helps you identify vulnerabilities in your web application as you create it, rather than at the end of a project.\n","tags":["workshop","dev-ops","dev-sec-ops","atdd","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","owasp","owasp-zap","stdd","security","selenium","software-security","web-application","web-application-security","web-security","zap"],"title":"Workshop - Security Regression Testing with ZapAPI and NodeGoat","type":"talk"},{"authors":null,"categories":null,"content":"","date":1466200800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1466200800,"objectID":"f9d540e5055979fa03258ebd55abb987","permalink":"https://binarymist.io/talk/code-camp-chch-2016-agile-security-for-web-developers/","publishdate":"2016-06-18T10:00:00+12:00","relpermalink":"/talk/code-camp-chch-2016-agile-security-for-web-developers/","section":"talk","summary":"Join Kim at CodeCamp Christchurch for an exploration into an insightful set of steps he has learned, from an architectural, engineering and penetration testing perspective.\n","tags":["talk","agile","dev-ops","dev-sec-ops","people-security","penetration-testing","reconnaissance","scrum","owasp-zap","zap"],"title":"Talk - Agile Security for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":" DevSecOps and AWS Migration\n    Implemented Security Regression Test framework based on Kim's Proof of Concept\nRe-architected legacy to new code-base.\nMigrated PayGlobal services to AWS.\nScrum mentoring.\nAdditional details on Kim's LinkedIn\n   ","date":1464739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1464739200,"objectID":"90c4e4a698803e8b51a65e982320d132","permalink":"https://binarymist.io/project/portfolio-myob/","publishdate":"2016-06-01T00:00:00Z","relpermalink":"/project/portfolio-myob/","section":"project","summary":"DevSecOps \u0026#38; AWS Migration","tags":["portfolio","architecture-engineering-portfolio","devops-portfolio","security-portfolio"],"title":"MYOB","type":"project"},{"authors":null,"categories":null,"content":"Join Kim in the exploration into an insightful set of steps he has learned, from an architectural perspective down to the zeros and ones. Also providing insights of how attackers of your systems think.\nWe will also look at other tried and tested practices and processes for reducing security defects early. That is every Sprint for each Product Backlog Item (PBI). As an architect, engineer and security specialist, Kim will uncover how to identify the lowest hanging fruit (for the attackers) by taking a holistic approach (a 30,000′ view), then honing in on the areas with the highest security ratings, based on a tried and tested threat modelling process that allows you to discover and prioritise the defects most likely to be compromised by attackers of your systems.\nWe are going to look at automating (Security Test (Behaviour) Driven Development (STDD/SBDD)) some of the traditional manual based penetration testing methods often performed after go live and bringing them forward into parallel with your development cycles (Sprints).\nThus empowering Developers to do what was once only performed by deeply specialised security consultancies at the end of the project. Dramatically increasing the confidence we as developers have in what we are delivering, thus reducing the cost of change due to defects being found as they are introduced rather than at go live.\n","date":1463950800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1463950800,"objectID":"2f41f436cae6b7c9f1e8af102bc6569e","permalink":"https://binarymist.io/talk/auscert-2016-workshop-holistic-info-sec-for-web-developers/","publishdate":"2016-05-23T09:00:00+12:00","relpermalink":"/talk/auscert-2016-workshop-holistic-info-sec-for-web-developers/","section":"talk","summary":"AusCERT hands-on threat modelling, attack and defence strategy training for Web Developers wishing to understand their attackers better, stay ahead of them and create cost effective defence strategies.\n","tags":["workshop","security","physical-security","people-security","vps-security","network-security","cloud","cloud-security","dev-ops","dev-sec-ops","docker","web-application-security","web-security","web-application","holistic-info-sec-for-web-developers","application-security","cybersecurity","information-security","security-weaknesses","software-security","hacking","conference","operational-efficiencies","owasp"],"title":"Workshop - Holistic Info-Sec for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":" General Manager, SBS Bank\n I\u0026rsquo;ve enjoyed having Kim as part of our team.\nYou have done a fantastic job there and we are lucky to have you.\n","date":1461801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461801600,"objectID":"2bf02c803acdcd7d25081b566c953be7","permalink":"https://binarymist.io/project/testimonial-lana-winders/","publishdate":"2016-04-28T00:00:00Z","relpermalink":"/project/testimonial-lana-winders/","section":"project","summary":"SBS Bank","tags":["testimonial"],"title":"Lana Winders","type":"project"},{"authors":null,"categories":null,"content":" Project Manager, SBS Bank\n Congratulations!!!!!!!!!!!!!!!!!!!!! Cheers to Kim on our first PIB change completed in house.\nThe PIB reskin looks magnificent and has gone through without a glitch Well done Kim – you’ve given SBS that little bit of independence and it feels fantastic!\nhope you feel really proud Kim.\n","date":1461801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461801600,"objectID":"a227855e3d33d581804f337c493182d3","permalink":"https://binarymist.io/project/testimonial-rachel-robertson/","publishdate":"2016-04-28T00:00:00Z","relpermalink":"/project/testimonial-rachel-robertson/","section":"project","summary":"SBS Bank","tags":["testimonial"],"title":"Rachel Robertson","type":"project"},{"authors":null,"categories":null,"content":"    ","date":1461742200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461742200,"objectID":"5ec7bf24b02210ee564502c45f2e4736","permalink":"https://binarymist.io/talk/isig-2016-talk-tools-password-profiling-brute-forcing/","publishdate":"2016-04-27T19:30:00+12:00","relpermalink":"/talk/isig-2016-talk-tools-password-profiling-brute-forcing/","section":"talk","summary":"Kim will take ISIG through the [collection of tools](https://f0.holisticinfosecforwebdevelopers.com/chap05.html#tooling-setup) added and configured on his penetration testing machine used throughout his book series ([Holistic Info-Sec for Web Developers](https://www.holisticinfosecforwebdevelopers.com)). Kim will then profile a well known celebrities password, creating a short-list, then (on-line) brute force their login. Come along, it’ll be fun.\n","tags":["workshop","cracking","hacking","application-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","networking","network-security","owasp","people-security","physical-security","sanitisation","security","security-weaknesses","software-security","sql-injection","ssh","vps","vps-security","web","xss","kdf","md5"],"title":"Workshop - Tools, Password Profiling, Brute Forcing","type":"talk"},{"authors":null,"categories":null,"content":" You\u0026rsquo;ve realised that you need to do something about the rising number of defects being introduced into your software products. Competitors are outmanoeuvring you. Security reviews and penetration testing is costing you too much. Your customers are demanding higher security and protection of their data. Your Development Team(s) simply don\u0026rsquo;t have the time or expertise to add more heavy weight security process and practises.\nWhat if we told you: That by working with you we could reduce the amount you spend on traditional security reviews, penetration testing, and at the same time reduce the defects being introduced, and significantly improve your security stature, while reducing total project cost?\nTogether, we could help get your product to market quicker, and with fewer security defects?\nWe could give you the ability to prove to your customers that you were taking the security of their data seriously, and that your product(s) were a much safer investment than your competitor\u0026rsquo;s?\nYou could even invite your customers to be part of your development process, and be amazed by seeing security defects fixed as they are found in a continuous integration or nightly build environment.\nOutcomes: Once you have a roadmap for success, which we can work with you to provide at a fixed price, detailing where your Development Team(s) can be doing better, how to do better, and providing clear steps to achieve the shared goal, teams will often need some hands on assistance to establish the light weight processes and practises, tools and techniques outlined in the roadmap, workshop, and Kim\u0026rsquo;s book.\nWe can work with your Development Team(s) implementing the security roadmap, providing ongoing mentoring as required, and then handing the reins over, continuing to monitor and provide ongoing advice and coaching as required, this way setting you up for the pit of success.\nThis process can be relatively quick to implement, and has the side-effect of saving huge amounts of money on fixing defects once they\u0026rsquo;ve been in the system for a long time.\n\n If you would get excited about reducing costs on security, while increasing the ability of your Development Team(s) to deliver secure products\u0026hellip;\n \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nReview our Portfolio and Testimonials for some of the teams we have helped reduce costs and security defect counts by shifting the security focus up front of the development life-cycle.\nWhat our customers are saying  Andrew Balfour\n Owner/Managing Director, Solvam Corporation Ltd\n Kim Carter was engaged on a contract basis to implement and guide our future software development for School-links. www.school-links.co.nz\nIn doing that he -\n Brought to our product a much higher level of expertise and capability complementing our development team Directed a disciplined and methodical software development process as the Scrum Master of ‘Scrum’ Helped with the restructuring and planning of our infrastructure in order to scale the product successfully Brings security expertise at a high level with the ability to implement ongoing security hardening program and audits Introduced the Scrum process which provided more consistent and accurate release cycles enabling our marketing efforts to be better coordinated and focused  Kim is a good team member and we will look to reengage with his services when required.\n \nWe have had the unique opportunity to work in both defensive (development) and offensive (penetration testing) teams, across many domains, for a large number of years. This has produced a deep understanding of what Development Team(s) need in order to help you create solutions that will effectively resist attacks from your adversaries.\n  \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nWe can only take on one or two of these engagements every few months.\n\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"882e3d6f051add0060030403a15329a2","permalink":"https://binarymist.io/project/service-development-team-security-implementation/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/service-development-team-security-implementation/","section":"project","summary":"Your Development Team(s) are struggling to create secure software. Your business is paying too much for security reviews, and penetration testing at the end of the project.\nYour customers want to be certain that their personal data is secure. You could be saving significant expenditure on security and software development in general.","tags":["service","development-team-security-service","agile","security","cybersecurity","infosec","dev-ops","dev-sec-ops","operational-efficiencies","software-security","web-security"],"title":"Development Team Security Implementation","type":"project"},{"authors":null,"categories":null,"content":" Situation Your software project is at the stage where you would like some verification that it is going to be able to resist attacks from your likely attackers.\nYou have deployed your project to the Cloud and need some confirmation that the infrastructure is configured correctly so that your attackers can not compromise your customers.\nDocker containers can be a god send for creating micro-service architectures, but often Docker environments are insecure by default.\nYour Software Engineers are building networks by way of infrastructure as code (IaC). These networks need security review and sometimes penetration testing.\nWe can do better Would you like peace of mind that your software project is going to be able to withstand the likely attacks from your adversaries?\nAchieving and maintaining a level of security with your cloud configuration, security rules and settings can be a daunting task. Would you like to be able to relax and be confident that this is taken care of?\nSecuring your micro-service and Docker environments is not for the faint hearted, this is an area that Kim has a wealth of experience in. You too can share the same knowledge that your micro-service and Docker environments are well secured.\nWith the knowledge and experience that we have with cloud environments and tools such as Terraform, Ansible, etc, you can rest assured that the networks your Engineers are creating are configured correctly, and will resist the attempts of your attackers.\nHow we can help Although we advocate bringing the security focus up front where it\u0026rsquo;s the cheapest to implement, we understand that this is a journey that takes time. Ultimately our aim is to help you get there, but in the interim, we can work with you by reviewing, testing and establishing a solid security stature across your market offerings.\nWe can review, penetration test, evaluate costs and trade-offs, provide a custom report outlining the defects and effective mitigations. Then work with your development team(s) to help them understand the issues and how to apply the mitigations themselves, thus aiding recognition of future defects as they\u0026rsquo;re introduced, saving large amounts of rework. We can also simply fix the defects for you if that\u0026rsquo;s your preference.\nWe can traverse the minefield of your cloud environment with you. Locate, document, and work with your Engineers helping them to rectify the security issues in your cloud deployments, or apply the necessary remedies for you and your teams.\nNetwork security is an area that Kim has been actively engaged in designing, building and breaking for many years. We can work with you supplying valuable knowledge and experience to your project.\n\n Let us review, test, and provide the peace of mind that your market offerings will withstand the attacks from your adversaries\u0026hellip;\n \nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nDue to the sensitive nature of these engagements, they are not usually added to our portfolio, but you can see\u0026hellip;\nWhat our customers are saying  Stefan Streichsbier\n Numisec Pte. Ltd\n I\u0026rsquo;ve met Kim at DevSecCon Singapore in 2017 where he gave a well-received workshop. A few months later we had a project where his top-notch strong Node.js security code review skills were required and this gave us the chance to work together closely.\nOver a 2 week period he was doing security code reviews of containerized Node.js microservices in a very thorough way. We communicated well and progressed quickly. Kim has a very broad yet deep understanding of modern application security that comes from years of experience. I can recommend Kim to anyone who needs an application security expert and wants a professional second opinion on the security posture of an application.\n \nKim has spent significant effort in researching Docker security, how to determine insecure environments, configurations, how to provide countermeasures, and has written on the topic extensively. Kim has also liaised with and interviewed the Docker Security Team Lead, and is well equipped to address and rectify any security issues you may have with Docker environments.\n BinaryMist project leveraging Docker and Terraform to create free and secure networking components:   \nKim has also detailed some of his network knowledge in the Network chapter of his second book, along with interview of network security guru Haroon Meer.\nBecause Kim has spent many years in development and engineering, as well as performing security reviews and penetration tests, he brings a unique and holistic view of what is required from both sides (defence and attack), being able to work with your team(s) to provide effective and realistic simulations of real-world attacks, at the same time, coaching your developers what to look for.\n\nReserve Your Consultation Currently we have availability for select new clients.\nReserve Your Confidential Consultation\n\nDue to the nature of this type of work, we can only take on one new client per month.\n\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"4a8978cb2802d6d7ea1abebd4cc350b4","permalink":"https://binarymist.io/project/service-security-review-penetration-testing/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/service-security-review-penetration-testing/","section":"project","summary":"You need to be sure that what your development team(s) are creating is going to withstand the onslaught of those tasked with breaking your deliverables, and stealing your customers data.\nYour customers want to be certain that their personal data is secure. You need your product to stand-up to those that are going to attack it.","tags":["service","organisational-security-service","hacking","penetration-testing","cybersecurity","information-security","infosec","security","software-security","web-application-security","web-security"],"title":"Security Review, Penetration Testing","type":"project"},{"authors":["Kim Carter"],"categories":null,"content":"","date":1461628800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461628800,"objectID":"0798d97408f961c440d8bc580589d83d","permalink":"https://binarymist.io/publication/dotnetrocks-interview-infosec-for-developers/","publishdate":"2016-04-26T00:00:00Z","relpermalink":"/publication/dotnetrocks-interview-infosec-for-developers/","section":"publication","summary":"Carl and Richard talk with Kim Carter about his experience in helping developers grasp information security and successfully employ it within their teams.\n","tags":["publication","podcast","cybersecurity","security","holistic-info-sec-for-web-developers","information-security","infosec","software-security","web-application-security","web-security","dev-sec-ops"],"title":"InfoSec for Developers","type":"publication"},{"authors":null,"categories":null,"content":"Who is it for?\n Web Developers: The morning sessions will introduce you to application security. Afternoon sessions will dive deeper into technical topics, and build on the morning sessions Management: After an introduction to web application security, one of the afternoon streams will focus on informational and defensive topics Security Professionals and Enthusiasts: Technical sessions later in the day will showcase new and interesting attack and defence topics  ","date":1454529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454529600,"objectID":"76d693f08ab0c3716b57a0e729c4a4ac","permalink":"https://binarymist.io/talk/owaspnzday-2016/","publishdate":"2016-02-04T09:00:00+13:00","relpermalink":"/talk/owaspnzday-2016/","section":"talk","summary":"The seventh OWASP New Zealand Day conference, held at the University of Auckland.\n","tags":["conference","cloud-security","cybersecurity","information-security","owasp","owasp-nz-day","infosec","security","web-application-security","web-security"],"title":"Conference - OWASP New Zealand Day","type":"talk"},{"authors":null,"categories":null,"content":" Transitioning, architecture and development\n    Assisted with transition between engineering teams.\nProvided architecture and development assistance. Technologies:  NodeJS, MongoDB BackboneJS, MarionetteJS, Gulp  Platforms:  Heroku AWS     See testimonial by Peter Montgomery\n","date":1454284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454284800,"objectID":"7feb65191f3770cceaf7d4cb7bfd9bc2","permalink":"https://binarymist.io/project/portfolio-inventorytech/","publishdate":"2016-02-01T00:00:00Z","relpermalink":"/project/portfolio-inventorytech/","section":"project","summary":"Transitioning, architecture, \u0026#38; dev","tags":["portfolio","architecture-engineering-portfolio","devops-portfolio"],"title":"InventoryTech","type":"project"},{"authors":null,"categories":null,"content":" This post was taken from the content of the Web Applications chapter of Kim\u0026rsquo;s book Holistic Info-Sec for Web Developers F1\nRisks Lack of captchas are a risk, but so are captchas themselves\u0026hellip;\nLet\u0026rsquo;s look at the problem here? What are we trying to stop with captchas?\nBots submitting. What ever it is, whether:\n Advertising Creating an unfair advantage over real humans Link creation in attempt to increase SEO Malicious code insertion  You are more than likely not interested in accepting it.\nWhat do we not want to block?\nPeople submitting genuinely innocent input. If a person is prepared to fill out a form manually, even if it is spam, then a person can view the submission and very quickly delete the validated, filtered and possibly sanitised message.\nCountermeasures Types Text Recognition recaptcha uses this technique. See below for details.\nImage Recognition Uses images which users have to perform certain operations on, like dragging them to another image. For example: \u0026ldquo;Please drag all cat images to the cat mat.\u0026rdquo;, or \u0026ldquo;Please select all images of things that dogs eat.\u0026rdquo; sweetcaptcha is an example of this type of captcha. This type completely rules out the visually impaired users.\nFriend Recognition Pioneered by\u0026hellip; you guessed it. Facebook. This type of captcha focusses on human hackers, the idea being that they will not know who your friends are.\n\u0026ldquo;Instead of showing you a traditional captcha on Facebook, one of the ways we may help verify your identity is through social authentication. We will show you a few pictures of your friends and ask you to name the person in those photos. Hackers halfway across the world might know your password, but they don\u0026rsquo;t know who your friends are.\u0026ldquo;\nI disagree with that statement. A determined hacker will usually be able to find out who your friends are. There is another problem, do you know who all of your friends are? Every acquaintance? I am terrible with names and so are many people. This is supposed to be used to authenticate you. So you have to be able to answer the questions before you can log in.\nLogic Questions This is what textcaptcha uses. Simple logic questions designed for the intelligence of a seven year old child. These are more accessible than image and textual image recognition, but they can take longer than image recognition to answer, unless the user is visually impared. The questions are usually language specific also, usually targeting the English language.\nUser Interaction This is a little like image recognition. Users have to perform actions that virtual intelligence can not work out\u0026hellip; yet. Like dragging a slider a certain number of notches. If an offering gets popular, creating some code to perform the action may not be that hard and would definitely be worth the effort for bot creators. This is obviously not going to work for the visually impaired or for people with handicapped motor skills.\nIn NPM land, as usual there are many options to choose from. The following were the offerings I evaluated. None of which really felt like a good fit:\nOfferings  total-captcha. Depends on node-canvas. Have to install cairo first, but why? No explanation. Very little of anything here. Move on. How does this work? Do not know. What type is it? Presume text recognition. easy-captcha is a text recognition offering generating images simple-captcha looks like another text recognition offering. I really do not want to be writing image files to my server. node-captcha Depends on canvas. By the look of the package this is another text recognition in a generated image. re-captcha was one of the first captcha offerings, created at the Carnegie Mellon University by Luis von Ahn, Ben Maurer, Colin McMillen, David Abraham and Manuel Blum who invented the term captcha. Google later acquired it in September 2009. recaptcha is a text recognition captcha that uses scanned text that optical character recognition (OCR) technology has failed to interpret, which has the added benefit of helping to digitise text for The New York Times and Google Books.  sweetcaptcha uses the sweetcaptcha cloud service of which you must abide by their terms and conditions, requires another node package, and requires some integration work. sweetcaptcha is an image recognition type of captcha.  textcaptcha is a logic question captcha relying on an external service for the questions and md5 hashes of the correct lower cased answers. This looks pretty simple to set up, but again expects your users to use their brain on things they should not have to.  After some additional research I worked out why the above types and offerings didn\u0026rsquo;t feel like a good fit. It pretty much came down to user experience.\n Why should genuine users/customers of your web application be disadvantaged by having to jump through hoops because you have decided you want to stop bots spamming you? Would it not make more sense to make life harder for the bots rather than for your genuine users?\n Some other considerations I had. Ideally I wanted a simple solution requiring few or ideally no external dependencies, no JavaScript required, no reliance on the browser or anything out of my control, no images and it definitely should not cost any money.\nAlternative Approaches  Services like Disqus can be good for commenting. Obviously the comments are all stored somewhere in the cloud out of your control and this is an external dependency. For simple text input, this is probably not what you want. Similar services such as all the social media authentication services can take things a bit too far I think. They remove freedoms from your users. Why should your users be disadvantaged by leaving a comment or posting a message on your web application? Disqus tracks users activities from hosting website to website whether you have an account, are logged in or not. Any information they collect such as IP address, web browser details, installed add-ons, referring pages and exit links may be disclosed to any third party. When this data is aggregated it is useful for de-anonymising users. If users choose to block the Disqus script, the comments are not visible. Disqus has also published its registered users entire commenting histories, along with a list of connected blogs and services on publicly viewable user profile pages. Disqus also engage in add targeting and blackhat SEO techniques from the websites in which their script is installed. Services like Akismet and Mollom which take user input and analyse for spam signatures. Mollom sometimes presents a captcha if it is unsure. These two services learn from their mistakes if they mark something as spam and you unmark it, but of course you are going to have to be watching for that. Matt Mullenweg created Akismet so that his mother could blog in safety. \u0026ldquo;His first attempt was a JavaScript plugin which modified the comment form and hid fields, but within hours of launching it, spammers downloaded it, figured out how it worked, and bypassed it. This is a common pitfall for anti-spam plugins: once they get traction\u0026rdquo;. My advice to this is not to use a common plugin, but to create something custom. I discuss this soon.  The above solutions are excellent targets for creating exploits that will have a large pay off due to the fact that so many websites are using them. There are exploits discovered for these services regularly.\nStill not cutting it \u0026ldquo;Given the fact that many clients count on conversions to make money, not receiving 3.2% of those conversions could put a dent in sales. Personally, I would rather sort through a few SPAM conversions instead of losing out on possible income.\u0026ldquo;\n Casey Henry: Captchas\u0026rsquo; Effect on Conversion Rates\n \u0026ldquo;Spam is not the user’s problem; it is the problem of the business that is providing the website. It is arrogant and lazy to try and push the problem onto a website’s visitors.\u0026ldquo;\n Tim Kadlec: Death to Captchas\n User Time Expenditure Recording how long it takes from fetch to submit. This is another technique, in which the time is measured from fetch to submit. For example if the time span is under five seconds it is more than likely a bot, so handle the message accordingly.\nBot Pot Spamming bots operating on custom mechanisms will in most cases just try, then move on. If you decide to use one of the common offerings from above, exploits will be more common, depending on how wide spread the offering is. This is one of the cases where going custom is a better option. Worse case is you get some spam and you can modify your technique, but you get to keep things simple, tailored to your web application, your users needs, no external dependencies and no monthly fees. This is also the simplest technique and requires very little work to implement.\nSpam bots:  Love to populate form fields Usually ignore CSS. For example, if you have some CSS that hides a form field and especially if the CSS is not inline on the same page, they will usually fail at realising that the field is not supposed to be visible.  So what we do is create a field that is not visible to humans and is supposed to be kept empty. On the server once the form is submitted, we check that it is still empty. If it is not, then we assume a bot has been at it.\nThis is so simple, does not get in the way of your users, yet very effective at filtering bot spam.\nClient side: CSS form .bot-pot { display: none; } HTML \u0026lt;form\u0026gt; \u0026lt;!--...--\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;bot-pot\u0026#34; class=\u0026#34;bot-pot\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;!--...--\u0026gt; \u0026lt;/form\u0026gt; Server side: I show the validation code middleware of the route on line 30 of routes/home.js below.\nThe validation is performed on line 16 of routes/home.js below.\nroutes/home.js 1var form = require(\u0026#39;express-form\u0026#39;); 2var fieldToValidate = form.field; 3//... 4 5function home(req, res) { 6 res.redirect(\u0026#39;/\u0026#39;); 7} 8 9function index(req, res) { 10 res.render(\u0026#39;home\u0026#39;, { title: \u0026#39;Home\u0026#39;, id: \u0026#39;home\u0026#39;, brand: \u0026#39;your brand\u0026#39; }); 11} 12 13function validate() { 14 return form( 15 // Bots love to populate everything. 16 fieldToValidate(\u0026#39;bot-pot\u0026#39;).maxLength(0) 17 ); 18} 19 20function contact(req, res) { 21 22 if(req.form.isValid) 23 // We know the bot-pot is of zero length. So no bots. 24 //... 25} 26 27module.exports = function (app) { 28 app.get(\u0026#39;/\u0026#39;, index); 29 app.get(\u0026#39;/home\u0026#39;, home); 30 app.post(\u0026#39;/contact\u0026#39;, validate(), contact); 31};  So as you can see, a very simple solution. You could even consider combining the above two techniques.\n","date":1451473200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451473200,"objectID":"e4e1f2d1018cedd15c983133b91fef54","permalink":"https://binarymist.io/blog/2015/12/31/captcha-considerations/","publishdate":"2015-12-31T00:00:00+13:00","relpermalink":"/blog/2015/12/31/captcha-considerations/","section":"post","summary":"Lack of captchas are a risk, but so are captchas themselves...\n","tags":["application-security","book","captcha","css","cybersecurity","holistic-info-sec-for-web-developers","infosec","javascript","nodejs","npm","security","software-security","web-application","web-security"],"title":"Captcha Considerations","type":"post"},{"authors":null,"categories":null,"content":" BinaryMist Privacy Statement \nThe Short Version We collect your statistics only with your consent. We only collect the minimum amount of personal information required to understand the purpose of your interactions with this website. This information as far as we are aware will not be sold to third parties.\nFor more information read the below.\nAnalytics We are using Google Analytics (GA) as a third party tracking service. We do not use it to track you individually or collect personal information about you. GA is used to collect information about website performance, how users of this website interact (navigate around) with it. This helps us understand better what is of most interest to the users and any issues that may be causing frustration.\nGA gathers certain simple, non-personally identifying information over time, such as your IP address, browser type, internet service provider, referring and exit pages, time stamp, and similar data about your use of this website.\nWe will not personally or allow any third party to the best of our understanding use GA to track users of this website individually, collect any personal information other than IP address.\nYou can opt out of GA tracking by using a script blocking browser extension or add-on and simply disabling the GA script. Google also provides a browser add-on to block GA.\nGoogles Privacy Policy is here.\n","date":1450742400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450742400,"objectID":"91731c48342b4f3f5a6a9641e29e00e2","permalink":"https://binarymist.io/publication/privacy/","publishdate":"2015-12-22T00:00:00Z","relpermalink":"/publication/privacy/","section":"publication","summary":"BinaryMist Privacy Statement \nThe Short Version We collect your statistics only with your consent. We only collect the minimum amount of personal information required to understand the purpose of your interactions with this website. This information as far as we are aware will not be sold to third parties.\nFor more information read the below.\nAnalytics We are using Google Analytics (GA) as a third party tracking service. We do not use it to track you individually or collect personal information about you.","tags":null,"title":"Privacy","type":"publication"},{"authors":null,"categories":null,"content":"The content is aimed at software engineers to teach them how to think holistically about security. The theme that runs through the training and the book is pulling the security focus that’s usually left until the end of the project or “go live” right into each Sprint. Baking security into the product from the cheapest possible place. Thus saving large amounts of money due to re-work and business asset loss. Kim will be teaching attendees a very simple threat modelling process initially blue printed by one of the best security experts the world has known, Bruce Schneier, then how to apply that process to a 10,000′ view and lower for a collection of areas: Physical, People, Cloud, VPS, Network and Web Applications within each Sprint.\nA hands on training. Emulating the Scrum process and augmenting with the processes and practices as the day progresses. For each of the above areas mentioned, we will be creating Product Backlog Items and a Product Owner facilitating the ordering of them. Attendees will be able to take these learnings and apply them within their own Scrum Teams.\n","date":1449604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1449604800,"objectID":"c4c5dbc1d4ed0efec09beb6bf1997b19","permalink":"https://binarymist.io/talk/kiwicon-2015-workshop-holistic-info-sec-for-web-developers/","publishdate":"2015-12-09T09:00:00+13:00","relpermalink":"/talk/kiwicon-2015-workshop-holistic-info-sec-for-web-developers/","section":"talk","summary":"Kiwicon hands-on threat modelling, attack and defence strategy training for Web Developers wishing to understand their attackers better, stay ahead of them and create cost effective defence strategies.\n","tags":["workshop","security","physical-security","people-security","vps-security","network-security","cloud","cloud-security","dev-ops","dev-sec-ops","docker","web-application-security","web-security","web-application","holistic-info-sec-for-web-developers","application-security","cybersecurity","information-security","security-weaknesses","software-security","hacking","conference","operational-efficiencies","owasp"],"title":"Workshop - Holistic Info-Sec for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":"Kim then takes the word-lists and analysis of failed and successful login attempts to a web application and educates a collection of brute-forcing tools what an unsuccessful and successful login looks like. Then run the brute-forcing tools until the credentials have been discovered. This demonstrates that common password strategies are no longer sufficient to stop full account compromise and worse.\nThis is followed up with some tips on how to make this process a lot harder for attackers. Content can be found in Kims Holistic Infosec for Web Developers book.\n   ","date":1449165600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1449165600,"objectID":"d7fd6a065aa3f794eafa2a18be64401e","permalink":"https://binarymist.io/talk/toastmasters-2015-talk-password-profiling/","publishdate":"2015-12-04T07:00:00+13:00","relpermalink":"/talk/toastmasters-2015-talk-password-profiling/","section":"talk","summary":"Kim talks with his fellow Toastmasters about profiling peoples passwords and then brute forcing web applications with the shortlist of guessed passwords..\n","tags":["talk","hacking","cracking","application-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","networking","network-security","owasp","people-security","physical-security","sanitisation","security","security-weaknesses","software-security","sql-injection","ssh","vps","vps-security","web","xss","kdf","md5"],"title":"Talk - Password Profiling, Brute Forcing","type":"talk"},{"authors":null,"categories":null,"content":"In this talk Kim walks through the psychology of why humans succumb to infectious media attacks and how the attacker is easily able to leverage the human weaknesses to do their bidding. This is a very useful and effective approach at getting inside a target organisation with no physical or network access.\n When the human weaknesses are coupled with the inherent trust of Human Interface Devices (HID) we have a recipe for success, or disaster depending on which side of the equation you are on.\nKim walks through:\n Ducky Script Encoding the payload Loading the SD card and card into the device Distributing the devices Launching attacks  The community contributed attacks are also discussed and how to extend them.\nFinally mitigation techniques are explored. Including using the device of compromise to train potential targets how not to be targets.\n","date":1448562600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448562600,"objectID":"ce18b029491019ec7002371758d9765b","permalink":"https://binarymist.io/talk/toastmasters-2015-talk-infectious-media-with-rubber-ducky/","publishdate":"2015-11-27T07:30:00+13:00","relpermalink":"/talk/toastmasters-2015-talk-infectious-media-with-rubber-ducky/","section":"talk","summary":"Kim talks with his fellow Toastmasters about the risks and countermeasures of luring targets to execute infectious media on their devices.\n","tags":["talk","hacking","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","people-security","physical-security","security","security-weaknesses"],"title":"Talk - Infectious Media with Rubber Ducky","type":"talk"},{"authors":null,"categories":null,"content":" This post was taken from the content of the Web Applications chapter of Kim\u0026rsquo;s book Holistic Info-Sec for Web Developers F1\nRisks I see this as an indirect risk to the asset of web application ownership (That\u0026rsquo;s the assumption that you will always own your web application).\nNot being able to introspect your application at any given time or being able to know how the health status is, is not a comfortable place to be in and there is no reason you should be there.\nInsufficient Logging and Monitoring Can you tell at any point in time if someone or something is:\n Using your application in a way that it was not intended to be used Violating policy. For example circumventing client side input sanitisation.  How easy is it for you to notice:\n Poor performance and potential DoS? Abnormal application behaviour or unexpected logic threads Logic edge cases and blind spots that stake holders, Product Owners and Developers have missed?  Countermeasures As Bruce Schneier said: \u0026ldquo;Detection works where prevention fails and detection is of no use without response\u0026rdquo;. This leads us to application logging.\nWith good visibility we should be able to see anticipated and unanticipated exploitation of vulnerabilities as they occur and also be able to go back and review the events.\nInsufficient Logging When it comes to logging in NodeJS, you can\u0026rsquo;t really go past winston. It has a lot of functionality and what it does not have is either provided by extensions, or you can create your own. It is fully featured, reliable and easy to configure like NLog in the .NET world.\nI also looked at express-winston, but could not see why it needed to exist.\npackage.json { ... \u0026#34;dependencies\u0026#34;: { ..., \u0026#34;config\u0026#34;: \u0026#34;^1.15.0\u0026#34;, \u0026#34;express\u0026#34;: \u0026#34;^4.13.3\u0026#34;, \u0026#34;morgan\u0026#34;: \u0026#34;^1.6.1\u0026#34;, \u0026#34;//\u0026#34;: \u0026#34;nodemailer not strictly necessary for this example,\u0026#34;, \u0026#34;//\u0026#34;: \u0026#34;but used later under the node-config section.\u0026#34;, \u0026#34;nodemailer\u0026#34;: \u0026#34;^1.4.0\u0026#34;, \u0026#34;//\u0026#34;: \u0026#34;What we use for logging.\u0026#34;, \u0026#34;winston\u0026#34;: \u0026#34;^1.0.1\u0026#34;, \u0026#34;winston-email\u0026#34;: \u0026#34;0.0.10\u0026#34;, \u0026#34;winston-syslog-posix\u0026#34;: \u0026#34;^0.1.5\u0026#34;, ... } }\nwinston-email also depends on nodemailer.\nOpening UDP port with winston-syslog seems to be what a lot of people are using. I think it may be due to the fact that winston-syslog is the first package that works well for winston and syslog.\nIf going this route, you will need the following in your /etc/rsyslog.conf:\n$ModLoad imudp # Listen on all network addresses. This is the default. $UDPServerAddress 0.0.0.0 # Listen on localhost. $UDPServerAddress 127.0.0.1 $UDPServerRun 514 # Or the new style configuration. Address \u0026lt;IP\u0026gt; Port \u0026lt;port\u0026gt; # Logging for your app. local0.* /var/log/yourapp.log I Also looked at winston-rsyslog2 and winston-syslogudp, but they did not measure up for me.\nIf you do not need to push syslog events to another machine, then it does not make much sense to push through a local network interface when you can use your posix syscalls as they are faster and safer. The line 514/udp open|filtered syslog no-response below shows the open port.\nnmap with winston-syslog root@kali:~# nmap -p514 -sU -sV \u0026lt;target IP\u0026gt; --reason Starting Nmap 6.47 ( http://nmap.org ) Nmap scan report for kali (\u0026lt;target IP\u0026gt;) Host is up, received arp-response (0.0015s latency). PORT STATE SERVICE REASON VERSION 514/udp open|filtered syslog no-response MAC Address: 34C9AC:E0 (My Computer) Using Posix The winston-syslog-posix package was inspired by blargh. winston-syslog-posix uses node-posix.\nIf going this route, you will need the following in your /etc/rsyslog.conf instead of the above:\n# Logging for your app. local0.* /var/log/yourapp.log Now you can see on the 514/udp closed syslog port-unreach line below that the syslog port is no longer open:\nnmap with winston-syslog-posix root@kali:~# nmap -p514 -sU -sV \u0026lt;target IP\u0026gt; --reason Starting Nmap 6.47 ( http://nmap.org ) Nmap scan report for kali (\u0026lt;target IP\u0026gt;) Host is up, received arp-response (0.0014s latency). PORT STATE SERVICE REASON VERSION 514/udp closed syslog port-unreach MAC Address: 34C9AC:E0 (My Computer) Logging configuration should not be in the application startup file. It should be in the configuration files. This is discussed further under the Store Configuration in Configuration files section.\nNotice the syslog transport in the configuration below starting on the syslogPosixTransportOptions: { line.\ndefault.js 1module.exports = { 2 logger: { 3 colours: { 4 debug: \u0026#39;white\u0026#39;, 5 info: \u0026#39;green\u0026#39;, 6 notice: \u0026#39;blue\u0026#39;, 7 warning: \u0026#39;yellow\u0026#39;, 8 error: \u0026#39;yellow\u0026#39;, 9 crit: \u0026#39;red\u0026#39;, 10 alert: \u0026#39;red\u0026#39;, 11 emerg: \u0026#39;red\u0026#39; 12 }, 13 // Syslog compatible protocol severities. 14 levels: { 15 debug: 0, 16 info: 1, 17 notice: 2, 18 warning: 3, 19 error: 4, 20 crit: 5, 21 alert: 6, 22 emerg: 7 23 }, 24 consoleTransportOptions: { 25 level: \u0026#39;debug\u0026#39;, 26 handleExceptions: true, 27 json: false, 28 colorize: true 29 }, 30 fileTransportOptions: { 31 level: \u0026#39;debug\u0026#39;, 32 filename: \u0026#39;./yourapp.log\u0026#39;, 33 handleExceptions: true, 34 json: true, 35 maxsize: 5242880, //5MB 36 maxFiles: 5, 37 colorize: false 38 }, 39 syslogPosixTransportOptions: { 40 handleExceptions: true, 41 level: \u0026#39;debug\u0026#39;, 42 identity: \u0026#39;yourapp_winston\u0026#39; 43 //facility: \u0026#39;local0\u0026#39; // default 44 // /etc/rsyslog.conf also needs: local0.* /var/log/yourapp.log 45 // If non posix syslog is used, then /etc/rsyslog.conf or one 46 // of the files in /etc/rsyslog.d/ also needs the following 47 // two settings: 48 // $ModLoad imudp // Load the udp module. 49 // $UDPServerRun 514 // Open the standard syslog port. 50 // $UDPServerAddress 127.0.0.1 // Interface to bind to. 51 }, 52 emailTransportOptions: { 53 handleExceptions: true, 54 level: \u0026#39;crit\u0026#39;, 55 from: \u0026#39;yourusername_alerts@fastmail.com\u0026#39;, 56 to: \u0026#39;yourusername_alerts@fastmail.com\u0026#39;, 57 service: \u0026#39;FastMail\u0026#39;, 58 auth: { 59 user: \u0026#34;yourusername_alerts\u0026#34;, 60 pass: null // App specific password. 61 }, 62 tags: [\u0026#39;yourapp\u0026#39;] 63 } 64 } 65}  In development I have chosen here to not use syslog. You can see this on the syslogPosixTransportOptions: null line below. If you want to test syslog in development, you can either remove the logger object override from the devbox1-development.js file or modify it to be similar to the above. Then add one line to the /etc/rsyslog.conf file to turn on. As mentioned in a comment above in the default.js config file on the line // /etc/rsyslog.conf also needs: local0.* /var/log/yourapp.log.\ndevbox1-development.js wraplines=\u0026#34;false\u0026#34; highlight=\u0026#34;3\u0026#34; firstline=\u0026#34;1\u0026#34;] module.exports = { logger: { syslogPosixTransportOptions: null  } }  In production we log to syslog and because of that we do not need the file transport you can see configured starting on line 30 above in the default.js configuration file, so we set it to null as seen on line 6 below in the prodbox-production.js file.\nI have gone into more depth about how we handle syslogs here, where all of our logs including these ones get streamed to an off-site syslog server. Thus providing easy aggregation of all system logs into one user interface that DevOpps can watch on their monitoring panels in real-time and also easily go back in time to visit past events. This provides excellent visibility as one layer of defence.\nThere were also some other options for those using Papertrail as their off-site syslog and aggregation PaaS, but the solutions were not as clean as simply logging to local syslog from your applications and then sending off-site from there.\nprodbox-production.js wraplines=\u0026#34;false\u0026#34; highlight=\u0026#34;6\u0026#34; firstline=\u0026#34;1\u0026#34;] module.exports = { logger: { consoleTransportOptions: { level: {}, }, fileTransportOptions: null, syslogPosixTransportOptions: { handleExceptions: true, level: \u0026#39;info\u0026#39;, identity: \u0026#39;yourapp_winston\u0026#39; } } }  local.js // Build creates this file. module.exports = { logger: { emailTransportOptions: { auth: { pass: \u0026#39;Z-o?(7GnCQsnrx/!-G=LP]-ib\u0026#39; // App specific password.  } } } }  The logger.js file wraps and hides extra features and transports applied to the logging package we are consuming.\nlogger.js var winston = require(\u0026#39;winston\u0026#39;); var loggerConfig = require(\u0026#39;config\u0026#39;).logger; require(\u0026#39;winston-syslog-posix\u0026#39;).SyslogPosix; require(\u0026#39;winston-email\u0026#39;).Email; winston.emitErrs = true; var logger = new winston.Logger({ // Alternatively: set to winston.config.syslog.levels  exitOnError: false, // Alternatively use winston.addColors(customColours); There are many ways  // to do the same thing with winston  colors: loggerConfig.colours, levels: loggerConfig.levels }); // Add transports. There are plenty of options provided and you can add your own.  logger.addConsole = function(config) { logger.add (winston.transports.Console, config); return this; }; logger.addFile = function(config) { logger.add (winston.transports.File, config); return this; }; logger.addPosixSyslog = function(config) { logger.add (winston.transports.SyslogPosix, config); return this; }; logger.addEmail = function(config) { logger.add (winston.transports.Email, config); return this; }; logger.emailLoggerFailure = function (err /*level, msg, meta*/) { // If called with an error, then only the err param is supplied.  // If not called with an error, level, msg and meta are supplied.  if (err) logger.alert( JSON.stringify( \u0026#39;error-code:\u0026#39; + err.code + \u0026#39;. \u0026#39; + \u0026#39;error-message:\u0026#39; + err.message + \u0026#39;. \u0026#39; + \u0026#39;error-response:\u0026#39; + err.response + \u0026#39;. logger-level:\u0026#39; + err.transport.level + \u0026#39;. transport:\u0026#39; + err.transport.name ) ); }; logger.init = function () { if (loggerConfig.fileTransportOptions) logger.addFile( loggerConfig.fileTransportOptions ); if (loggerConfig.consoleTransportOptions) logger.addConsole( loggerConfig.consoleTransportOptions ); if (loggerConfig.syslogPosixTransportOptions) logger.addPosixSyslog( loggerConfig.syslogPosixTransportOptions ); if (loggerConfig.emailTransportOptions) logger.addEmail( loggerConfig.emailTransportOptions ); }; module.exports = logger; module.exports.stream = { write: function (message, encoding) { logger.info(message); } };  When the app first starts it initialises the logger on the logger.init(); line below.\napp.js //... var express = require(\u0026#39;express\u0026#39;); var morganLogger = require(\u0026#39;morgan\u0026#39;); var logger = require(\u0026#39;./util/logger\u0026#39;); // Or use requireFrom module so no relative paths. var app = express(); //... logger.init(); app.set(\u0026#39;port\u0026#39;, process.env.PORT || 3000); app.set(\u0026#39;views\u0026#39;, __dirname + \u0026#39;/views\u0026#39;); app.set(\u0026#39;view engine\u0026#39;, \u0026#39;jade\u0026#39;); //... // In order to utilise connect/express logger module in our third party logger, // Pipe the messages through. app.use(morganLogger(\u0026#39;combined\u0026#39;, {stream: logger.stream})); //... app.use(express.static(path.join(__dirname, \u0026#39;public\u0026#39;))); //... require(\u0026#39;./routes\u0026#39;)(app); if (\u0026#39;development\u0026#39; == app.get(\u0026#39;env\u0026#39;)) { app.use(errorHandler({ dumpExceptions: true, showStack: true })); //... } if (\u0026#39;production\u0026#39; == app.get(\u0026#39;env\u0026#39;)) { app.use(errorHandler()); //... } http.createServer(app).listen(app.get(\u0026#39;port\u0026#39;), function(){ logger.info( \u0026#34;Express server listening on port \u0026#34; + app.get(\u0026#39;port\u0026#39;) + \u0026#39; in \u0026#39; + process.env.NODE_ENV + \u0026#39; mode\u0026#39; ); });   You can also optionally log JSON metadata You can provide an optional callback to do any work required, which will be called once all transports have logged the specified message  Here are some examples of how you can use the logger. The logger.log(\u0026lt;level\u0026gt; can be replaced with logger.\u0026lt;level\u0026gt;( where level is any of the levels defined in the default.js configuration file above:\nAnywhere you need logging // With string interpolation also. logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message %s\u0026#39;, \u0026#39;my string\u0026#39;); logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message %d\u0026#39;, 123); logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message %j\u0026#39;, {aPropertyName: \u0026#39;Some message details\u0026#39;}, {}); logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message %s, %s\u0026#39;, \u0026#39;first\u0026#39;, \u0026#39;second\u0026#39;, {aPropertyName: \u0026#39;Some message details\u0026#39;}); logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message\u0026#39;, \u0026#39;first\u0026#39;, \u0026#39;second\u0026#39;, {aPropertyName: \u0026#39;Some message details\u0026#39;}); logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message %s, %s\u0026#39;, \u0026#39;first\u0026#39;, \u0026#39;second\u0026#39;, {aPropertyName: \u0026#39;Some message details\u0026#39;}, logger.emailLoggerFailure); logger.log(\u0026#39;info\u0026#39;, \u0026#39;test message\u0026#39;, \u0026#39;first\u0026#39;, \u0026#39;second\u0026#39;, {aPropertyName: \u0026#39;Some message details\u0026#39;}, logger.emailLoggerFailure);  Also consider hiding cross cutting concerns like logging using Aspect Oriented Programing (AOP)\nInsufficient Monitoring There are a couple of ways of approaching monitoring. You may want to see the health of your application even if it is all fine, or only to be notified if it is not fine (sometimes called the dark cockpit approach).\nMonit is an excellent tool for the dark cockpit approach. It\u0026rsquo;s easy to configure. Has excellent short documentation that is easy to understand and the configuration file has lots of examples commented out ready for you to take as is and modify to suite your environment.\nRisks that Solution Causes Lack of Visibility With the added visibility, you will have to make decisions based on the new found information you now have. There will be no more blissful ignorance if there was before.\nInsufficient Logging and Monitoring There will be learning and work to be done to become familiar with libraries and tooling. Code will have to be written around logging as in wrapping libraries, initialising and adding logging statements or hiding them using AOP.\nCosts and Trade-offs Insufficient Logging and Monitoring You can do a lot for little cost here. I would rather trade off a few days work in order to have a really good logging system through your code base that is going to show you errors fast in development and then show you different errors in the places your DevOps need to see them in production.\nSame for monitoring. Find a tool that you find working with a pleasure. There are just about always free and open source tools to every commercial alternative. If you are working with a start-up or young business, the free and open source tools can be excellent to keep ongoing costs down. Especially mature tools that are also well maintained like Monit.\nAdditional Resources  Details that helped setup NodeJS logging Application logging to syslog server on another machine:  http://unix.stackexchange.com/questions/67250/where-does-rsyslog-keep-facility-local0 http://wiki.rsyslog.com/index.php/Very_simple_config_--_starting_point_for_modifications  Or the new style configuration Syslog compatible protocol severities  ","date":1448449200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1448449200,"objectID":"dffe05c0400189e66ce6876f3c829acc","permalink":"https://binarymist.io/blog/2015/11/26/lack-of-visibility-in-web-applications/","publishdate":"2015-11-26T00:00:00+13:00","relpermalink":"/blog/2015/11/26/lack-of-visibility-in-web-applications/","section":"post","summary":"Not being able to introspect your application at any given time or being able to know how the health status is, is not a comfortable place to be in and there is no reason you should be there.\n","tags":["application-security","book","cybersecurity","express","holistic-info-sec-for-web-developers","information-security","infosec","javascript","kali","kali-linux","logging","monit","morgan","nmap","nodejs","nodemailer","npm","posix","rsyslog","security","security-weaknesses","web-application-security","web-security","winston","winston-syslog","winston-syslog-posix"],"title":"Lack of Visibility in Web Applications","type":"post"},{"authors":null,"categories":null,"content":"  Consuming Free and Open Source  \n","date":1446030000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1446030000,"objectID":"7d6dd4d2e1b27d3f698faabe5059259a","permalink":"https://binarymist.io/blog/2015/10/29/consuming-free-and-open-source/","publishdate":"2015-10-29T00:00:00+13:00","relpermalink":"/blog/2015/10/29/consuming-free-and-open-source/","section":"post","summary":"Redirects to legacy blog post.\n\nThis is where A9 (Using Components with Known Vulnerabilities) of the 2013 OWASP Top 10 comes in. We are consuming far more free and open source libraries than we have ever before. Much of the code we are pulling into our projects is never intentionally used, but is still adding surface area for attack. In this post we address the risks and countermeasures.\n","tags":["application-security","bithound","book","cybersecurity","git","grunt","gulp","holistic-info-sec-for-web-developers","information-security","infosec","javascript","nodejs","npm","owasp","owasp-top-10","owasp-zap","requiresafe","retirejs","safenuget","security","security-weaknesses","stdd","tdd","test","testing","web-application-security","web-security","zap"],"title":"Consuming Free and Open Source","type":"post"},{"authors":null,"categories":null,"content":" The presentation is basically the process I take to carry out a small client penetration testing assignment, but with a focus on why and how web developers should be doing the same within their teams. It goes through:\nWhy we even care about breaking our or a clients code and/or system(s)\n Reconnaissance (information gathering), tools and tips Vulnerability scanning, tools and tips Vulnerability searching, tools and tips Exploitation, where to start, how to start, tools (and why) and tips  \n Demo 1: Exploiting an XSS vulnerable web app and what you can get from it. The whole reason being here is to be able to show your employer / boss / client and why they need to do something about it. After seeing how easy it is and what you can do, few will deny that it just needs to be fixed.\n   Discuss countermeasures  Demo 2: Exploiting people with spear phishing, obtaining their credentials by cloning, spoofing a website they frequently login at with the Social Engineer Toolkit\u0026rsquo;s (SET) Credential Harvester.\n   Discuss countermeasures doppelganger domains (domains that look like the real thing but are fakes)  Demo 3: Add ARP and DNS spoofing to the mix. Now when a victim browsers to a website that they like to spend time at, they will be visiting our spoofed website. We add the Browser Exploitation Framework (BeEF) hook.js to the cloned website. This hook converts the victims browser into a zombie that continually polls the BeEF comms server requesting commands to execute on the victims machine. This is the window of time we use to install a root-kit and pwn the victims machine.\n   Discuss countermeasures Discuss what we can do with BeEF  Demo 4: Again we clone and host a website we know the victim likes to visit with SET. We use a couple of Metasploit attack methods and exploit memory injection. Then select a collection of payloads to deliver via shell code injection. Encrypt the payloads and configure the reverse shells. launch Metasploit and watch the reverse shells connect. Attempt to escalate privileges to system account. anti-virus (AV) stops us.\n   Demo 5: We use Veil-Evasion to get around AV by creating our payload. We encrypt the payload with Hyperion using a weak 128-bit AES key, which decrypts itself by brute force at the time of execution on the victims machine. We use Metasploit to deliver our psexec exploit that we created with Veil-Evasion and Hyperion. We watch the attackers reverse shell connect straight to the system account.\n   Discuss countermeasures   \n","date":1443551400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1443551400,"objectID":"af3d79d505548ea76c803e99d8a1d37a","permalink":"https://binarymist.io/talk/owaspchch-meetup-2015-talk-the-exploited-and-the-exploiters/","publishdate":"2015-09-30T07:30:00+13:00","relpermalink":"/talk/owaspchch-meetup-2015-talk-the-exploited-and-the-exploiters/","section":"talk","summary":"Taking the perspective of the penetration tester hired in by the target to find the defects in their security defences before the cyber criminals do.\n","tags":["talk","hacking","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","people-security","physical-security","security","security-weaknesses"],"title":"Talk - The Exploited \u0026 the Exploiters","type":"talk"},{"authors":null,"categories":null,"content":"  Risks and Countermeasures to the Management of Application Secrets  \n","date":1442404800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442404800,"objectID":"0775de2123e724f6c4ce24a21bcef9be","permalink":"https://binarymist.io/blog/2015/09/17/risks-and-countermeasures-to-the-management-of-application-secrets/","publishdate":"2015-09-17T00:00:00+12:00","relpermalink":"/blog/2015/09/17/risks-and-countermeasures-to-the-management-of-application-secrets/","section":"post","summary":"Redirects to legacy blog post.\n","tags":["application-security","asic","bcrypt","blowfish","book","cipher","crypto","cryptography","deployment","eksblowfish","encryption","fgdump","field-programmable-gate-arrays","fpga","gnu-linux","gpu","hash-dump","hmac","holistic-info-sec-for-web-developers","information-security","infosec","javascript","kdf","key-derivation-function","linux","lsass","md5","mimikatz","nodejs","parallelisation","pbkdf2","prf","pseudorandom-function","salt","scrypt","secure-boot","security","sha-1","sha-2","sha-256","uefi","wce","hashing","web-security"],"title":"Risks and Countermeasures to the Management of Application Secrets","type":"post"},{"authors":null,"categories":null,"content":" Due to popular demand, this presentation is running again. This time at Functional Christchurch.   \n The presentation is basically the process I take to carry out a small client penetration testing assignment, but with a focus on why and how web developers should be doing the same within their teams. It goes through:\nWhy we even care about breaking our or a clients code and/or system(s)\n Reconnaissance (information gathering), tools and tips Vulnerability scanning, tools and tips Vulnerability searching, tools and tips Exploitation, where to start, how to start, tools (and why) and tips  \n Demo 1: Exploiting an XSS vulnerable web app and what you can get from it. The whole reason being here is to be able to show your employer / boss / client and why they need to do something about it. After seeing how easy it is and what you can do, few will deny that it just needs to be fixed.\n   Discuss countermeasures  Demo 2: Exploiting people with spear phishing, obtaining their credentials by cloning, spoofing a website they frequently login at with the Social Engineer Toolkit\u0026rsquo;s (SET) Credential Harvester.\n   Discuss countermeasures doppelganger domains (domains that look like the real thing but are fakes)  Demo 3: Add ARP and DNS spoofing to the mix. Now when a victim browsers to a website that they like to spend time at, they will be visiting our spoofed website. We add the Browser Exploitation Framework (BeEF) hook.js to the cloned website. This hook converts the victims browser into a zombie that continually polls the BeEF comms server requesting commands to execute on the victims machine. This is the window of time we use to install a root-kit and pwn the victims machine.\n   Discuss countermeasures Discuss what we can do with BeEF  Demo 4: Again we clone and host a website we know the victim likes to visit with SET. We use a couple of Metasploit attack methods and exploit memory injection. Then select a collection of payloads to deliver via shell code injection. Encrypt the payloads and configure the reverse shells. launch Metasploit and watch the reverse shells connect. Attempt to escalate privileges to system account. anti-virus (AV) stops us.\n   Demo 5: We use Veil-Evasion to get around AV by creating our payload. We encrypt the payload with Hyperion using a weak 128-bit AES key, which decrypts itself by brute force at the time of execution on the victims machine. We use Metasploit to deliver our psexec exploit that we created with Veil-Evasion and Hyperion. We watch the attackers reverse shell connect straight to the system account.\n   Discuss countermeasures   \n","date":1442296800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442296800,"objectID":"cd9619ff8ddad4df60259080bbbc0e7c","permalink":"https://binarymist.io/talk/functional-meetup-2015-talk-0wn1ng-the-web/","publishdate":"2015-09-15T18:00:00+12:00","relpermalink":"/talk/functional-meetup-2015-talk-0wn1ng-the-web/","section":"talk","summary":"At Functional Christchurch, due to popular demand. Taking the perspective of the penetration tester hired in by the target to find the defects in their security defences before the cyber criminals do.\n","tags":["talk","hacking","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","people-security","physical-security","security","security-weaknesses"],"title":"Talk - 0wn1ng The Web","type":"talk"},{"authors":null,"categories":null,"content":" Due to popular demand, this presentation is running again. This time at Christchurch Test Professionals Network.   \n The presentation is basically the process I take to carry out a small client penetration testing assignment, but with a focus on why and how web developers should be doing the same within their teams. It goes through:\nWhy we even care about breaking our or a clients code and/or system(s)\n Reconnaissance (information gathering), tools and tips Vulnerability scanning, tools and tips Vulnerability searching, tools and tips Exploitation, where to start, how to start, tools (and why) and tips  \n Demo 1: Exploiting an XSS vulnerable web app and what you can get from it. The whole reason being here is to be able to show your employer / boss / client and why they need to do something about it. After seeing how easy it is and what you can do, few will deny that it just needs to be fixed.\n   Discuss countermeasures  Demo 2: Exploiting people with spear phishing, obtaining their credentials by cloning, spoofing a website they frequently login at with the Social Engineer Toolkit\u0026rsquo;s (SET) Credential Harvester.\n   Discuss countermeasures doppelganger domains (domains that look like the real thing but are fakes)  Demo 3: Add ARP and DNS spoofing to the mix. Now when a victim browsers to a website that they like to spend time at, they will be visiting our spoofed website. We add the Browser Exploitation Framework (BeEF) hook.js to the cloned website. This hook converts the victims browser into a zombie that continually polls the BeEF comms server requesting commands to execute on the victims machine. This is the window of time we use to install a root-kit and pwn the victims machine.\n   Discuss countermeasures Discuss what we can do with BeEF  Demo 4: Again we clone and host a website we know the victim likes to visit with SET. We use a couple of Metasploit attack methods and exploit memory injection. Then select a collection of payloads to deliver via shell code injection. Encrypt the payloads and configure the reverse shells. launch Metasploit and watch the reverse shells connect. Attempt to escalate privileges to system account. anti-virus (AV) stops us.\n   Demo 5: We use Veil-Evasion to get around AV by creating our payload. We encrypt the payload with Hyperion using a weak 128-bit AES key, which decrypts itself by brute force at the time of execution on the victims machine. We use Metasploit to deliver our psexec exploit that we created with Veil-Evasion and Hyperion. We watch the attackers reverse shell connect straight to the system account.\n   Discuss countermeasures   \n","date":1441692000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441692000,"objectID":"08ffd8334d2ea9c8ff922c64cefb68ca","permalink":"https://binarymist.io/talk/test-professionals-network-2015-talk-0wn1ng-the-web/","publishdate":"2015-09-08T18:00:00+12:00","relpermalink":"/talk/test-professionals-network-2015-talk-0wn1ng-the-web/","section":"talk","summary":"At Test Professionals Network Christchurch, due to popular demand. Taking the perspective of the penetration tester hired in by the target to find the defects in their security defences before the cyber criminals do.\n","tags":["talk","hacking","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","people-security","physical-security","security","security-weaknesses"],"title":"Talk - 0wn1ng The Web","type":"talk"},{"authors":null,"categories":null,"content":"  TL-WN722N on Kali VM on Linux Host  \n","date":1441195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441195200,"objectID":"3c49b5e526716a845675f77cfcd11345","permalink":"https://binarymist.io/blog/2015/09/03/tl-wn722n-on-kali-vm-on-linux-host/","publishdate":"2015-09-03T00:00:00+12:00","relpermalink":"/blog/2015/09/03/tl-wn722n-on-kali-vm-on-linux-host/","section":"post","summary":"Redirects to legacy blog post.\n\nThe following is the process I found to set-up the pass-through of the very common USB TP-LINK TL-WN722N Wifi adapter (which is known to work well with Linux) to a Virtual Host Kali Linux 1.1.0 (same process for 2.0) guest, by-passing the Linux Mint 17.1 (Rebecca) Host.\n","tags":["ath9k-htc","atheros","gnu-linux","hardware","kali-linux","kali","linux","networking","penetration-testing","tl-wn722n","virtualbox","wi-fi","wireless","wireless-networking"],"title":"TL-WN722N on Kali VM on Linux Host","type":"post"},{"authors":null,"categories":null,"content":"  Due to popular demand, this presentation is running again. This time at Chch.js Christchurch.   \n The presentation is basically the process I take to carry out a small client penetration testing assignment, but with a focus on why and how web developers should be doing the same within their teams. It goes through:\nWhy we even care about breaking our or a clients code and/or system(s)\n Reconnaissance (information gathering), tools and tips Vulnerability scanning, tools and tips Vulnerability searching, tools and tips Exploitation, where to start, how to start, tools (and why) and tips  \n Demo 1: Exploiting an XSS vulnerable web app and what you can get from it. The whole reason being here is to be able to show your employer / boss / client and why they need to do something about it. After seeing how easy it is and what you can do, few will deny that it just needs to be fixed.\n   Discuss countermeasures  Demo 2: Exploiting people with spear phishing, obtaining their credentials by cloning, spoofing a website they frequently login at with the Social Engineer Toolkit\u0026rsquo;s (SET) Credential Harvester.\n   Discuss countermeasures doppelganger domains (domains that look like the real thing but are fakes)  Demo 3: Add ARP and DNS spoofing to the mix. Now when a victim browsers to a website that they like to spend time at, they will be visiting our spoofed website. We add the Browser Exploitation Framework (BeEF) hook.js to the cloned website. This hook converts the victims browser into a zombie that continually polls the BeEF comms server requesting commands to execute on the victims machine. This is the window of time we use to install a root-kit and pwn the victims machine.\n   Discuss countermeasures Discuss what we can do with BeEF  Demo 4: Again we clone and host a website we know the victim likes to visit with SET. We use a couple of Metasploit attack methods and exploit memory injection. Then select a collection of payloads to deliver via shell code injection. Encrypt the payloads and configure the reverse shells. launch Metasploit and watch the reverse shells connect. Attempt to escalate privileges to system account. anti-virus (AV) stops us.\n   Demo 5: We use Veil-Evasion to get around AV by creating our payload. We encrypt the payload with Hyperion using a weak 128-bit AES key, which decrypts itself by brute force at the time of execution on the victims machine. We use Metasploit to deliver our psexec exploit that we created with Veil-Evasion and Hyperion. We watch the attackers reverse shell connect straight to the system account.\n   Discuss countermeasures   \nWhat others have said \n\n","date":1438239600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438239600,"objectID":"ac9ed5a29c8b9eeca0b8fb4460d9dc02","permalink":"https://binarymist.io/talk/chchjs-meetup-2015-talk-0wn1ng-the-web/","publishdate":"2015-07-30T19:00:00+12:00","relpermalink":"/talk/chchjs-meetup-2015-talk-0wn1ng-the-web/","section":"talk","summary":"At CHCH.js Christchurch, due to popular demand. Taking the perspective of the penetration tester hired in by the target to find the defects in their security defences before the cyber criminals do.\n","tags":["talk","hacking","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","people-security","physical-security","security","security-weaknesses"],"title":"Talk - 0wn1ng The Web","type":"talk"},{"authors":null,"categories":null,"content":" New advances in technology look shiny… until we stop believing the hype, open our minds and start poking at them. Let me show you what happens when we start poking.\nPresentation Video \n  \nSlide Deck \n The presentation is basically the process I take to carry out a small client penetration testing assignment, but with a focus on why and how web developers should be doing the same within their teams. It goes through:\nWhy we even care about breaking our or a clients code and/or system(s)\n\n Reconnaissance (information gathering), tools and tips Vulnerability scanning, tools and tips Vulnerability searching, tools and tips Exploitation, where to start, how to start, tools (and why) and tips   No Room Left!    Demo 1: Exploiting an XSS vulnerable web app and what you can get from it. The whole reason being here is to be able to show your employer / boss / client and why they need to do something about it. After seeing how easy it is and what you can do, few will deny that it just needs to be fixed.\n   Discuss countermeasures  Demo 2: Exploiting people with spear phishing, obtaining their credentials by cloning, spoofing a website they frequently login at with the Social Engineer Toolkit\u0026rsquo;s (SET) Credential Harvester.\n   Discuss countermeasures doppelganger domains (domains that look like the real thing but are fakes)  Demo 3: Add ARP and DNS spoofing to the mix. Now when a victim browsers to a website that they like to spend time at, they will be visiting our spoofed website. We add the Browser Exploitation Framework (BeEF) hook.js to the cloned website. This hook converts the victims browser into a zombie that continually polls the BeEF comms server requesting commands to execute on the victims machine. This is the window of time we use to install a root-kit and pwn the victims machine.\n   Discuss countermeasures Discuss what we can do with BeEF  Demo 4: Again we clone and host a website we know the victim likes to visit with SET. We use a couple of Metasploit attack methods and exploit memory injection. Then select a collection of payloads to deliver via shell code injection. Encrypt the payloads and configure the reverse shells. launch Metasploit and watch the reverse shells connect. Attempt to escalate privileges to system account. anti-virus (AV) stops us.\n   Demo 5: We use Veil-Evasion to get around AV by creating our payload. We encrypt the payload with Hyperion using a weak 128-bit AES key, which decrypts itself by brute force at the time of execution on the victims machine. We use Metasploit to deliver our psexec exploit that we created with Veil-Evasion and Hyperion. We watch the attackers reverse shell connect straight to the system account.\n   Discuss countermeasures   \n","date":1437621000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437621000,"objectID":"f8746530a87d52ef0fbce317ec01a4b0","permalink":"https://binarymist.io/talk/wdcnz-2015-0wn1ng-the-web/","publishdate":"2015-07-23T15:10:00+12:00","relpermalink":"/talk/wdcnz-2015-0wn1ng-the-web/","section":"talk","summary":"At WDCNZ: Kim discusses and demonstrates how JavaScript can be used for good and evil.\n","tags":["talk","hacking","conference","agile","application-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","operational-efficiencies","penetration-testing","people-security","power-shell","ps","reconnaissance","sanitisation","security","security-weaknesses","software-security","stdd"],"title":"Talk - 0wn1ng The Web","type":"talk"},{"authors":null,"categories":null,"content":" Due to popular demand, this presentation is running again. This time at Christchurch Dot Net User Group.   \n ","date":1435642200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435642200,"objectID":"6404c5c2882f13510cd8f5db8606a3f6","permalink":"https://binarymist.io/talk/dotnet-user-group-2015-talk-does-your-cloud-solution-look-like-a-mushroom/","publishdate":"2015-06-30T17:30:00+12:00","relpermalink":"/talk/dotnet-user-group-2015-talk-does-your-cloud-solution-look-like-a-mushroom/","section":"talk","summary":"At Dot Net User Group, Christchurch, due to popular demand this presentation is being run again. Drawing from Kim's recent blog post \"[Journey to Self Hosting](https://binarymist.wordpress.com/2014/11/29/journey-to-self-hosting/)\" and many more resources for some high-level ideas about cloud solutions. Kim will discuss what's good and what's not good about \"the Cloud\".\n","tags":["talk","cloud","cloud-security","cybersecurity","information-security","infosec","security"],"title":"Talk - Does Your Cloud Solution Look Like a Mushroom","type":"talk"},{"authors":null,"categories":null,"content":"  Keeping Your NodeJS Web App Running on Production Linux  \n","date":1435233600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435233600,"objectID":"ca632743754fa96a6cf9059f22a02027","permalink":"https://binarymist.io/blog/2015/06/26/keeping-your-nodejs-web-app-running-on-production-linux/","publishdate":"2015-06-26T00:00:00+12:00","relpermalink":"/blog/2015/06/26/keeping-your-nodejs-web-app-running-on-production-linux/","section":"post","summary":"Redirects to legacy blog post.\n\nAll the following offerings that I’ve evaluated target different scenarios. I’ve listed the pros and cons for each of them and where I think they fit into a potential solution to monitor your web applications (I’m leaning toward NodeJS) and make sure they keep running.\n","tags":["cloud","debian","dev-ops","forever","gnu-linux","hids","linux","monit","networking","passenger","pm2","security","supervisor","sys-admin","systemd","sysvinit","upstart","vps"],"title":"Keeping Your NodeJS Web App Running on Production Linux","type":"post"},{"authors":null,"categories":null,"content":" Due to popular demand, this presentation is running again. This time at Christchurch Dot Net User Group.   \n ","date":1435129200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435129200,"objectID":"c028fddfe59071e5565c65be3963c17c","permalink":"https://binarymist.io/talk/owaspnz-chch-meetup-2015-talk-does-your-cloud-solution-look-like-a-mushroom/","publishdate":"2015-06-24T19:00:00+12:00","relpermalink":"/talk/owaspnz-chch-meetup-2015-talk-does-your-cloud-solution-look-like-a-mushroom/","section":"talk","summary":"At OWASP meetup, Christchurch, due to popular demand this presentation is being run again. Drawing from Kim's recent blog post \"[Journey to Self Hosting](https://binarymist.wordpress.com/2014/11/29/journey-to-self-hosting/)\" and many more resources for some high-level ideas about cloud solutions. Kim will discuss what's good and what's not good about \"the Cloud\".\n","tags":["talk","cloud","cloud-security","cybersecurity","information-security","infosec","security"],"title":"Talk - Does Your Cloud Solution Look Like a Mushroom","type":"talk"},{"authors":null,"categories":null,"content":"Kim then goes over a collection of techniques that end users can employ to keep themselves safe while we’re waiting for developers to accept the call to action and increase their knowledge and ability to create robust software and networks.\n\n ","date":1433446200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433446200,"objectID":"898027aa11727527935782b451d02f94","permalink":"https://binarymist.io/talk/toastmasters-2015-talk-passwords-101/","publishdate":"2015-06-05T07:30:00+12:00","relpermalink":"/talk/toastmasters-2015-talk-passwords-101/","section":"talk","summary":"In this 5 – 7 minute talk, Kim demonstrates (hands on) how easy it can be to compromise passwords using a collection of techniques. Kim discusses how most developers are failing at keeping their end users safe.\n","tags":["talk","cybersecurity","holistic-info-sec-for-web-developers","information-security","infosec","people-security","security","security-weaknesses"],"title":"Talk - Passwords 101","type":"talk"},{"authors":null,"categories":null,"content":"  Evaluation of Host Intrusion Detection Systems (HIDS)  \n","date":1432900800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1432900800,"objectID":"18a01e47794072f27e44abbf0b44fff7","permalink":"https://binarymist.io/blog/2015/05/30/evaluation-of-host-intrusion-detection-systems-hids/","publishdate":"2015-05-30T00:00:00+12:00","relpermalink":"/blog/2015/05/30/evaluation-of-host-intrusion-detection-systems-hids/","section":"post","summary":"Redirects to legacy blog post.\n\nThe best time to install a HIDS is on a fresh install before you open the host up to the internet or even your LAN if it’s corporate. Of course if you don’t have that luxury, there are a bunch of tools that can help you determine if you’re already owned. Be sure to run one or more over your target system before your HIDS bench-marks it.\n","tags":["debian","dev-ops","gnu-linux","hids","ids","infosec","ips","linux","networking","ossec","security","stealth","sys-admin"],"title":"Evaluation of Host Intrusion Detection Systems (HIDS)","type":"post"},{"authors":null,"categories":null,"content":" This was the very first workshop performed as Kim\u0026rsquo;s book series was just getting started.   We will also look at other tried and tested practices and processes for reducing security defects early. That is every Sprint for each Product Backlog Item (PBI). As an architect, engineer and security specialist, Kim will uncover how to identify the lowest hanging fruit (for the attackers) by taking a holistic approach (a 30,000′ view), then honing in on the areas with the highest security ratings, based on a tried and tested threat modelling process that allows you to discover and prioritise the defects most likely to be compromised by attackers of your systems.\n \nWe are going to look at automating (Security Test (Behaviour) Driven Development (STDD/SBDD)) some of the traditional manual based penetration testing methods often performed after go live and bringing them forward into parallel with your development cycles (Sprints). Thus empowering Developers to do what was once only performed by deeply specialised security consultancies at the end of the project. Dramatically increasing the confidence we as developers have in what we are delivering, thus reducing the cost of change due to defects being found as they are introduced rather than at go live. Trainee Requirements:\n Laptop or something able to run the following Some virtualisation software able to run an ISO. I.E. VirtualBox or VMWare Test tools required  Kali Linux (physical or bootable USB stick or VM)    ","date":1432429200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1432429200,"objectID":"8a619926e9154a6b7c9595fa3ff1ac8c","permalink":"https://binarymist.io/talk/campjs-2015-workshop-holistic-infosec-for-web-developers/","publishdate":"2015-05-24T13:00:00+12:00","relpermalink":"/talk/campjs-2015-workshop-holistic-infosec-for-web-developers/","section":"talk","summary":"At CampJS, Melbourne, Australia: Join Kim in the exploration into an insightful set of steps he has learned, from an architectural perspective down to the zeros and ones. Also providing insights of how attackers of your systems think.\n","tags":["talk","hacking","conference","agile","application-security","cybersecurity","dev-ops","dev-sec-ops","holistic-info-sec-for-web-developers","information-security","infosec","penetration-testing","people-security","reconnaissance","sanitisation","security","security-weaknesses","software-security","stdd"],"title":"Workshop - Holistic Info-Sec for Web Developers","type":"talk"},{"authors":null,"categories":null,"content":"\n ","date":1430280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430280000,"objectID":"7ccbc37cdb864f06453f974dc0f137c9","permalink":"https://binarymist.io/talk/saturn-2015-talk-does-your-cloud-solution-look-like-a-mushroom/","publishdate":"2015-04-29T16:00:00+12:00","relpermalink":"/talk/saturn-2015-talk-does-your-cloud-solution-look-like-a-mushroom/","section":"talk","summary":"Saturn Architect Conference, Baltimore, MD, USA: Drawing from Kim's recent blog post \"[Journey to Self Hosting](https://binarymist.wordpress.com/2014/11/29/journey-to-self-hosting/)\" and many more resources for some high-level ideas about cloud solutions. Kim will discuss what's good and what's not good about \"the Cloud\".\n","tags":["talk","cloud","cloud-security","cybersecurity","information-security","infosec","security"],"title":"Talk - Does Your Cloud Solution Look Like a Mushroom","type":"talk"},{"authors":null,"categories":null,"content":"  Web Server Log Management  \n","date":1429876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1429876800,"objectID":"917ebdfb13e46cee5627889fc62eb32b","permalink":"https://binarymist.io/blog/2015/04/25/web-server-log-management/","publishdate":"2015-04-25T00:00:00+12:00","relpermalink":"/blog/2015/04/25/web-server-log-management/","section":"post","summary":"Redirects to legacy blog post.\n\nAs part of the ongoing work around preparing a Debian web server to host applications accessible from the WWW I performed some research, analysis, made decisions along the way and implemented a first stage logging strategy. I’ve done similar set-ups many times before, but thought it worth sharing my experience for all to learn something from it and/or provide input, recommendations, corrections to the process so we all get to improve.\n","tags":["arp-poisoning","arp-spoof","debian","dev-ops","dsniff","gnu-linux","infosec","kali","linux","kali-linux","macof","mitm","networking","reconnaissance","relp","rsyslog","scp","security","sniffing","ss","sys-admin","syslog","tcp","telnet","tls","udp","wireshark"],"title":"Web Server Log Management","type":"post"},{"authors":null,"categories":null,"content":" Architectural and Security Consulting\n    Provided architectural, engineering and security guidance to the Wholesaler development team.\nMigrated parts of the C#.Net solution to a CQRS approach.\nLarge cost savings.    ","date":1427846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427846400,"objectID":"420db87b117a98d728c189a5d8717ff6","permalink":"https://binarymist.io/project/portfolio-lentune/","publishdate":"2015-04-01T00:00:00Z","relpermalink":"/project/portfolio-lentune/","section":"project","summary":"Architectural \u0026#38; Security Consulting","tags":["portfolio","architecture-engineering-portfolio","security-portfolio"],"title":"Lentune","type":"project"},{"authors":null,"categories":null,"content":"  Keeping Your Linux Server/s In Time With Your Router  \n","date":1427454000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427454000,"objectID":"e64e7c9c43c9061363f0c8846ef9d01e","permalink":"https://binarymist.io/blog/2015/03/28/keeping-your-linux-server/s-in-time-with-your-router/","publishdate":"2015-03-28T00:00:00+13:00","relpermalink":"/blog/2015/03/28/keeping-your-linux-server/s-in-time-with-your-router/","section":"post","summary":"Redirects to legacy blog post.\n\nWith this set-up, we’ve got one-to-many Linux servers in a network that all want to be synced with the same up-stream Network Time Protocol (NTP) server/s that your router (or what ever server you choose to be your NTP authority) uses.\n","tags":["dev-ops","freebsd","gnu-linux","linux","networking","ntp","sys-admin","vps"],"title":"Keeping Your Linux Server/s In Time With Your Router","type":"post"},{"authors":null,"categories":null,"content":"Similar to last year:\n We will be offering training on the day before the conference (Thursday, 26th of February) After lunch on the conference day, we will split into two tracks – one focused on technical topics, the other on policy, compliance and risk management  ","date":1424980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1424980800,"objectID":"f24df8711ae07cbfd6636ea351239a93","permalink":"https://binarymist.io/talk/owaspnzday-2015/","publishdate":"2015-02-27T09:00:00+13:00","relpermalink":"/talk/owaspnzday-2015/","section":"talk","summary":"The sixth OWASP New Zealand Day conference, held at the University of Auckland.\n","tags":["conference","cloud-security","cybersecurity","information-security","owasp","owasp-nz-day","infosec","security","web-application-security","web-security"],"title":"Conference - OWASP New Zealand Day","type":"talk"},{"authors":null,"categories":null,"content":"  GnuPG Key-Pair with Sub-Keys  \n","date":1422615600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422615600,"objectID":"46690a082ae44190c5a2c1e830867e36","permalink":"https://binarymist.io/blog/2015/01/31/gnupg-key-pair-with-sub-keys/","publishdate":"2015-01-31T00:00:00+13:00","relpermalink":"/blog/2015/01/31/gnupg-key-pair-with-sub-keys/","section":"post","summary":"Redirects to legacy blog post.\n\nThere are quite a few other posts on this topic, but my set-up hasn’t been exactly the same as any I found, so I found myself using quite a few resources to achieve exactly what I wanted.\n","tags":["encryption","crypto","gpg","security","pgp"],"title":"GnuPG Key-Pair with Sub-Keys","type":"post"},{"authors":null,"categories":null,"content":"  Installation and Hardening of Debian Web Server  \n","date":1419591600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1419591600,"objectID":"3fcdc90f52423c1fbb20537d6b4a8c84","permalink":"https://binarymist.io/blog/2014/12/27/installation-and-hardening-of-debian-web-server/","publishdate":"2014-12-27T00:00:00+13:00","relpermalink":"/blog/2014/12/27/installation-and-hardening-of-debian-web-server/","section":"post","summary":"Redirects to legacy blog post. These are the steps I took to set-up and harden a Debian web server before being placed into a DMZ and undergoing additional hardening before opening the port from the WWW to it. Most of the steps below are fairly simple to do, and in doing so, remove a good portion of the low hanging fruit for nasty entities wanting to gain a foot-hold on your server-network. ","tags":["backups","cloud","debian","dev-ops","dmz","esxi","exim","fire-wall","ftp","gnu-linux","hids","hips","ids","ips","linux","mta","networking","nids","nips","nmap","security","ssh","blowfish","crypto","cryptography","telnet","virtualisation","waf"],"title":"Installation and Hardening of Debian Web Server","type":"post"},{"authors":null,"categories":null,"content":" Principal Recruitment Consultant, Platinum Recruitment Ltd\n We engaged Kim to take the technical reigns on a large client project.\nKim was on point right from day one, diving head first into the work and committing himself to project delivery. Technically, Kim is very sharp with a good head for commercial software development. If there’s something strange in your development project, forget the Ghostbusters and give Kim Carter a call.\nCouldn’t recommended him highly enough.\n","date":1417478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417478400,"objectID":"05c6ef4b65e3ab03217775333e81fcf1","permalink":"https://binarymist.io/project/testimonial-david-gadsby/","publishdate":"2014-12-02T00:00:00Z","relpermalink":"/project/testimonial-david-gadsby/","section":"project","summary":"Platinum Recruitment Ltd","tags":["testimonial"],"title":"David Gadsby","type":"project"},{"authors":null,"categories":null,"content":" Personal Internet Banking\n    Successfully brought the development of Personal Online-Banking in-house. Assisted in recruiting and mentoring managers and a development team to take over PIB. Created road map for ongoing architecture and development. Restructured and worked on new features. Ongoing reviews and security status reports with proposed solutions. Full evaluation of web module loaders. Replacing RequireJS with WebPack to utilise all module systems available (ES6 modules, globals, AMD, CommonJS).    Replacing BackboneJS views and templates with React/Flux components and jsx. Evaluated CSS pre-processors again.\nCommon Technologies:\n JavaScript, HandlebarsJS, gulp.js, AMD and CommonJS, NodeJS, LESS, React with Flux Mocha, SinonJS, C#.NET Git, gitbash WebStorm, VisualStudio  See testimonials by David Gadsby, Lana Winders and Rachel Robertson\n","date":1417392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417392000,"objectID":"2832297e87d94a3ac73fa21c04f4c529","permalink":"https://binarymist.io/project/portfolio-sbs/","publishdate":"2014-12-01T00:00:00Z","relpermalink":"/project/portfolio-sbs/","section":"project","summary":"Personal Internet Banking","tags":["portfolio","architecture-engineering-portfolio","security-portfolio"],"title":"SBS Bank","type":"project"},{"authors":null,"categories":null,"content":"There are many ways to lift software developers’ productivity and, as a result, the development team’s total output. This session addresses some quick wins, as well as some that take longer to implement.\nThis talk was based around ideas from the following blog post\n How to Increase Software Developer Productivity\n Also discussed in depth in Kims book series.\n ","date":1409803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409803200,"objectID":"8d882d6843c0fd66eca2b810258a72e4","permalink":"https://binarymist.io/talk/agilenz-2014-talk-how-to-increase-software-developer-productivity/","publishdate":"2014-09-04T16:00:00+12:00","relpermalink":"/talk/agilenz-2014-talk-how-to-increase-software-developer-productivity/","section":"talk","summary":"At AgileNZ: Are you looking to get more out of your organisation’s software developers, increase your ROI, spend less money on fixing bugs or increase your development team’s business value and release rate? If so, this session is for you.\n","tags":["talk"],"title":"Talk - How to Increase Software Developer Productivity","type":"talk"},{"authors":null,"categories":null,"content":"  Node.js Asynchronicity and Callback Nesting  \n","date":1406289600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1406289600,"objectID":"3769eeda3893c7578d4719c9ed97751b","permalink":"https://binarymist.io/blog/2014/07/26/node.js-asynchronicity-and-callback-nesting/","publishdate":"2014-07-26T00:00:00+12:00","relpermalink":"/blog/2014/07/26/node.js-asynchronicity-and-callback-nesting/","section":"post","summary":"Redirects to legacy blog post.\n\nAKA callback hell, temple of doom, often the functions that are nested are anonymous and often they are implicit closures. When it comes to asynchronicity in JavaScript, callbacks are our bread and butter. In saying that, often the best way to use them is by abstracting them behind more elegant APIs.\n","tags":["async","asyncjs","asynchronicity","callback","callback-nesting","deep-callback-nesting","ecma-script","ecma-script-5","ecma-script-6","es5","es6","event-emitter","javascript","module","nodejs","promise","promises-a+","prototype","web","web-application","recursion","npm","amd","requirejs","commonjs","mocha","tdd"],"title":"Node.js Asynchronicity and Callback Nesting","type":"post"},{"authors":null,"categories":null,"content":"  Exploring JavaScript Prototypes  \n","date":1403870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1403870400,"objectID":"05888f20b08ef0a65aeb8172b5b99ae7","permalink":"https://binarymist.io/blog/2014/06/28/exploring-javascript-prototypes/","publishdate":"2014-06-28T00:00:00+12:00","relpermalink":"/blog/2014/06/28/exploring-javascript-prototypes/","section":"post","summary":"Redirects to legacy blog post.\n\nMy intention with this post is to arm our developers with enough information around JavaScript prototypes to know when they are the right tool for the job as opposed to other constructs when considering how to create polymorphic JavaScript that’s performant and easy to maintain.\n","tags":["aggregation","composition","dry","ecma-script","ecma-script-3","ecma-script-5","ecma-script-6","es3","es5","es6","garbage-collection","gc","inheritance","javascript","polymorphism","prototypal-inheritance","prototype"],"title":"Exploring JavaScript Prototypes","type":"post"},{"authors":null,"categories":null,"content":"  Exploring JavaScript Closures  \n","date":1401451200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1401451200,"objectID":"f8c95c0d7096a9abbf5ab0d56e5332ca","permalink":"https://binarymist.io/blog/2014/05/31/exploring-javascript-closures/","publishdate":"2014-05-31T00:00:00+12:00","relpermalink":"/blog/2014/05/31/exploring-javascript-closures/","section":"post","summary":"Redirects to legacy blog post.\n\nNow establishing the formal definition has been quite an interesting journey, with quite a few sources not quite getting it right. Although the ES3 spec talks about closure, there is no formal definition of what it actually is. The ES5 spec on the other hand does discuss what closure is in two distinct locations.\n","tags":["closure","ecma-script","ecma-script-3","ecma-script-5","ecma-script-6","es3","es5","es6","functional-programming","garbage-collection","gc","javascript","web","web-application","module","information-hiding","encapsulation","partial-function-application","currying"],"title":"Exploring JavaScript Closures","type":"post"},{"authors":null,"categories":null,"content":" Owner/Managing Director, Solvam Corporation Ltd\n Kim Carter was engaged on a contract basis to implement and guide our future software development for School-links. www.school-links.co.nz\nIn doing that he -\n Brought to our product a much higher level of expertise and capability complementing our development team Directed a disciplined and methodical software development process as the Scrum Master of ‘Scrum’ Helped with the restructuring and planning of our infrastructure in order to scale the product successfully Brings security expertise at a high level with the ability to implement ongoing security hardening program and audits Introduced the Scrum process which provided more consistent and accurate release cycles enabling our marketing efforts to be better coordinated and focused  Kim is a good team member and we will look to reengage with his services when required.\n","date":1397606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397606400,"objectID":"4fc3332dc8424ad9fc362876913686bf","permalink":"https://binarymist.io/project/testimonial-andrew-balfour/","publishdate":"2014-04-16T00:00:00Z","relpermalink":"/project/testimonial-andrew-balfour/","section":"project","summary":"Solvam Corporation Ltd","tags":["testimonial"],"title":"Andrew Balfour","type":"project"},{"authors":null,"categories":null,"content":" Process Improvement. Back End Re-Architect\n    Architected and re-factored school-links, a PHP messaging system into NodeJS. Security reviews - hardening of applications and infrastructure (multi platform environment). Linux System administration and DevOps. Mentoring, setting up and mastering another Scrum Team. Re-factored enterprise LAMP application to full stack modular JavaScript enterprise application. Jenkins evaluation. Set-up coding standards, conventions and guidelines.    Common Technologies:\n Sails, Waterline, Sequelize ORM, OAuth, Google and Apple messaging NodeJS, Mocha, SinonJS, JSHint, Git, pdepend AMQP (RabbitMQ), supervisord, DNode, Redis Eclipse, Sublime Text, Bash and friends  See testimonial by Andrew Balfour\n","date":1396310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396310400,"objectID":"a48f78c8ca47100470aebdbc6f0f346c","permalink":"https://binarymist.io/project/portfolio-schoollinks/","publishdate":"2014-04-01T00:00:00Z","relpermalink":"/project/portfolio-schoollinks/","section":"project","summary":"Process Improvement. Back End Re-Architect","tags":["portfolio","architecture-engineering-portfolio","devops-portfolio","security-portfolio"],"title":"School-Links","type":"project"},{"authors":null,"categories":null,"content":"  Up and Running with Kali Linux and Friends  \n","date":1396004400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396004400,"objectID":"c0b14ff6062dc2992cbf5c86346c1ae7","permalink":"https://binarymist.io/blog/2014/03/29/up-and-running-with-kali-linux-and-friends/","publishdate":"2014-03-29T00:00:00+13:00","relpermalink":"/blog/2014/03/29/up-and-running-with-kali-linux-and-friends/","section":"post","summary":"Redirects to legacy blog post.\n\nIn this article I’ll go over getting Kali Linux installed and set-up. I’ll go over a few of the packages in a low level of detail (due to the share number of them) that come out of the box. On top of that I’ll also go over a few programmes I like to install separately. In a subsequent article I’d like to continue with additional programmes that come with Kali Linux as there are just to many to cover in one go.\n","tags":["infosec","kali-linux","kali","nmap","owasp","security","xss","hacking","zap","burp-suite","metasploit","sql-injection","sanitisation"],"title":"Up and Running with Kali Linux and Friends","type":"post"},{"authors":null,"categories":null,"content":"  Automating Specification by Example for .NET Web Applications  \n","date":1392980400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1392980400,"objectID":"bc7b5fa5845af3e25bfae1c068ce6d0a","permalink":"https://binarymist.io/blog/2014/02/22/automating-specification-by-example-for-.net-web-applications/","publishdate":"2014-02-22T00:00:00+13:00","relpermalink":"/blog/2014/02/22/automating-specification-by-example-for-.net-web-applications/","section":"post","summary":"Redirects to legacy blog post.\n\nIt’s my intention that the following details will help you create a system that automates “Specification by Example”.\n","tags":["dot-net","atdd","bdd","tdd","ci","continuous-integration","jenkins","machine.specification","mspec","nightly-build","nspec","dev-ops","performance","power-shell","ps","psake","selenium","specflow","specification-by-example","xbehave","xspec","operational-efficiencies","deployment"],"title":"Automating Specification by Example for .NET Web Applications","type":"post"},{"authors":null,"categories":null,"content":"  Essentials for Creating and Maintaining a High Performance Development Team  \n","date":1390561200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390561200,"objectID":"aa166503cb0c677956403aa180c12c0e","permalink":"https://binarymist.io/blog/2014/01/25/essentials-for-creating-and-maintaining-a-high-performance-development-team/","publishdate":"2014-01-25T00:00:00+13:00","relpermalink":"/blog/2014/01/25/essentials-for-creating-and-maintaining-a-high-performance-development-team/","section":"post","summary":"Redirects to legacy blog post.\n\nWhat I see a lot of, is organisations hiring code monkeys rather than professionals.\n","tags":["operational-efficiencies","performance","scrum"],"title":"Essentials for Creating and Maintaining a High Performance Development Team","type":"post"},{"authors":null,"categories":null,"content":"","date":1390456800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1390456800,"objectID":"6b701985d1893fca8b9fd53c94d34344","permalink":"https://binarymist.io/talk/chcjs-meetup-2014-workshop-writing-an-ember-js-application/","publishdate":"2014-01-23T19:00:00+13:00","relpermalink":"/talk/chcjs-meetup-2014-workshop-writing-an-ember-js-application/","section":"talk","summary":"At CHC.js Kim will demonstrate write a blogging platform in JavaScript using Ember.js. The application had the functionality to display, edit and navigate blog posts written in markdown in about 35 lines of JavaScript on top of the handlebars templates.\n","tags":["workshop","javascript","web-application"],"title":"Workshop - Writing an Ember.JS Application","type":"talk"},{"authors":null,"categories":null,"content":"  Evaluation of AngularJS, EmberJS, BackboneJS + MarionetteJS  \n","date":1388142000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388142000,"objectID":"22dfa4b6e70689891200fa4d949d07eb","permalink":"https://binarymist.io/blog/2013/12/28/evaluation-of-angularjs-emberjs-backbonejs-marionettejs/","publishdate":"2013-12-28T00:00:00+13:00","relpermalink":"/blog/2013/12/28/evaluation-of-angularjs-emberjs-backbonejs-marionettejs/","section":"post","summary":"Redirects to legacy blog post.\n\nRecently I’ve undertaken the task of reviewing some JavaScript MV* frameworks to help organise/structure the client side code within an application I’m currently working on. This is about the third time I’ve done this. Each time has been for a different type of application with completely different requirements, frameworks and libraries to consider. Unlike Angular and Ember, Backbone is a small library. Marionette adds quite a lot of extra functionality and provides some nice abstractions on top . All mentioned frameworks/libraries are free and open source.\n","tags":["amd","angular","ember","backbone","bootstrap","commonjs","ecma-script","handlebars","javascript","marionette","module","mvc","mvp","requirejs","underscore"],"title":"Evaluation of AngularJS, EmberJS, BackboneJS + MarionetteJS","type":"post"},{"authors":null,"categories":null,"content":"  Evaluation of .Net Mocking libraries  \n","date":1386932400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1386932400,"objectID":"7c0dfc71e87b1a45e2ae8b5fe6df866e","permalink":"https://binarymist.io/blog/2013/12/14/evaluation-of-dot-net-mocking-libraries/","publishdate":"2013-12-14T00:00:00+13:00","relpermalink":"/blog/2013/12/14/evaluation-of-dot-net-mocking-libraries/","section":"post","summary":"Redirects to legacy blog post.\n\nI’ve recently undertaken another round of evaluating .NET mocking (fake/substitute/dummy/stub/ or what ever you want to call them now) libraries. Interestingly the landscape has changed quite a bit since last time I went through this exercise, which was about two years ago. The outcome of the previous investigation is at the bottom of this post.\n","tags":["dot-net","dummy","fake","fakeiteasy","faking","free-and-open-source","justmock","mock","mocking","moq","nmock","nsubstitute","rhino-mocks","stub","stubbing","substitute"],"title":"Evaluation of dot Net Mocking libraries","type":"post"},{"authors":null,"categories":null,"content":" Architectural Consulting and Development\n    Provided Architectural and Development guidance to the:\n Development Manager Development Lead Development Team  Mentoring all.    ","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"9649b3b6d9d53d1bc8d5188f004ed0f8","permalink":"https://binarymist.io/project/portfolio-hindinsolutions/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/project/portfolio-hindinsolutions/","section":"project","summary":"Architectural Consulting \u0026#38; Development","tags":["portfolio","architecture-engineering-portfolio"],"title":"Hindin Solutions","type":"project"},{"authors":null,"categories":null,"content":" Architectural Consulting\n    Provided architectural guidance specifically around JavaScript framework decisions to the development lead.    ","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"0ac5bd778ff9449143a0690361cd25f4","permalink":"https://binarymist.io/project/portfolio-pivotsoftware/","publishdate":"2013-12-01T00:00:00Z","relpermalink":"/project/portfolio-pivotsoftware/","section":"project","summary":"Architectural Consulting","tags":["portfolio","architecture-engineering-portfolio"],"title":"Pivot Software","type":"project"},{"authors":null,"categories":null,"content":"  Up and Running with Sass (scss) and Less in Visual Studio  \n","date":1385377200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385377200,"objectID":"7b82ad423a6fe5e0d5bb9d0b353f64b8","permalink":"https://binarymist.io/blog/2013/11/26/up-and-running-with-sass-scss-and-less-in-visual-studio/","publishdate":"2013-11-26T00:00:00+13:00","relpermalink":"/blog/2013/11/26/up-and-running-with-sass-scss-and-less-in-visual-studio/","section":"post","summary":"Redirects to legacy blog post.\n\nI recently evaluated the support for the top two CSS preprocessors (Sass and Less) for the environment my client team and myself are currently constrained to (Visual Studio 2012).\n","tags":["css","jshint","less","preprocessor","sass","scss","visual-studio"],"title":"Up and Running with Sass (scss) and Less in Visual Studio","type":"post"},{"authors":null,"categories":null,"content":"We have a vast collection of libraries, techniques, cheat sheets, tutorials, guides and tools at our disposal. I often find myself thinking… how can we commoditise the sanitisation of user input and I keep coming up with the same answer. It’s not easy. Every application has a completely different set of concerns.\nIn order for our software to be shielded from an attack, the builders must think like attackers.\nIn this talk I’ll attempt to:\n Increase our knowledge and awareness Discuss practical techniques and approaches that increase our defences Break some software   ","date":1378936200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1378936200,"objectID":"01f8dd6ef6f5122e7d7f09310c9f0302","permalink":"https://binarymist.io/talk/owaspnzday-2013-talk-whats-our-software-doing-with-all-that-user-input/","publishdate":"2013-09-12T09:50:00+12:00","relpermalink":"/talk/owaspnzday-2013-talk-whats-our-software-doing-with-all-that-user-input/","section":"talk","summary":"At OWASP NZ Day: What are we doing with all the characters that get shoved into our applications? Have we considered every potential execution context?\n","tags":["talk","application-security","csrf","cybersecurity","filtering","information-security","infosec","owasp-nz-day","owasp-top-10","owasp-zap","sanitisation","security","software-security","validation","web","web-application","web-application-security","web-security","xss","zap"],"title":"Talk - What's Our Software Doing With All That User Input","type":"talk"},{"authors":["Kim Carter"],"categories":null,"content":"","date":1377993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377993600,"objectID":"b7986f950f12924f013c0c086de577c4","permalink":"https://binarymist.io/publication/pentest-magazine-kali-linux-review/","publishdate":"2013-09-01T00:00:00Z","relpermalink":"/publication/pentest-magazine-kali-linux-review/","section":"publication","summary":"PenTest Magazine article by Kim.\n","tags":["publication","cybersecurity","security","information-security","infosec","kali","kali-linux","metasploit","nmap","owasp","owasp-top-10","owasp-zap","security","xss","zap"],"title":"Kali Linux Review","type":"publication"},{"authors":null,"categories":null,"content":" ","date":1377495000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1377495000,"objectID":"d7ed56d799a3dc41ebfdc2cbc0f40ab8","permalink":"https://binarymist.io/talk/anztb-2013-workshop-security-testing-with-kim-carter/","publishdate":"2013-08-26T17:30:00+12:00","relpermalink":"/talk/anztb-2013-workshop-security-testing-with-kim-carter/","section":"talk","summary":"At ANZTB: Hands-on insight into security testing. Kim will discuss some of the more common security vulnerabilities being found in today’s software implementations, and will demonstrate ways of testing them.\n","tags":["talk","application-security","csrf","cybersecurity","filtering","information-security","infosec","owasp-nz-day","owasp-top-10","owasp-zap","sanitisation","security","software-security","validation","web","web-application","web-application-security","web-security","xss","zap"],"title":"Workshop - Security Testing with Kim Carter","type":"talk"},{"authors":null,"categories":null,"content":" Security Assessment\n    Provided Security Assessment following a responsible disclosure.\n Liaised with trusties and vendors Provided education and mentoring     ","date":1375315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1375315200,"objectID":"0c539d3cdda8c98589b9fe4e1774cb8f","permalink":"https://binarymist.io/project/portfolio-kingschurch/","publishdate":"2013-08-01T00:00:00Z","relpermalink":"/project/portfolio-kingschurch/","section":"project","summary":"Security Assessment","tags":["portfolio","security-portfolio"],"title":"King's Church","type":"project"},{"authors":null,"categories":null,"content":"  Up and Running with Express on Node.js … and friends  \n","date":1374840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1374840000,"objectID":"7abd4c2f6b39ad23bba1df0a8706c311","permalink":"https://binarymist.io/blog/2013/07/27/up-and-running-with-express-on-node.js-and-friends/","publishdate":"2013-07-27T00:00:00+12:00","relpermalink":"/blog/2013/07/27/up-and-running-with-express-on-node.js-and-friends/","section":"post","summary":"Redirects to legacy blog post.\n\nThis is a result of a lot of trial and error, reading, notes taken, advice from more knowledgeable people than myself over a period of a few months in my spare time. This is the basis of a web site I’m writing for a new business endeavour.\n","tags":["bootstrap","css","css3","express","jade","less","nodejs","nodemon","responsive-design","less","stylus","sass","npm"],"title":"Up and Running with Express on Node.js, and friends","type":"post"},{"authors":null,"categories":null,"content":"  JavaScript Object Creation Patterns  \n","date":1373025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1373025600,"objectID":"770ae6662c1ccfe0fdae80be8ec964b7","permalink":"https://binarymist.io/blog/2013/07/06/javascript-object-creation-patterns/","publishdate":"2013-07-06T00:00:00+12:00","relpermalink":"/blog/2013/07/06/javascript-object-creation-patterns/","section":"post","summary":"Redirects to legacy blog post.\n\nWhat are the differences in creating an object by way of simple function invocation, vs using a constructor vs creating an object using the object literal notation vs function application?\n","tags":["ecma-script","ecma-script-3","ecma-script-5","es3","es5","javascript","prototypal-inheritance","prototype","performance","design-patern"],"title":"JavaScript Object Creation Patterns","type":"post"},{"authors":null,"categories":null,"content":"  Reassembly of the Eee PC 901  \n","date":1370606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1370606400,"objectID":"f67669cf7cf17fe0af8eabe0c05b7c59","permalink":"https://binarymist.io/blog/2013/06/08/reassembly-of-the-eee-pc-901/","publishdate":"2013-06-08T00:00:00+12:00","relpermalink":"/blog/2013/06/08/reassembly-of-the-eee-pc-901/","section":"post","summary":"Redirects to legacy blog post.\n\nThis is a follow on from “Upgrade Linux Eee PC 901 4GB SSD“\n\nAs usual, this is just the previous section but in reverse. Hopefully you won’t have any screws left when it’s back together.\n","tags":["hardware"],"title":"Reassembly of the Eee PC 901","type":"post"},{"authors":null,"categories":null,"content":" Integration Development\n    Integrated some of our cities public organisations into the Christchurch City Council's work flow. Liaising with Architects, development teams from CCC, City Care and others to achieve the optimum result.\nMentoring all involved.\nCommon Technologies: C#, WCF    See testimonials by Ming Yii and Engela Pretorius\n","date":1370044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1370044800,"objectID":"eb67aeb075c7731d1e2c0beca9ef2157","permalink":"https://binarymist.io/project/portfolio-ccc/","publishdate":"2013-06-01T00:00:00Z","relpermalink":"/project/portfolio-ccc/","section":"project","summary":"Integration Development","tags":["portfolio","architecture-engineering-portfolio"],"title":"Christchurch City Council","type":"project"},{"authors":null,"categories":null,"content":"  Upgrade Linux Eee PC 901 4GB SSD  \n","date":1369396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1369396800,"objectID":"b724309ebae784f63f195c38c3116441","permalink":"https://binarymist.io/blog/2013/05/25/upgrade-linux-eee-pc-901-4gb-ssd/","publishdate":"2013-05-25T00:00:00+12:00","relpermalink":"/blog/2013/05/25/upgrade-linux-eee-pc-901-4gb-ssd/","section":"post","summary":"Redirects to legacy blog post.\n","tags":["hardware"],"title":"Upgrade Linux Eee PC 901 4GB SSD","type":"post"},{"authors":null,"categories":null,"content":"  Software Engineer Interview Quick Question Set  \n","date":1368187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1368187200,"objectID":"abc932ae397328790ca1bf35a073c1fc","permalink":"https://binarymist.io/blog/2013/05/11/software-engineer-interview-quick-question-set/","publishdate":"2013-05-11T00:00:00+12:00","relpermalink":"/blog/2013/05/11/software-engineer-interview-quick-question-set/","section":"post","summary":"Redirects to legacy blog post.\n","tags":["agile","architecture","concurrency","c-sharp","design-pattern","dot-net","dry","garbage-collection","gc","inheritance","javascript","parallelisation","polymorphism","scrum","sdlc","solid","sql-injection","testing","wcf","web","xss"],"title":"Software Engineer Interview Quick Question Set","type":"post"},{"authors":null,"categories":null,"content":"  Software Engineer Interview Process and Questions  \n","date":1366977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1366977600,"objectID":"598842b68e060816d59a32014de5daa5","permalink":"https://binarymist.io/blog/2013/04/27/software-engineer-interview-process-and-questions/","publishdate":"2013-04-27T00:00:00+12:00","relpermalink":"/blog/2013/04/27/software-engineer-interview-process-and-questions/","section":"post","summary":"Redirects to legacy blog post.\n\nA short time ago, I was tasked with finding the right software engineer/s for the organisation I was working for. I settled on a process, a set of background questions,  a set of practical programming exercises and a set of verbal questions. Later on I cut the set of verbal questions down to a quicker set. In this post, I’ll be going over the process and the full set of verbal questions. In a subsequent post I’ll go over the quicker set.\n","tags":["agile","algorithm","architecture","bdd","ci","concurrency","csrf","c-sharp","design-pattern","dot-net","dry","dummy","fake","garbage-collection","gc","inheritance","ioc","javascript","parallelisation","mock","mvc","mvp","polymorphism","scrum","sdlc","solid","testing","tdd","wcf","web","windows","xss"],"title":"Software Engineer Interview Process and Questions","type":"post"},{"authors":null,"categories":null,"content":"  Running Wireshark as non-root user  \n","date":1365768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1365768000,"objectID":"0da96ccceb6df1c706266fe4cba745e6","permalink":"https://binarymist.io/blog/2013/04/13/running-wireshark-as-non-root-user/","publishdate":"2013-04-13T00:00:00+12:00","relpermalink":"/blog/2013/04/13/running-wireshark-as-non-root-user/","section":"post","summary":"Redirects to legacy blog post.\n\nThis post is targeted at getting Wireshark running on Linux. If you’re a windows user, you can check out the Windows notes here.\n","tags":["capabilities","control-groups","infosec","networking","network-security","security","wireshark"],"title":"Running Wireshark as non-root user","type":"post"},{"authors":null,"categories":null,"content":" System Analyst, Christchurch City Council\n Kim has an excellent work ethic and always keeps the bigger picture in mind.\nHis recommendations added value to the final solution.\nAppreciated his diligence to unravel a difficult process and make it work.\n","date":1365379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1365379200,"objectID":"f14464e7319c390475a62aa41a4728d5","permalink":"https://binarymist.io/project/testimonial-engela-pretorius/","publishdate":"2013-04-08T00:00:00Z","relpermalink":"/project/testimonial-engela-pretorius/","section":"project","summary":"Christchurch City Council","tags":["testimonial"],"title":"Engela Pretorius","type":"project"},{"authors":null,"categories":null,"content":" Team Leader, Software Engineering Team, Christchurch City Council\n 2 words to describe Kim – mystery \u0026#38; legend.\nMystery – Kim is deep \u0026#38; smart. He sees things differently, from several angles \u0026#38; is full of ideas. You never know what he will suggest, and will be surprised with how he tackles issues with the solutions that he has.\nLegend – Throw anything to him, no matter how twisted and broken they are, and Kim will sort them out, with\nquality. He is keen to improve things \u0026#38; build people up technically. Sorry I lied, there’s a 3rd one.\nPassion – The silent driver in Kim. Self-motivated, self-organised \u0026#38; a wonderful team player. Kim would do everything he could in order to achieve. I’ll want him in my team any day!\n","date":1365379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1365379200,"objectID":"c9f040a81662bde89b44a9d7bb5b7955","permalink":"https://binarymist.io/project/testimonial-ming-yii/","publishdate":"2013-04-08T00:00:00Z","relpermalink":"/project/testimonial-ming-yii/","section":"project","summary":"Christchurch City Council","tags":["testimonial"],"title":"Ming Yii","type":"project"},{"authors":null,"categories":null,"content":"  Setup of Chromium, Burp Suite, Node.js to view HTTP on the wire  \n","date":1364554800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364554800,"objectID":"7e7a902bc8a5e2fc8b1110224f0360c5","permalink":"https://binarymist.io/blog/2013/03/30/setup-of-chromium-burp-suite-node.js-to-view-http-on-the-wire/","publishdate":"2013-03-30T00:00:00+13:00","relpermalink":"/blog/2013/03/30/setup-of-chromium-burp-suite-node.js-to-view-http-on-the-wire/","section":"post","summary":"Redirects to legacy blog post.\n\nAs part of my Node.js development I really wanted to see what was going over the wire from chromium-browser to my Node.js web apps.\n","tags":["nodejs","burp-suite","networking","web"],"title":"Setup of Chromium, Burp Suite, Node.js to view HTTP on the wire","type":"post"},{"authors":null,"categories":null,"content":"  Erasing data from your drives  \n","date":1363431600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1363431600,"objectID":"63c0b8a33cd0f70d010c2823b2dcbbca","permalink":"https://binarymist.io/blog/2013/03/17/erasing-data-from-your-drives/","publishdate":"2013-03-17T00:00:00+13:00","relpermalink":"/blog/2013/03/17/erasing-data-from-your-drives/","section":"post","summary":"Redirects to legacy blog post.\n\nIn this post Kim discusses some tools and techniques to use when preparing your drives for decommissioning.\n","tags":["dd","ubcd"],"title":"Erasing data from your drives","type":"post"},{"authors":null,"categories":null,"content":" ","date":1362463200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362463200,"objectID":"0394652dfb5416c227a2de2ef17a0600","permalink":"https://binarymist.io/talk/canterburysoftwarecluster-2013-talk-moving-to-test-and-behaviour-driven-development/","publishdate":"2013-03-05T19:00:00+13:00","relpermalink":"/talk/canterburysoftwarecluster-2013-talk-moving-to-test-and-behaviour-driven-development/","section":"talk","summary":"At Canterbury Software Cluster: In this session Kim went over the benefits of introducing TDD and BDD: How to introduce them, their differences, how to deal with push back from team members and upper management.\n","tags":["talk","atdd","development-methodologies","gherkin","mock","mocking","moq","nightly-build","operational-efficiencies","rhino-mocks","specflow","specification-by-example","tdd","test","testing","test-conditions"],"title":"Talk - Moving to test and behaviour-driven development","type":"talk"},{"authors":null,"categories":null,"content":"  How to Increase Software Developer Productivity  \n","date":1362135600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362135600,"objectID":"e835430edfa54a2774912ea6e617ca14","permalink":"https://binarymist.io/blog/2013/03/02/how-to-increase-software-developer-productivity/","publishdate":"2013-03-02T00:00:00+13:00","relpermalink":"/blog/2013/03/02/how-to-increase-software-developer-productivity/","section":"post","summary":"Redirects to legacy blog post.\n\nIs your organisation:\n\n* Wanting to get more out of your Software Developers?\n* Wanting to increase RoI?\n* Spending too much money fixing bugs?\n* Development team not releasing business value fast enough?\n* Maybe your a software developer and you want to lift your game to the next level?\n\nIf any of these points are of concern to you… read on.\n","tags":["ci","continuous-integration","code-review","coding-standards","continuous-deployment","definition-of-done","development-methodologies","operational-efficiencies","retrospective","tdd"],"title":"How to Increase Software Developer Productivity","type":"post"},{"authors":null,"categories":null,"content":"  Establishing your SSH Server’s Key Fingerprint  \n","date":1360926000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1360926000,"objectID":"eaa00140329ba9e573e4bdd8ca53bb4a","permalink":"https://binarymist.io/blog/2013/02/16/establishing-your-ssh-servers-key-fingerprint/","publishdate":"2013-02-16T00:00:00+13:00","relpermalink":"/blog/2013/02/16/establishing-your-ssh-servers-key-fingerprint/","section":"post","summary":"Redirects to legacy blog post.\n\nWhen you connect to a remote host via SSH that you haven’t established a trust relationship with before, you’re going to be told that the authenticity of the host your attempting to connect to can’t be established.\n","tags":["linux","md5","security","ssh"],"title":"Establishing your SSH Server’s Key Fingerprint","type":"post"},{"authors":null,"categories":null,"content":"  A Decent Console for Windows  \n","date":1358506800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1358506800,"objectID":"beeeb8c562c56e1f38f648f94254051c","permalink":"https://binarymist.io/blog/2013/01/19/a-decent-console-for-windows/","publishdate":"2013-01-19T00:00:00+13:00","relpermalink":"/blog/2013/01/19/a-decent-console-for-windows/","section":"post","summary":"Redirects to legacy blog post.\n\nOn *nix we’re kind of spoilt when it comes to the CLI experience. The console I use most in a GUI environment is the great terminator.\n","tags":["linux","gnu-linux","windows","terminal"],"title":"A Decent Console for Windows","type":"post"},{"authors":null,"categories":null,"content":"  Generic Coding Standards and Guidelines  \n","date":1357297200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1357297200,"objectID":"3743ca9a187e7c708aeb6618457f3db8","permalink":"https://binarymist.io/blog/2013/01/05/generic-coding-standards-and-guidelines/","publishdate":"2013-01-05T00:00:00+13:00","relpermalink":"/blog/2013/01/05/generic-coding-standards-and-guidelines/","section":"post","summary":"Redirects to legacy blog post.\n\nWhen programming in a mixed-language environment, the naming conventions, formatting conventions, documentation conventions, and other conventions, can be optimised for overall consistency and readability. This may mean going against convention for one or more of the languages that’s part of the mix.\n","tags":["coding-standards"],"title":"Generic Coding Standards and Guidelines","type":"post"},{"authors":null,"categories":null,"content":"  JavaScript Coding Standards and Guidelines  \n","date":1355828400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1355828400,"objectID":"6fd0dc4f97a8edd4a546c0d24bb5e198","permalink":"https://binarymist.io/blog/2012/12/19/javascript-coding-standards-and-guidelines/","publishdate":"2012-12-19T00:00:00+13:00","relpermalink":"/blog/2012/12/19/javascript-coding-standards-and-guidelines/","section":"post","summary":"Redirects to legacy blog post.\n\nThis is the current set of coding standards and guidelines I use when I’m coding in the JavaScript language. I thought it would be good to share so others could get use out of them also, and maybe start a discussion as to amendments / changes they see that could be useful?\n","tags":["coding-standards","design-pattern","inheritance","javascript","prototypal-inheritance"],"title":"JavaScript Coding Standards and Guidelines","type":"post"},{"authors":null,"categories":null,"content":"  Moving to TDD  \n","date":1354273200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1354273200,"objectID":"0968f55046d5b93bdcfee26f04f65d88","permalink":"https://binarymist.io/blog/2012/12/01/moving-to-tdd/","publishdate":"2012-12-01T00:00:00+13:00","relpermalink":"/blog/2012/12/01/moving-to-tdd/","section":"post","summary":"Redirects to legacy blog post.\n\nThe first thing to clear up is that TDD is not primarily about testing, but rather it forces the developer to write code that is testable (the fact the code has tests written for it and running regularly is a side effect, albeit a very positive one).\n","tags":["architecture","atdd","bdd","fake","faking","ioc","mock","mocking","operational-efficiencies","polymorphism","solid","tdd"],"title":"Moving to TDD","type":"post"},{"authors":null,"categories":null,"content":"  Sanitising User Input from Browser. part 2  \n","date":1352977200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1352977200,"objectID":"a1eaf7ff99ac5da4628d8a0a3b720aed","permalink":"https://binarymist.io/blog/2012/11/16/sanitising-user-input-from-browser-part-2/","publishdate":"2012-11-16T00:00:00+13:00","relpermalink":"/blog/2012/11/16/sanitising-user-input-from-browser-part-2/","section":"post","summary":"Redirects to legacy blog post.\n\nUntrusted data (data entered by a user), should always be treated as though it contains attack code. This data should not be sent anywhere without taking the necessary steps to detect and neutralise the malicious code.\n","tags":["cybersecurity","c-sharp","dot-net","filtering","information-security","infosec","owasp","sanitisation","security","software-security","validation","wcf","web","web-application","web-application-security","web-security","xss"],"title":"Sanitising User Input from Browser part 2","type":"post"},{"authors":null,"categories":null,"content":"  Sanitising User Input from Browser. part 1  \n","date":1351940400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1351940400,"objectID":"02a2e87cbebd733c659910363374c97e","permalink":"https://binarymist.io/blog/2012/11/04/sanitising-user-input-from-browser-part-1/","publishdate":"2012-11-04T00:00:00+13:00","relpermalink":"/blog/2012/11/04/sanitising-user-input-from-browser-part-1/","section":"post","summary":"Redirects to legacy blog post.\n\nI was working on a web based project recently where there was no security thought about when designing, developing it. The following outlines my experience with retrofitting security. It’s my hope that someone will find it useful for their own implementation.\n","tags":["cybersecurity","information-security","infosec","javascript","owasp-top-10","sanitisation","security","software-security","validation","web","web-application","web-application-security","web-security","xss"],"title":"Sanitising User Input from Browser part 1","type":"post"},{"authors":null,"categories":null,"content":"  JavaScript Properties  \n","date":1349089200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1349089200,"objectID":"4a691bdf924478967dcd02d02520dbe6","permalink":"https://binarymist.io/blog/2012/10/02/javascript-properties/","publishdate":"2012-10-02T00:00:00+13:00","relpermalink":"/blog/2012/10/02/javascript-properties/","section":"post","summary":"Redirects to legacy blog post.\n\nIn ECMAScript 5 we now have two distinct kinds of properties.\n\n* Data properties\n* Accessor properties\n","tags":["ecma-script","ecma-script-3","ecma-script-5","es3","es5","function","javascript","web"],"title":"JavaScript Properties","type":"post"},{"authors":null,"categories":null,"content":"  C# .NET Coding Standards and Guidelines  \n","date":1344686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1344686400,"objectID":"671cb5c8944323be5dd4695aa802923a","permalink":"https://binarymist.io/blog/2012/08/12/c-sharp-dot-net-coding-standards-and-guidelines/","publishdate":"2012-08-12T00:00:00+12:00","relpermalink":"/blog/2012/08/12/c-sharp-dot-net-coding-standards-and-guidelines/","section":"post","summary":"Redirects to legacy blog post.\n\nThis is the current set of coding standards and guidelines I use when I’m coding in the C#.NET language. I thought it would be good to share so others could get use out of them also, and maybe start a discussion as to amendments / changes they see that could be useful?\n","tags":["coding-standards","c-sharp","dot-net","function"],"title":"C Sharp Dot NET Coding Standards and Guidelines","type":"post"},{"authors":null,"categories":null,"content":"  Guidance on Running Retrospectives  \n","date":1343390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1343390400,"objectID":"f55a012df5206c551ba46a56018ad11e","permalink":"https://binarymist.io/blog/2012/07/28/guidance-on-running-retrospectives/","publishdate":"2012-07-28T00:00:00+12:00","relpermalink":"/blog/2012/07/28/guidance-on-running-retrospectives/","section":"post","summary":"Redirects to legacy blog post.\n\nFollowing is the five steps we use to run our Retrospectives. I’ve purposely made these as terse as possible, so it can be used as a check list as the retrospective progresses. Below the five steps I’ve added some extra info and tips.\n","tags":["agile","operational-efficiencies","retrospective","scrum"],"title":"Guidance on Running Retrospectives","type":"post"},{"authors":null,"categories":null,"content":"  A Handful of Singletons in C#  \n","date":1342180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1342180800,"objectID":"3082cf21b1eba150dcdda3509cf11d0a","permalink":"https://binarymist.io/blog/2012/07/14/a-handful-of-singletons-in-c-sharp/","publishdate":"2012-07-14T00:00:00+12:00","relpermalink":"/blog/2012/07/14/a-handful-of-singletons-in-c-sharp/","section":"post","summary":"Redirects to legacy blog post.\n\nRecently I was involved in an interview where I was queried on the Singleton Creational design pattern. I thought I’d share what I came up with. In order of preference from most to least used.\n","tags":["dot-net","c-sharp","design-patern"],"title":"A Handful of Singletons in C Sharp","type":"post"},{"authors":null,"categories":null,"content":"  Extending, Currying and Monkey Patching. part 3  \n","date":1338033600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1338033600,"objectID":"3db07001c8fad00424c946a24429167e","permalink":"https://binarymist.io/blog/2012/05/27/extending-currying-and-monkey-patching-part-3/","publishdate":"2012-05-27T00:00:00+12:00","relpermalink":"/blog/2012/05/27/extending-currying-and-monkey-patching-part-3/","section":"post","summary":"Redirects to legacy blog post.\n\nMonkey Patching, or sometimes known as Duck Punching.\n","tags":["currying","ecma-script","ecma-script-5","es5","function","functional-programming","javascript","partial-function-application"],"title":"Extending, Currying and Monkey Patching part 3","type":"post"},{"authors":null,"categories":null,"content":"  Extending, Currying and Monkey Patching. part 2  \n","date":1336910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1336910400,"objectID":"5ad5e5ad0bb3f12e57bf1f31d953c7f8","permalink":"https://binarymist.io/blog/2012/05/14/extending-currying-and-monkey-patching-part-2/","publishdate":"2012-05-14T00:00:00+12:00","relpermalink":"/blog/2012/05/14/extending-currying-and-monkey-patching-part-2/","section":"post","summary":"Redirects to legacy blog post.\n\nCurrying got it’s name from Haskell Curry, originally discovered by Moses Schönfinkel. The programming language Haskell named after Haskell Curry is a purely functional language. So the concept of Currying has it’s roots in functional programming. It seems that the concepts of Currying and Partial Function Application are often used interchangeably, although they are different. Lets try and shed some light on the confusion.\n","tags":["currying","ecma-script","ecma-script-5","es5","function","functional-programming","javascript","partial-function-application"],"title":"Extending, Currying and Monkey Patching part 2","type":"post"},{"authors":null,"categories":null,"content":"  Extending, Currying and Monkey Patching. part 1  \n","date":1335614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1335614400,"objectID":"d4de42c8a16ca9f2cf29ac2b5078108b","permalink":"https://binarymist.io/blog/2012/04/29/extending-currying-and-monkey-patching-part-1/","publishdate":"2012-04-29T00:00:00+12:00","relpermalink":"/blog/2012/04/29/extending-currying-and-monkey-patching-part-1/","section":"post","summary":"Redirects to legacy blog post.\n\nExtending: The JavaScript Function.prototype.call and Function.prototype.apply methods allow us to extend an object with additional functionality...\n","tags":["currying","ecma-script","ecma-script-5","es5","function","functional-programming","javascript","partial-function-application"],"title":"Extending, Currying and Monkey Patching part 1","type":"post"},{"authors":null,"categories":null,"content":" ","date":1335229200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1335229200,"objectID":"c7321e38df8128399b27dc5f704fd1e1","permalink":"https://binarymist.io/talk/tsbc-2012-workshop-pearls-for-improving-operational-efficiency/","publishdate":"2012-04-24T13:00:00+12:00","relpermalink":"/talk/tsbc-2012-workshop-pearls-for-improving-operational-efficiency/","section":"talk","summary":"This was a presentation held at one of TSBCs Sprint Reviews after attending a Clarus Professional Scrum Master course.\n","tags":["talk","scrum","workshop"],"title":"Workshop - Pearls For Improving Operational Efficiency","type":"talk"},{"authors":null,"categories":null,"content":"  Supporting multiple sites with a single SSL Certificate  \n","date":1333886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1333886400,"objectID":"9d00d93d10dc6168833772f778c54f38","permalink":"https://binarymist.io/blog/2012/04/09/supporting-multiple-sites-with-a-single-ssl-certificate/","publishdate":"2012-04-09T00:00:00+12:00","relpermalink":"/blog/2012/04/09/supporting-multiple-sites-with-a-single-ssl-certificate/","section":"post","summary":"Redirects to legacy blog post.\n\nThere are a couple of ways I’m aware of you can support multiple web sites with a single SSL certificate using the same port...\n","tags":[],"title":"Supporting multiple sites with a single SSL Certificate","type":"post"},{"authors":null,"categories":null,"content":"  How to optimise your testing effort  \n","date":1332500400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1332500400,"objectID":"889d61975959fcb6fdc2479da5ab0731","permalink":"https://binarymist.io/blog/2012/03/24/how-to-optimise-your-testing-effort/","publishdate":"2012-03-24T00:00:00+13:00","relpermalink":"/blog/2012/03/24/how-to-optimise-your-testing-effort/","section":"post","summary":"Redirects to legacy blog post.\n\nI recently wrote a post for the company I currently work for around the joys of doing TDD. What is your current approach to testing? How can you spend the little time you have on the most important areas? I thought I’d share some thoughts around where I see the optimal areas to invest your test effort.\n","tags":["acceptance-criteria","agile","ci","continuous-integration","code-review","definition-of-done","development-methodologies","operational-efficiencies","solid","test","testing","test-conditions","tdd"],"title":"How to optimise your testing effort","type":"post"},{"authors":null,"categories":null,"content":"  Keeping your events thread safe  \n","date":1331377200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1331377200,"objectID":"8df2b42b464c8249e4dbd72d09c55050","permalink":"https://binarymist.io/blog/2012/03/11/keeping-your-events-thread-safe/","publishdate":"2012-03-11T00:00:00+13:00","relpermalink":"/blog/2012/03/11/keeping-your-events-thread-safe/","section":"post","summary":"Redirects to legacy blog post.\n\nAn area I’ve noticed where engineers often forget to think about synchronization is when firing events. It seems to be a common misconception, that all that is needed to keep synchronisation, is to check the delegate (technically a `MulticastDelegate`, or in architectural terms the publisher of the publish-subscribe pattern (more commonly known as the observer pattern)) for null.\n","tags":["architecture","c-sharp","design-pattern","dot-net"],"title":"Keeping your events thread safe","type":"post"},{"authors":null,"categories":null,"content":" Owner, TSBC\n Kim set up a huge legacy at TSBC by implementing Scrum across our dev, and the transparency I\u0026rsquo;ve had in the last few months is a testament to his passion for our work, and his dedication to having the interests of the business a priority.\n","date":1329004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1329004800,"objectID":"144bbabb0af4ccb5a2c540cdb67f74ca","permalink":"https://binarymist.io/project/testimonial-glen-senior/","publishdate":"2012-02-12T00:00:00Z","relpermalink":"/project/testimonial-glen-senior/","section":"project","summary":"TSBC","tags":["testimonial"],"title":"Glen Senior","type":"project"},{"authors":null,"categories":null,"content":" Principal Consultant - Agile | Lean at Double-O Consultants\n I\u0026rsquo;ve had the pleasure of managing Kim and have found him to be a highly-focused and very skilled software developer. He works hard to ensure he achieves high quality in everything he develops and always has his employer\u0026rsquo;s interests at heart.\nHe wants to achieves great results and will drive himself and others around him to achieve this. Any organisation Kim is involved with will benefit immensely from his involvement.\n","date":1329004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1329004800,"objectID":"a625e2b98e81226f8f4b3372f0d9aa3d","permalink":"https://binarymist.io/project/testimonial-joe-kearns/","publishdate":"2012-02-12T00:00:00Z","relpermalink":"/project/testimonial-joe-kearns/","section":"project","summary":"Double-O Consultants","tags":["testimonial"],"title":"Joe Kearns","type":"project"},{"authors":null,"categories":null,"content":"  Bare-metal Hypervisor Setup Evaluation  \n","date":1327230000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1327230000,"objectID":"2da3c9e8f7f652be321fc4d0207c9940","permalink":"https://binarymist.io/blog/2012/01/23/bare-metal-hypervisor-setup-evaluation/","publishdate":"2012-01-23T00:00:00+13:00","relpermalink":"/blog/2012/01/23/bare-metal-hypervisor-setup-evaluation/","section":"post","summary":"Redirects to legacy blog post.\n\nRecently I had the opportunity for work, to carry out some research on what’s in the market in regards to bare-metal hypervisors. The following is the result of an in depth research and deployment project of the following bare-metal hyper-visors. This will enable us to trial the hypervisors out for performance, ease of setup, ease of administration, and ease of use.\n","tags":["esxi","free-and-open-source","linux","gnu-linux","hypervisor","kvm","proxmox","virtualisation","vmware","xen","xen-server","ups","backups","archipel"],"title":"Bare-metal Hypervisor Setup Evaluation","type":"post"},{"authors":null,"categories":null,"content":"  OpenSSH from Linux to Windows 7 via tunneled RDP  \n","date":1324897200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1324897200,"objectID":"27e9dbe27b61ff169ad3d5df24670ce2","permalink":"https://binarymist.io/blog/2011/12/27/openssh-from-linux-to-windows-7-via-tunneled-rdp/","publishdate":"2011-12-27T00:00:00+13:00","relpermalink":"/blog/2011/12/27/openssh-from-linux-to-windows-7-via-tunneled-rdp/","section":"post","summary":"Redirects to legacy blog post.\n\nIn this article I’ll go over getting Kali Linux installed and set-up. I’ll go over a few of the packages in a low level of detail (due to the share number of them) that come out of the box. On top of that I’ll also go over a few programmes I like to install separately. In a subsequent article I’d like to continue with additional programmes that come with Kali Linux as there are just to many to cover in one go.\n","tags":["blowfish","cipher","linux","networking","rdp","windows","ssh"],"title":"OpenSSH from Linux to Windows 7 via tunneled RDP","type":"post"},{"authors":null,"categories":null,"content":"  JavaScript Reserved Words  \n","date":1324206000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1324206000,"objectID":"bc30ed1ac97d39d7460698a8dffc997c","permalink":"https://binarymist.io/blog/2011/12/19/javascript-reserved-words/","publishdate":"2011-12-19T00:00:00+13:00","relpermalink":"/blog/2011/12/19/javascript-reserved-words/","section":"post","summary":"Redirects to legacy blog post.\n\nFunnily enough, most of these are not used in the language. They cannot be used to name variables or parameters. In saying that, I did some testing below and that statement’s not entirely accurate.\n","tags":["javascript"],"title":"JavaScript Reserved Words","type":"post"},{"authors":null,"categories":null,"content":"  Centerim, Irssi, Alpine on Screen  \n","date":1322305200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322305200,"objectID":"89f3141fa0d64cca73eb065eefb06509","permalink":"https://binarymist.io/blog/2011/11/27/centerim-irssi-alpine-on-screen/","publishdate":"2011-11-27T00:00:00+13:00","relpermalink":"/blog/2011/11/27/centerim-irssi-alpine-on-screen/","section":"post","summary":"Redirects to legacy blog post.\n\nDetailing the setup/configuration of Centerim, Irssi, Alpine on the Linux shell session manager Screen.\n","tags":["linux","gnu-linux","terminal"],"title":"Centerim, Irssi, Alpine on Screen","type":"post"},{"authors":null,"categories":null,"content":"  Scoping and Hoisting in JavaScript  \n","date":1321182000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1321182000,"objectID":"67d427da81927b3e40bba78785c03b23","permalink":"https://binarymist.io/blog/2011/11/14/scoping-and-hoisting-in-javascript/","publishdate":"2011-11-14T00:00:00+13:00","relpermalink":"/blog/2011/11/14/scoping-and-hoisting-in-javascript/","section":"post","summary":"Redirects to legacy blog post.\n\nIn this article I’ll go over getting Kali Linux installed and set-up. I’ll go over a few of the packages in a low level of detail (due to the share number of them) that come out of the box. On top of that I’ll also go over a few programmes I like to install separately. In a subsequent article I’d like to continue with additional programmes that come with Kali Linux as there are just to many to cover in one go.\n","tags":["closure","function","javascript"],"title":"Scoping and Hoisting in JavaScript","type":"post"},{"authors":null,"categories":null,"content":"  Employing Scrum  \n","date":1314532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1314532800,"objectID":"77b9e87b66e6e81534ebffe741a47b55","permalink":"https://binarymist.io/blog/2011/08/29/employing-scrum/","publishdate":"2011-08-29T00:00:00+12:00","relpermalink":"/blog/2011/08/29/employing-scrum/","section":"post","summary":"Redirects to legacy blog post.\n\nIn this post, it’s my intention to bring some clarity to the following question. Why does a business decide to employ Scrum as the chosen framework that their development team/s use for managing the business’s projects / work items?\n","tags":["agile","development-methodologies","operational-efficiencies","scrum"],"title":"Employing Scrum","type":"post"},{"authors":null,"categories":null,"content":"  Function Declarations vs Function Expressions  \n","date":1313496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1313496000,"objectID":"d380ed30830671d1c9b82d43bd10ac70","permalink":"https://binarymist.io/blog/2011/08/17/function-declarations-vs-function-expressions/","publishdate":"2011-08-17T00:00:00+12:00","relpermalink":"/blog/2011/08/17/function-declarations-vs-function-expressions/","section":"post","summary":"Redirects to legacy blog post.\n\nThis short post is in reaction to another post on JavaScript Function Declarations and Function Expressions. My concern was with the littering of the global object.\n","tags":["function","javascript"],"title":"Function Declarations vs Function Expressions","type":"post"},{"authors":null,"categories":null,"content":"  Quick walk through, of my UPS library  \n","date":1312372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1312372800,"objectID":"8dcddb92c5741a36ce59a383ae18da24","permalink":"https://binarymist.io/blog/2011/08/04/quick-walk-through-of-my-ups-library/","publishdate":"2011-08-04T00:00:00+12:00","relpermalink":"/blog/2011/08/04/quick-walk-through-of-my-ups-library/","section":"post","summary":"Redirects to legacy blog post.\n\nPart three of a three part series.\n\nOn setting up a UPS solution, to enable clean shutdown of vital network components. In this post, we’ll be reviewing the library that performs the shutting down of our servers.\n","tags":["c-sharp","dot-net","encryption","esxi","networking","ups","virtualisation","vmware","windows"],"title":"Quick walk through, of my UPS library","type":"post"},{"authors":null,"categories":null,"content":"  Preparing APC Smart-UPS 1500 clients  \n","date":1311595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1311595200,"objectID":"d43bd72f7bba432b8f305487fbc61b33","permalink":"https://binarymist.io/blog/2011/07/26/preparing-apc-smart-ups-1500-clients/","publishdate":"2011-07-26T00:00:00+12:00","relpermalink":"/blog/2011/07/26/preparing-apc-smart-ups-1500-clients/","section":"post","summary":"Redirects to legacy blog post.\n\nPart two of a three part series.\n","tags":["dot-net","esxi","linux","networking","power-shell","ps","reverse-engineering","ups","virtualisation","vmware","windows"],"title":"Preparing APC Smart-UPS 1500 clients","type":"post"},{"authors":null,"categories":null,"content":"  Preparing APC Smart-UPS 1500 for Critical Servers  \n","date":1308139200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1308139200,"objectID":"dd215012212b334e1236c9c3103f96b5","permalink":"https://binarymist.io/blog/2011/06/16/preparing-apc-smart-ups-1500-for-critical-servers/","publishdate":"2011-06-16T00:00:00+12:00","relpermalink":"/blog/2011/06/16/preparing-apc-smart-ups-1500-for-critical-servers/","section":"post","summary":"Redirects to legacy blog post.\n\nPart one of a three part series on Setting up a UPS solution, to enable clean shutdown of vital network components. This post is essentially about setting up a Smart-UPS and it’s NMC (Network Management Card),\nas the project I embarked upon was a little large for a single post.\n","tags":["cracking","esxi","hardware","hydra","networking","terminal","ups","virtualisation","wireshark"],"title":"Preparing APC Smart-UPS 1500 for Critical Servers","type":"post"},{"authors":null,"categories":null,"content":"  Using PSCredentials  \n","date":1306929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1306929600,"objectID":"58144f15eaeeef8be24617cdef59f3db","permalink":"https://binarymist.io/blog/2011/06/02/using-pscredentials/","publishdate":"2011-06-02T00:00:00+12:00","relpermalink":"/blog/2011/06/02/using-pscredentials/","section":"post","summary":"Redirects to legacy blog post.\n\nI’ve been working on a small project that shuts down machines attached by network and of course power feed to an APC Smart-UPS. The code that was shutting down the guests required authentication to be passed to the receiving services.\n","tags":["c-sharp","dot-net","information-security","infosec","power-shell","ps","security","ups"],"title":"Using PSCredentials","type":"post"},{"authors":null,"categories":null,"content":"  rsync over SSH from Linux workstation to FreeNAS  \n","date":1299322800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1299322800,"objectID":"1dc1875c61d1c951f2c027aa55c51eeb","permalink":"https://binarymist.io/blog/2011/03/06/rsync-over-ssh-from-linux-workstation-to-freenas/","publishdate":"2011-03-06T00:00:00+13:00","relpermalink":"/blog/2011/03/06/rsync-over-ssh-from-linux-workstation-to-freenas/","section":"post","summary":"Redirects to legacy blog post.\n\nI’ve been intending for quite some time to setup an automated or at least a thoughtless one click backup procedure from my family members PC’s to a file server. Now if you put files directories in the place where we are going to rsync to, and run the command we’re going to setup, those new files directories will be deleted.\n","tags":["backups","freebsd","freenas","linux","networking","rsync","ssh"],"title":"rsync over SSH from Linux workstation to FreeNAS","type":"post"},{"authors":null,"categories":null,"content":"  Quick technology mash-up  \n","date":1296298800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1296298800,"objectID":"133e2cc49214a8babc67e86339aa94b2","permalink":"https://binarymist.io/blog/2011/01/30/quick-technology-mash-up/","publishdate":"2011-01-30T00:00:00+13:00","relpermalink":"/blog/2011/01/30/quick-technology-mash-up/","section":"post","summary":"Redirects to legacy blog post.\n","tags":[],"title":"Quick technology mash-up","type":"post"},{"authors":null,"categories":null,"content":"  Garbage Collection in .NET 4.0  \n","date":1287226800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1287226800,"objectID":"2ecb0ab1aae4fafb2fbaeda42994ff09","permalink":"https://binarymist.io/blog/2010/10/17/garbage-collection-in-dot-net-4.0/","publishdate":"2010-10-17T00:00:00+13:00","relpermalink":"/blog/2010/10/17/garbage-collection-in-dot-net-4.0/","section":"post","summary":"Redirects to legacy blog post.\n\nCoverage on what's new in the .NET 4.0 garbage collector.\n","tags":["gc","garbage-collection","dot-net","windows"],"title":"Garbage Collection in dot NET 4.0","type":"post"},{"authors":null,"categories":null,"content":"  LSP / DbC and .NET’s support  \n","date":1286794800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1286794800,"objectID":"89c37def3e4750da9fe19996a210cf05","permalink":"https://binarymist.io/blog/2010/10/12/lsp-dbc-and-dot-nets-support-part-2/","publishdate":"2010-10-12T00:00:00+13:00","relpermalink":"/blog/2010/10/12/lsp-dbc-and-dot-nets-support-part-2/","section":"post","summary":"Redirects to legacy blog post.\n\nPart two.\n","tags":["architecture","c-sharp","dbc","dot-net","lsp","solid"],"title":"LSP, DbC and dot NET’s support part 2","type":"post"},{"authors":null,"categories":null,"content":"  LSP / DbC and .NET’s support  \n","date":1286708400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1286708400,"objectID":"1d01497317a2f4b51cbe7c2e973457ac","permalink":"https://binarymist.io/blog/2010/10/11/lsp-dbc-and-dot-nets-support-part-1/","publishdate":"2010-10-11T00:00:00+13:00","relpermalink":"/blog/2010/10/11/lsp-dbc-and-dot-nets-support-part-1/","section":"post","summary":"Redirects to legacy blog post.\n\nPart one.\n","tags":["architecture","dbc","dot-net","lsp","solid"],"title":"LSP, DbC and dot NET’s support, part 1","type":"post"},{"authors":null,"categories":null,"content":"  Discussion on Class Construction Techniques  \n","date":1286622000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1286622000,"objectID":"06d07337541e682478c517e5f0b977c5","permalink":"https://binarymist.io/blog/2010/10/10/discussion-on-class-construction-techniques/","publishdate":"2010-10-10T00:00:00+13:00","relpermalink":"/blog/2010/10/10/discussion-on-class-construction-techniques/","section":"post","summary":"Redirects to legacy blog post.\n\nI had a discussion with some work colleges a short while ago, around a couple of different techniques of constructing a class object. The two approaches involved in the discussion where...\n","tags":["architecture","design-patern"],"title":"Discussion on Class Construction Techniques","type":"post"},{"authors":null,"categories":null,"content":"  Metadata Exchange options for WCF  \n","date":1283601600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1283601600,"objectID":"26a4d5128f14aaf4df910b902c09973d","permalink":"https://binarymist.io/blog/2010/09/05/metadata-exchange-options-for-wcf/","publishdate":"2010-09-05T00:00:00+12:00","relpermalink":"/blog/2010/09/05/metadata-exchange-options-for-wcf/","section":"post","summary":"Redirects to legacy blog post.\n\nThere are two options for publishing metadata from a WCF service. By default, the services metadata is not published. In order to make the services information about itself public, you must do either of the following.\n","tags":["dot-net","networking","tcp","web","wcf","windows"],"title":"Metadata Exchange options for WCF","type":"post"},{"authors":null,"categories":null,"content":"  Installation of SSH on 64bit Windows 7 to tunnel RDP  \n","date":1282737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1282737600,"objectID":"31d101d975c6f0dacfb36dd045cd2599","permalink":"https://binarymist.io/blog/2010/08/26/installation-of-ssh-on-64bit-windows-7-to-tunnel-rdp/","publishdate":"2010-08-26T00:00:00+12:00","relpermalink":"/blog/2010/08/26/installation-of-ssh-on-64bit-windows-7-to-tunnel-rdp/","section":"post","summary":"Redirects to legacy blog post.\n\nThis post covers two scenarios.\n","tags":["debian","linux","networking","rdp","windows","ssh"],"title":"Installation of SSH on 64bit Windows 7 to tunnel RDP","type":"post"},{"authors":null,"categories":null,"content":"  Message Inspection in WCF  \n","date":1276430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1276430400,"objectID":"acb41ad08d2639d3ef58d2a0f73cfefe","permalink":"https://binarymist.io/blog/2010/06/14/message-inspection-in-wcf/","publishdate":"2010-06-14T00:00:00+12:00","relpermalink":"/blog/2010/06/14/message-inspection-in-wcf/","section":"post","summary":"Redirects to legacy blog post.\n\nMessage Inspectors can be a very usefull tool in diagnosing problems between WCF services and clients. The messages that are transferred between clients/services can be intercepted and operations performed on them. We’ve used this at work in conjunction with a tool called SaopUI to capture the SOAP messages and fire them at our service. This can be usefull for load testing, concurrency testing scenarios amongst others.\n","tags":["c-sharp","dot-net","networking","wcf","windows"],"title":"Message Inspection in WCF","type":"post"},{"authors":null,"categories":null,"content":"  Duplex communication and callbacks in WCF  \n","date":1274529600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1274529600,"objectID":"4c270cb49d367c60a11b5f1159fcedd7","permalink":"https://binarymist.io/blog/2010/05/23/duplex-communication-and-callbacks-in-wcf/","publishdate":"2010-05-23T00:00:00+12:00","relpermalink":"/blog/2010/05/23/duplex-communication-and-callbacks-in-wcf/","section":"post","summary":"Redirects to legacy blog post.\n\nI was reading in the book Enterprise Integration Patterns that my dev manager bought for the team, on the Message Endpoint pattern on the way home from work a few days ago.\n\n“A Message Endpoint can be used to send messages or receive them, but one instance does not do both” From my experience, this wasn’t necessarily true. So I decided to confirm my suspicion.\nThe following is a mix of what I read and tested out.\n","tags":["callback","c-sharp","design-pattern","dot-net","networking","wcf","windows"],"title":"Duplex communication and callbacks in WCF","type":"post"},{"authors":null,"categories":null,"content":"  Setting up a NFS share in FreeNAS  \n","date":1273924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1273924800,"objectID":"76a22195408e29ac15b97637bfd46d35","permalink":"https://binarymist.io/blog/2010/05/16/setting-up-a-nfs-share-in-freenas/","publishdate":"2010-05-16T00:00:00+12:00","relpermalink":"/blog/2010/05/16/setting-up-a-nfs-share-in-freenas/","section":"post","summary":"Redirects to legacy blog post.\n","tags":["freebsd","freenas","linux","networking","nfs"],"title":"Setting up a NFS share in FreeNAS","type":"post"},{"authors":null,"categories":null,"content":"  Logical vs Physical Addresses in WCF  \n","date":1271505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1271505600,"objectID":"8d2f72d09b8c81a725a8ae9aa504c77d","permalink":"https://binarymist.io/blog/2010/04/18/logical-vs-physical-addresses-in-wcf/","publishdate":"2010-04-18T00:00:00+12:00","relpermalink":"/blog/2010/04/18/logical-vs-physical-addresses-in-wcf/","section":"post","summary":"Redirects to legacy blog post.\n\nIn this example, I share a listenUri between two endpoints.\n","tags":["c-sharp","dot-net","networking","tcp","wcf","windows"],"title":"Logical vs Physical Addresses in WCF","type":"post"},{"authors":null,"categories":null,"content":"  A few steps to secure a FreeNAS server  \n","date":1270468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270468800,"objectID":"46635b7820f4effd9d1bb1a86d89ed84","permalink":"https://binarymist.io/blog/2010/04/06/a-few-steps-to-secure-a-freenas-server/","publishdate":"2010-04-06T00:00:00+12:00","relpermalink":"/blog/2010/04/06/a-few-steps-to-secure-a-freenas-server/","section":"post","summary":"Redirects to legacy blog post.\n\nChange the default password in System|General|Password.\n\nSetup key pair authentication for SSH and secure FreeNAS.\n","tags":["freebsd","freenas","networking","security","ssh","network-security","free-and-open-source"],"title":"A few steps to secure a FreeNAS server","type":"post"},{"authors":null,"categories":null,"content":"  Built-in MSMQ Bindings  \n","date":1270382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1270382400,"objectID":"9262b3132c9526e90eea881a909a650c","permalink":"https://binarymist.io/blog/2010/04/05/built-in-msmq-bindings/","publishdate":"2010-04-05T00:00:00+12:00","relpermalink":"/blog/2010/04/05/built-in-msmq-bindings/","section":"post","summary":"Redirects to legacy blog post.\n\n`NetMsmqBinding` only works if you have WCF on both sides of the Queue-to-Queue transfer. `MsmqIntegrationBinding` is targeted toward existing MSMQ applications that use COM, native C++ APIs or the types defined in the `System.Messaging` namespace (as stated by MSDN).\n","tags":["wcf","dot-net","windows"],"title":"Built-in MSMQ Bindings","type":"post"},{"authors":null,"categories":null,"content":"  Adding disks, CIFS/SMB shares to FreeNAS  \n","date":1269601200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1269601200,"objectID":"e4e36db944c8d695aae5ebb2ba4b3078","permalink":"https://binarymist.io/blog/2010/03/27/adding-disks-cifs/smb-shares-to-freenas/","publishdate":"2010-03-27T00:00:00+13:00","relpermalink":"/blog/2010/03/27/adding-disks-cifs/smb-shares-to-freenas/","section":"post","summary":"Redirects to legacy blog post.\n\nWhat I did, was add a disk at a time (one each week, and stressed it for the entire week). This way the wear on the disk should be staggered and we are less likely to have all drives fail at the same time. Once I’d physically added all disks (ended up adding 4 x WD7500AACS for now).\n","tags":["freebsd","freenas","networking","smb-cifs"],"title":"Adding disks, CIFS/SMB shares to FreeNAS","type":"post"},{"authors":null,"categories":null,"content":" Solution Delivery Team Leader at IAG New Zealand\n I have worked with Kim as a colleague and as one of his Scrum Masters on projects including application integration, ASP.Net, Windows Workflow Foundation and Windows Communications Foundation. Kim is not only knowledgeable and passionate about software design and development, but also assertive in his approach to providing the best solution in the first instance. I believe Kim would be beneficial to any project he was a member.\n","date":1265932800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1265932800,"objectID":"847cb6d2eab542b5657700ca06934ab0","permalink":"https://binarymist.io/project/testimonial-james-pinamonti/","publishdate":"2010-02-12T00:00:00Z","relpermalink":"/project/testimonial-james-pinamonti/","section":"project","summary":"IAG, New Zealand","tags":["testimonial"],"title":"James Pinamonti","type":"project"},{"authors":null,"categories":null,"content":"  Keeping Encapsulation on ones mind  \n","date":1261566000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1261566000,"objectID":"1c5e7ebce53c2ea9da1ffc56bbab4df8","permalink":"https://binarymist.io/blog/2009/12/24/keeping-encapsulation-on-ones-mind/","publishdate":"2009-12-24T00:00:00+13:00","relpermalink":"/blog/2009/12/24/keeping-encapsulation-on-ones-mind/","section":"post","summary":"Redirects to legacy blog post.\n\nAnytime you find yourself looking at a class’s implementation to figure out how to use the class, you’re not programming to the interface; you’re programming through the interface to the implementation...\n","tags":["development-methodologies","encapsulation"],"title":"Keeping Encapsulation on ones mind","type":"post"}]